# AI Advent Challenge

[English](README.md) | [Ð ÑƒÑÑÐºÐ¸Ð¹](README.ru.md)

> Daily AI-powered projects exploring language models and multi-agent systems

## Overview

This repository contains daily challenges building AI-powered systems with language models. Each day introduces new concepts and builds upon previous challenges.

**Updates:** Project news and daily recaps are published in the Telegram channel [Ð’Ñ‹ÑÐ¾ÐºÐ¾Ð½Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹ ÐºÐ°Ð±Ð°Ð½Ñ‡Ð¸Ðº](https://t.me/data_intensive_boar).

**Current Status:** ðŸ† Day 25 COMPLETED & DEPLOYED â€” Personalised Butler with Alfred-style Ð´Ð²Ð¾Ñ€ÐµÑ†ÐºÐ¸Ð¹ persona, user profiles, and memory management (Epic 25). Voice commands integrated (Epic 24), observability & benchmarks delivered (Epic 23).

### Day 21 (Completed)
- Summary: `docs/specs/epic_21/epic_21.md`
- Archive Index: `docs/specs/epic_21/ARCHIVE_INDEX.md`
- Demo quick start:
  - `make day_21_demo` â€” interactive console demo
  - `make day_21_batch` â€” batch run on 10 questions
  - `make day_21_metrics` â€” print key rag_* metrics

**Project Status:**
- âœ… 25 daily challenges completed
- âœ… Clean Architecture fully implemented (Day 21)
- âœ… Security hardening deployed (path traversal protection, input validation)
- âœ… Quality automation established (pre-commit hooks, automated linting)
- âœ… Production-ready multi-agent system with self-improvement
- âœ… Automatic quality evaluation and fine-tuning
- âœ… Comprehensive documentation for AI assistants
- âœ… **Personalised Butler** (Day 25) with user profiles, memory, and interest extraction

**Key Features:**
- âœ… 25 daily challenges from simple chat to observability, benchmarks, voice commands, and personalization
- âœ… Clean Architecture with SOLID principles
- âœ… 420+ tests with 80%+ coverage
- âœ… Multi-model support (StarCoder, Mistral, Qwen, TinyLlama)
- âœ… MCP (Model Context Protocol) integration with HTTP server
- âœ… MCP-aware agent with automatic tool discovery and execution
- âœ… FSM-based Telegram bot for channel management and digest delivery
- âœ… **Hybrid Intent Recognition** (Rule-based + LLM with caching)
- âœ… **HW Checker integration** (all_checks_status, queue_status, retry_check)
- âœ… **Homework Review via Telegram** (list homeworks, review by commit hash)
- âœ… Channel digests with metadata support (title, description)
- âœ… PDF digest generation with automatic post collection
- âœ… Centralized logging system with structured output
- âœ… Health monitoring and metrics dashboard
- âœ… Hotreload for development (uvicorn --reload + watchdog)
- âœ… **Multi-Pass Code Review** (3-pass architecture for homework analysis)
- âœ… **LLM-as-Judge Quality Assessment** (automatic evaluation of summaries)
- âœ… **Self-Improving System** (automatic fine-tuning on high-quality data)
- âœ… **Stage 05 RU Benchmarks** (release-cadence quality scoreboard for channel digests & reviewer summaries)
- âœ… **Async Long Summarization** (queue-based processing with 600s timeout)
- âœ… **Code Review Queue System** (Day 17 - async review pipeline with diff analysis)
- âœ… **Pass 4 Log Analysis** (LLM-powered grouping, classification, and RCA for runtime logs)
- âœ… **Static Analysis Integration** (Flake8, Pylint, MyPy, Black, isort in the review loop)
- âœ… **MCP-first Publishing** (LLM calls external HW Checker MCP tool with automatic HTTP fallback)
- âœ… **Haiku Generation** (poetic postscript highlighting review sentiment)
- âœ… **Integration Contracts** (OpenAPI spec, JSON schema, cURL/Python examples for partners)
- âœ… **Personalised Butler** (Day 25 - user profiles, memory management, "Alfred-style Ð´Ð²Ð¾Ñ€ÐµÑ†ÐºÐ¸Ð¹" persona, automatic interest extraction)

## Quick Start

```bash
# Install dependencies
make install

# Start shared infrastructure (MongoDB, Prometheus, reviewer API)
./scripts/infra/start_shared_infra.sh

# Load shared infra credentials for Mongo/Prometheus
set -a
source ~/work/infra/.env.infra
set +a
export MONGODB_URL="mongodb://admin:${MONGO_PASSWORD}@127.0.0.1:27017/butler_test?authSource=admin"

# Run tests (local baseline 429 pass / 2 xfail due to latency thresholds)
poetry run pytest -q

# Run the API
make run-api

# Backoffice CLI
poetry run python -m src.presentation.cli.backoffice.main --help
```

### Document Embedding Index

```bash
# Load credentials (example)
export MONGO_USER=admin
export MONGO_PASSWORD=$(cat ~/work/infra/secrets/mongo_password.txt)
export MONGODB_URL="mongodb://${MONGO_USER}:${MONGO_PASSWORD}@127.0.0.1:27017/butler?authSource=admin"
export TEST_MONGODB_URL="$MONGODB_URL"
export REDIS_HOST=127.0.0.1
export REDIS_PORT=6379
export REDIS_PASSWORD=$(cat ~/work/infra/secrets/redis_password.txt)

# Build index across docs + lecture corpora
poetry run python -m src.presentation.cli.backoffice.main index run

# Inspect summary counts
poetry run python -m src.presentation.cli.backoffice.main index inspect
```

See `docs/specs/epic_19/stage_19_04_runbook.md` for detailed instructions,
troubleshooting, and maintenance guidance.

### Large Data Files

Some large JSONL files (>500KB) are stored in compressed format (.gz) to reduce repository size:
- `results_stage20.jsonl.gz` (compressed from 555KB to ~148KB, 26.5% of original)
- `results_with_labels.jsonl.gz` (compressed from 555KB to ~148KB, 26.5% of original)

To decompress:
```bash
gunzip results_stage20.jsonl.gz
gunzip results_with_labels.jsonl.gz
```

To compress new JSONL files:
```bash
python scripts/tools/compress_jsonl.py <file.jsonl>
```

For detailed setup instructions, see [DEVELOPMENT.md](docs/guides/en/DEVELOPMENT.md) and the [Maintainer Playbook](docs/MAINTAINERS_GUIDE.md).

## Project Structure

```
AI_Challenge/
â”œâ”€â”€ src/              # Clean Architecture Core
â”‚   â”œâ”€â”€ domain/      # Business logic layer
â”‚   â”œâ”€â”€ application/ # Use cases and orchestrators
â”‚   â”œâ”€â”€ infrastructure/ # External integrations
â”‚   â””â”€â”€ presentation/   # API and CLI
â”œâ”€â”€ tasks/           # Daily Challenges (historical archive)
â”œâ”€â”€ archive/legacy/local_models/    # Archived local model infrastructure (deprecated)
â”œâ”€â”€ shared/          # Unified SDK for model interaction
â”œâ”€â”€ scripts/         # Utility scripts (infra, maintenance, quality)
â”œâ”€â”€ config/          # Configuration files
â””â”€â”€ docs/            # Specifications, guides, references, archives
```

## Daily Challenges

| Day | Focus Area | Key Technologies | Status |
|-----|------------|------------------|--------|
| Day 1 | Basic chat interface | Python, API | âœ… Complete |
| Day 2 | JSON structured responses | Python, JSON parsing | âœ… Complete |
| Day 3 | Advisor mode | Python, Session management | âœ… Complete |
| Day 4 | Temperature control | Python, Experimentation | âœ… Complete |
| Day 5 | Local models | SDK, Docker, FastAPI | âœ… Complete |
| Day 6 | Testing framework | Testing, Report generation | âœ… Complete |
| Day 7 | Multi-agent systems | FastAPI, Docker, Orchestration | âœ… Complete |
| Day 8 | Token analysis | Clean Architecture, ML Engineering | âœ… Complete |
| Day 9 | MCP integration | MCP Protocol, Context management | âœ… Complete |
| Day 10 | Production MCP system | MCP, Streaming, Orchestration | âœ… Complete |
| Day 11 | Butler Bot FSM | Telegram Bot, FSM, Intent Parsing | âœ… Complete |
| Day 12 | PDF Digest System | MongoDB, PDF Generation, MCP Tools | âœ… Complete |
| Day 13 | Butler Agent Refactoring | Hybrid Intent Recognition, HW Checker, Metadata | âœ… Complete |
| Day 14 | Multi-Pass Code Review | MCP Homework Review, 3-Pass Analysis | âœ… Complete |
| Day 15 | Quality Assessment & Fine-tuning | LLM-as-Judge, Self-Improving System, Hugging Face | âœ… Complete |
| Day 17 | Code Review Platform & MCP Publishing | Async queue, static analysis, log diagnostics, MCP tool calls | âœ… Complete |
| Day 18 | Performance Benchmarks | Prometheus, Benchmarking | âœ… Complete |
| Day 19 | Document Embedding Index | Redis/FAISS, Mongo, LLM API | âœ… Complete |
| Day 20 | RAG vs Nonâ€‘RAG Answering Agent | Retrieval, LLM-as-Judge | âœ… Complete |
| Day 21 | Repository Refactor & RAG++ | Clean Architecture, Reranking, Observability | âœ… Complete |
| Day 22 | RAG Citations & Source Attribution | RAG, MongoDB, Vector Search | âœ… Complete |
| Day 23 | Observability & Benchmark Enablement | Prometheus, Grafana, Loki, Benchmarks | âœ… Complete |
| Day 24 | Voice Commands Integration | Telegram Bot, Whisper STT, Butler Orchestrator | âœ… Complete |
| Day 25 | Personalised Butler | User Profiles, Memory Management, Interest Extraction, Alfred-style Ð´Ð²Ð¾Ñ€ÐµÑ†ÐºÐ¸Ð¹ | âœ… Complete |

## Core Infrastructure

### Local Models (archived)
- Local model containers are deprecated in favor of shared infrastructure.
- Legacy manifests are preserved under `archive/legacy/local_models/`.

### Shared SDK
Unified SDK for model interaction across all challenges.

```python
from shared.clients.model_client import ModelClient
client = ModelClient(provider="perplexity")
response = await client.chat("Hello, world!")
```

### Stage 05 Benchmark Smoke (Dry Run)

```bash
poetry run python scripts/quality/benchmark/run_benchmark.py \
  --scenario channel_digest_ru \
  --dataset data/benchmarks/benchmark_digest_ru_v1/2025-11-09_samples.jsonl \
  --dry-run --fail-on-warn
```

The `--dry-run` flag reuses stored judge scores, enabling CI smoke checks without
incurring LLM costs. Omit it to execute live evaluations (requires shared infra
credentials).

## Code Review System

- **Five-pass insight pipeline**: Architecture overview â†’ Component deep dives â†’ Synthesis â†’ Static analysis (Flake8, Pylint, MyPy, Black, isort) â†’ Pass 4 log analysis with LLM-generated classification, root-cause, and remediation tips.
- **Archive-aware diffing**: ZIP ingestion, semantic diff analysis, and repository persistence via `ReviewSubmissionUseCase`.
- **Runtime diagnostics**: `LogParserImpl` + `LogNormalizer` feed curated groups into `LLMLogAnalyzer` with severity thresholds and configurable timeouts.
- **Creative postscript**: Automatic haiku summarises review tone and highlights key risks.
- **Publishing workflow**: LLM invokes the external HW Checker MCP tool (`submit_review_result`) through `MCPHTTPClient`; resilient fallback reuses `ExternalAPIClient` when needed.
- **Integration assets**: Contracts live in `contracts/` (OpenAPI spec, JSON schema, examples) with deep-dive docs under `docs/day17/` and `docs/reference/en/review_system_architecture.md`.
- **Observability-first**: Structured review logs, Prometheus metrics, and MongoDB audit trail for every session.

## Docker Compose Files

Primary entry points:

- **`docker-compose.butler.yml`** â€“ production stack (MongoDB, MCP server, workers, bot, Prometheus, Grafana).
- **`docker-compose.butler.dev.yml`** â€“ development variant with hot reload and lightweight defaults.

Legacy configurations (Day 11/12 demos, full GPU stacks, experimental layouts) now live under `archive/docker-compose/`. Existing `make` targets keep working and reference the archived manifests.

**Quick Start:**
```bash
# Run the full Butler/Day 17 stack
make butler-up

# Tear down when finished
make butler-down

# Explore the legacy Day 11 demo (still available via archive files)
make day-11-up
```

## Current Features

**Self-Improving LLM System:**
- **LLM-as-Judge**: Automatic quality assessment using Mistral (coverage, accuracy, coherence, informativeness)
- **Automatic Fine-tuning**: Self-improvement by training on high-quality samples (100+ samples trigger)
- **Asynchronous Evaluation**: Fire-and-forget pattern, no blocking of main flow
- **Extensible Architecture**: Support for multiple fine-tuning tasks (summarization, classification, Q&A)
- **Docker-based ML**: Full Hugging Face Transformers integration in containers
- **Dataset Management**: Automatic JSONL export for fine-tuning datasets

**Butler Agent System:**
- **Hybrid Intent Recognition**: Two-layer architecture (rule-based + LLM fallback) with caching
- **HW Checker Integration**: Full status monitoring, queue management, and retry functionality
- **Homework Review**: List recent commits and perform code review via Telegram bot
- **Multi-Pass Code Review Platform**: Architecture â†’ Components â†’ Synthesis â†’ Static Analysis â†’ Pass 4 Log Insights + Haiku
- **LLM-driven MCP Publishing**: Tool calling against external HW Checker MCP with resilient HTTP fallback
- **Static Analysis Bundle**: Flake8, Pylint, MyPy, Black, isort results embedded into review reports
- **Runtime Log Triage**: Grouping, classification, and remediation tips generated by the LLM
- **Channel Metadata**: Automatic title and description fetching from Telegram API
- **Enhanced Digests**: Adaptive summary length based on post count, time-aware prompts
- **Markdown Escaping**: Safe Telegram message formatting
- **Hotreload Development**: Fast iteration with automatic code reloading

**PDF Digest Generation System:**
- PDF digest generation via MCP tools (5 tools)
- Automatic hourly post collection via `PostFetcherWorker`
- Hybrid deduplication (message_id + content_hash)
- PDF caching with 1-hour TTL for instant delivery
- MongoDB storage with 7-day TTL for automatic cleanup

**MCP-Aware Agent:**
- Automatic tool discovery via MCPToolsRegistry (5-minute cache)
- LLM-based tool selection and execution
- Robust retry logic with exponential backoff
- Dialog history management with automatic compression
- Prometheus metrics integration

**Personalised Butler (Day 25):**
- **User Profiles**: Auto-created profiles with "Alfred-style Ð´Ð²Ð¾Ñ€ÐµÑ†ÐºÐ¸Ð¹" persona
- **Memory Management**: Remembers last 50 messages per user with automatic compression
- **Interest Extraction**: Automatically extracts user interests from conversations (Task 16)
- **Alfred Persona**: Witty, caring, respectful responses (English humour, Russian language)
- **Voice Integration**: Works with voice messages via Whisper STT
- **Privacy**: All data stored locally in MongoDB (no external SaaS)
- See [Personalized Butler User Guide](docs/guides/personalized_butler_user_guide.md) for details

Quick start:
```bash
# Ensure MongoDB is running
docker-compose up -d mongodb

# Run post fetcher worker (hourly collection)
python src/workers/post_fetcher_worker.py

# Or run bot for PDF digest generation
make run-bot
```

**Homework Review Commands:**
- `ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð´Ð¾Ð¼Ð°ÑˆÐºÐ¸` - List recent homework commits with status
- `Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ€ÐµÐ²ÑŒÑŽ {commit_hash}` - Download archive and perform code review
- Review results are sent as Markdown files via Telegram

**Day 17 - Code Review Platform Enhancements:**
- Static analysis (Flake8, Pylint, MyPy, Black, isort) bundled into every report
- Pass 4 log analysis with severity filtering, grouping, and LLM-derived root causes
- External MCP publishing invoked directly by the reviewer LLM (with HTTP fallback)
- Integration contracts (OpenAPI, JSON schema, cURL/Python) for external consumers
- Markdown report enriched with consolidated findings, log diagnostics, and haiku postscript

See [docs/day12/USER_GUIDE.md](docs/day12/USER_GUIDE.md) for user guide and [docs/day12/api.md](docs/day12/api.md) for API documentation.

## AI Assistant Support

This repository includes comprehensive documentation for AI-assisted development:

- **[AI_CONTEXT.md](AI_CONTEXT.md)** - Complete project context for AI assistants
- **[.cursorrules](.cursorrules)** - Coding standards and conventions
- **[docs/INDEX.md](docs/INDEX.md)** - Organized documentation index

These files help AI coding assistants understand the project structure, patterns, and conventions.

## Technologies

**Core**: Python 3.10+, Poetry, Docker, FastAPI, Pydantic, pytest

**AI/ML**: HuggingFace Transformers, PyTorch, NVIDIA CUDA, 4-bit Quantization, Local Models, Fine-tuning

**Architecture**: Clean Architecture, Domain-Driven Design, SOLID Principles, LLM-as-Judge Pattern

**Infrastructure**: Traefik, NVIDIA Container Toolkit, Multi-stage Docker builds, MongoDB, Prometheus

## Documentation

Main documentation:
- [DEVELOPMENT.md](docs/guides/en/DEVELOPMENT.md) - Setup, deployment, and operations
- [ARCHITECTURE.md](docs/reference/en/ARCHITECTURE.md) - System architecture
- [USER_GUIDE.md](docs/guides/en/USER_GUIDE.md) - User guide
- [API_DOCUMENTATION.md](docs/reference/en/API_DOCUMENTATION.md) - Complete API reference
- [AGENT_INTEGRATION.md](docs/guides/en/AGENT_INTEGRATION.md) - MCP-aware agent integration guide
- [MONITORING.md](docs/reference/en/MONITORING.md) - Monitoring setup and Grafana dashboards
- [SECURITY.md](docs/reference/en/SECURITY.md) - Security policies and practices

Day 15 documentation (current):
- [Quality Assessment & Fine-tuning Guide](docs/day15/README.md)
- [API Documentation](docs/day15/api.md)
- [Migration from Day 12](docs/day15/MIGRATION_FROM_DAY12.md)

Day 12 documentation:
- [PDF Digest User Guide](docs/day12/USER_GUIDE.md)
- [PDF Digest API](docs/day12/api.md)
- [PDF Digest Architecture](docs/day12/ARCHITECTURE.md)

See [docs/INDEX.md](docs/INDEX.md) for complete documentation index.

## Monitoring

```bash
# Start monitoring stack (Prometheus + Grafana)
docker-compose -f docker-compose.butler.yml up -d prometheus grafana

# Access Grafana: http://localhost:3000 (admin/admin)
# Access Prometheus: http://localhost:9090
```

Available dashboards:
1. **App Health** - System resources, HTTP metrics, latency, availability
2. **ML Service Metrics** - LLM inference latency, token usage, model versioning
3. **Post Fetcher & PDF Metrics** - Post collection and PDF generation metrics
4. **Quality Assessment Metrics** - Evaluation scores, fine-tuning runs, dataset growth

See [MONITORING.md](docs/reference/en/MONITORING.md) for detailed setup.

## Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

**Key Guidelines:**
- Follow PEP 8 and Zen of Python
- Functions max 15 lines where possible
- 100% type hints coverage
- 80%+ test coverage
- Document all changes

## License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Note**: This is a learning project exploring AI and language models. Use responsibly and in accordance with applicable terms of service.
