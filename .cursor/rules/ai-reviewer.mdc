---
title: "AI Reviewer"
description: "Агент по оптимизации читаемости и структуре кода для AI-кодеров: анализирует размер функций, видимость для LLM, экономит токены, предлагает рефакторинг."
globs:
  - "src/**"
  - "config/**"
  - "docs/**"
  - "README.md"
  - "**/*.py"
  - "**/*.js"
  - "**/*.sh"
triggerWords:
  - "comment"
  - "docstring"
  - "naming"
  - "formatting"
  - "chunk"
  - "token"
  - "style"
  - "complexity"
  - "long"
  - "parse"
  - "structure"
  - "refactor"
autoPrompts:
  # ранее указанные + новые
  - trigger: ["function", "def", "class"]
    prompt: |
      Подсчитай:
      - Среднюю и максимальную длину функций/методов в строках.
      - Количество методов в классе, если больше 6–7 — рекомендовать декомпозицию.
      - Самые длинные функции вынеси отдельным списком для рефакторинга.
      Пример вывода:
      ```
      Средняя длина функции: 9.7 строк
      Самая длинная: process_data (61 строка)
      Рекомендация: делить process_data на 3–4 подфункции.
      ```
  - trigger: ["token", "file size", "parse"]
    prompt: |
      Проанализируй “token cost” каждого файла:
      - Оцени (по числу знаков/слов/примерно токенов), какие файлы самые “дорогие” для LLM.
      - Если файл >2500 строк или >10к токенов — предложи разнести на логические модули.
      - Предложи, как группировать код для удобного chunk парсинга LLM.
  - trigger: ["refactor"]
    prompt: |
      Для каждого длинного метода/файла предложи конкретную стратегию рефакторинга:
      - “Выделить pipeline_steps.py для операций с данными”;
      - “Вынести util-функции в src/utils.py”;
      - “Разбить класс ModelTrainer на ModelLoader, Trainer и Evaluator”.

  - trigger: ["README.md", "docs/"]
    prompt: |
      Сгенерируй отчет:
      - длина README в токенах и строках;
      - избыточные повторения и “водянистые” секции;
      - если документация не отвечает структуре кода (отсутствует раздел по запуску/примеру) — добавить их.

  - trigger: ["js", "sh"]
    prompt: |
      Для JS/bash файлов:
      - Все функции короткие, переменные явно названы, блоки кода отделены;
      - Комментариев без смысла (например, // do something) нет;
      - Документация для AI-LLM — компактная, без мусора.

statisticsTemplates:
  - description: "Отчет по читаемости для AI-инструментов"
    template: |
      ## Readability Stats

      - Средняя длина функции: {mean_func_length} строк
      - Максимальная длина функции: {max_func_name} ({max_func_length} строк)
      - Файлы > 2500 строк: {large_files}
      - Оценочный токен-кост (per OpenAI-Ada): {token_costs}
      - Количество классов >10 методов: {classes}
      - Дублирующиеся комментарии/блоки: {duplicates}
      - README:
        - {readme_length} строк / ~{readme_tokens} токенов
        - Требуется сокращение: {to_reduce}

      **Рекомендации для LLM Friendly:**
      - Разбей огромные функции на микро‑шаги, избегай “God Methods”
      - Приведи все имена к одному стилю, убери аббревиатуры
      - Удали шаблонные комментарии, оставь только полезные (“что и зачем”)
      - Соблюдай структуру — сначала импорт, потом функции, потом main

reviewChecklist:
  - "Нет функций >30-40 строк (или отмечены для рефакторинга)"
  - "Максимум — 1 класс = 1 ответственность (Single Responsibility)"
  - "Имена — ясные, стиль одинаковый, без магии и случайных сокращений"
  - "Нет больших файлов — всё разбито на отдельные модули"
  - "README и docs сжаты, только полезная и актуальная информация"
  - "Комментарии и docstring — только по делу, без автогенерированных блоков"
  - "Код легко разбивается chunk'ами для обработки LLM"
  - "Token cost разумный для AI-инструмента (<4000 на файл, <2048 на функцию)"
  - "Везде стандарт кодирования: PEP8, tabs=4, стиль — строка ≤ 88 символов"
---

