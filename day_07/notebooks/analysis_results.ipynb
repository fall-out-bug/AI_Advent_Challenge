{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StarCoder Multi-Agent System - Result Analysis\n",
        "\n",
        "This notebook focuses on analyzing and interpreting results from the StarCoder Multi-Agent System. You'll learn how to:\n",
        "\n",
        "1. Parse and analyze generation results\n",
        "2. Extract insights from code reviews\n",
        "3. Identify patterns in quality metrics\n",
        "4. Create comprehensive reports\n",
        "5. Compare different approaches\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Complete Basic and Advanced tutorials\n",
        "- Results from previous runs\n",
        "- Analysis libraries: `pandas`, `matplotlib`, `seaborn`, `plotly`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import analysis libraries\n",
        "import asyncio\n",
        "import sys\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "from orchestrator import process_simple_task\n",
        "from communication.message_schema import OrchestratorRequest\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Analysis libraries imported successfully!\")\n",
        "print(f\"üìÅ Working directory: {Path.cwd()}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Sample Data for Analysis\n",
        "\n",
        "Let's create a diverse set of tasks to analyze different aspects of code generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define diverse tasks for comprehensive analysis\n",
        "analysis_tasks = [\n",
        "    {\n",
        "        \"category\": \"Algorithms\",\n",
        "        \"description\": \"Implement a quicksort algorithm\",\n",
        "        \"requirements\": [\"Use recursive approach\", \"Include type hints\", \"Handle edge cases\"],\n",
        "        \"expected_complexity\": \"medium\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Data Structures\",\n",
        "        \"description\": \"Create a binary search tree implementation\",\n",
        "        \"requirements\": [\"Include insert, delete, search operations\", \"Add tree traversal methods\", \"Handle balancing\"],\n",
        "        \"expected_complexity\": \"high\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Web Development\",\n",
        "        \"description\": \"Build a REST API endpoint for user authentication\",\n",
        "        \"requirements\": [\"Use FastAPI\", \"Include JWT tokens\", \"Add password hashing\", \"Include validation\"],\n",
        "        \"expected_complexity\": \"medium\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Data Processing\",\n",
        "        \"description\": \"Create a CSV data processor with filtering and aggregation\",\n",
        "        \"requirements\": [\"Use pandas\", \"Handle missing data\", \"Add data validation\", \"Include error handling\"],\n",
        "        \"expected_complexity\": \"medium\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Machine Learning\",\n",
        "        \"description\": \"Implement a simple linear regression model\",\n",
        "        \"requirements\": [\"Use numpy\", \"Include gradient descent\", \"Add model evaluation\", \"Include visualization\"],\n",
        "        \"expected_complexity\": \"high\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Utilities\",\n",
        "        \"description\": \"Create a file organizer that sorts files by type\",\n",
        "        \"requirements\": [\"Use pathlib\", \"Handle different file types\", \"Add logging\", \"Include progress tracking\"],\n",
        "        \"expected_complexity\": \"low\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìù Analyzing {len(analysis_tasks)} diverse tasks:\")\n",
        "for i, task in enumerate(analysis_tasks, 1):\n",
        "    print(f\"   {i}. [{task['category']}] {task['description']}\")\n",
        "\n",
        "# Process all tasks\n",
        "print(\"\\n‚è≥ Processing tasks for analysis...\")\n",
        "results = []\n",
        "\n",
        "for i, task_data in enumerate(analysis_tasks):\n",
        "    print(f\"   Processing task {i+1}/{len(analysis_tasks)}: {task_data['description'][:50]}...\")\n",
        "    \n",
        "    try:\n",
        "        result = await process_simple_task(\n",
        "            task_description=task_data[\"description\"],\n",
        "            language=\"python\",\n",
        "            requirements=task_data[\"requirements\"]\n",
        "        )\n",
        "        \n",
        "        # Add metadata for analysis\n",
        "        if result.success:\n",
        "            result.category = task_data[\"category\"]\n",
        "            result.expected_complexity = task_data[\"expected_complexity\"]\n",
        "            result.task_description = task_data[\"description\"]\n",
        "        \n",
        "        results.append(result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Task {i+1} failed: {e}\")\n",
        "        results.append(None)\n",
        "\n",
        "print(f\"‚úÖ Processing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract data for analysis\n",
        "analysis_data = []\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    if result and result.success:\n",
        "        # Extract code metrics\n",
        "        code = result.generation_result.generated_code\n",
        "        tests = result.generation_result.tests\n",
        "        \n",
        "        # Basic metrics\n",
        "        code_lines = len(code.split('\\n'))\n",
        "        test_lines = len(tests.split('\\n'))\n",
        "        total_lines = code_lines + test_lines\n",
        "        \n",
        "        # Code complexity indicators\n",
        "        function_count = len(re.findall(r'def\\s+\\w+', code))\n",
        "        class_count = len(re.findall(r'class\\s+\\w+', code))\n",
        "        import_count = len(re.findall(r'^(import|from)\\s+', code, re.MULTILINE))\n",
        "        \n",
        "        # Quality metrics\n",
        "        has_docstrings = '\"\"\"' in code or \"'''\" in code\n",
        "        has_type_hints = ': ' in code or ' -> ' in code\n",
        "        has_error_handling = 'try:' in code or 'except' in code\n",
        "        \n",
        "        analysis_data.append({\n",
        "            'category': result.category,\n",
        "            'task_description': result.task_description,\n",
        "            'expected_complexity': result.expected_complexity,\n",
        "            'actual_complexity': result.generation_result.metadata.complexity,\n",
        "            'quality_score': result.review_result.code_quality_score,\n",
        "            'workflow_time': result.workflow_time,\n",
        "            'tokens_used': result.generation_result.tokens_used,\n",
        "            'code_lines': code_lines,\n",
        "            'test_lines': test_lines,\n",
        "            'total_lines': total_lines,\n",
        "            'function_count': function_count,\n",
        "            'class_count': class_count,\n",
        "            'import_count': import_count,\n",
        "            'has_docstrings': has_docstrings,\n",
        "            'has_type_hints': has_type_hints,\n",
        "            'has_error_handling': has_error_handling,\n",
        "            'pep8_score': result.review_result.metrics.get('pep8_score', 0),\n",
        "            'test_coverage': result.review_result.metrics.get('test_coverage', 'unknown'),\n",
        "            'issues_count': len(result.review_result.issues),\n",
        "            'recommendations_count': len(result.review_result.recommendations)\n",
        "        })\n",
        "\n",
        "print(f\"üìä Extracted data for {len(analysis_data)} successful tasks\")\n",
        "print(f\"‚ùå {len(results) - len(analysis_data)} tasks failed\")\n",
        "\n",
        "# Create DataFrame for analysis\n",
        "df = pd.DataFrame(analysis_data)\n",
        "\n",
        "if not df.empty:\n",
        "    print(f\"\\nüìã Analysis Dataset Overview:\")\n",
        "    print(f\"‚Ä¢ Categories: {df['category'].nunique()}\")\n",
        "    print(f\"‚Ä¢ Average quality score: {df['quality_score'].mean():.1f}/10\")\n",
        "    print(f\"‚Ä¢ Average workflow time: {df['workflow_time'].mean():.2f}s\")\n",
        "    print(f\"‚Ä¢ Average lines of code: {df['total_lines'].mean():.0f}\")\n",
        "    print(f\"‚Ä¢ Total tokens used: {df['tokens_used'].sum()}\")\n",
        "else:\n",
        "    print(\"‚ùå No data available for analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive analysis visualizations\n",
        "if not df.empty:\n",
        "    # Create subplots\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=3,\n",
        "        subplot_titles=[\n",
        "            'Quality Score by Category', 'Workflow Time by Category',\n",
        "            'Code Lines by Category', 'Complexity Distribution',\n",
        "            'Quality vs Time', 'Code Metrics',\n",
        "            'PEP8 Scores', 'Token Usage', 'Success Rate by Category'\n",
        "        ],\n",
        "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "               [{\"type\": \"pie\"}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n",
        "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        "    )\n",
        "    \n",
        "    # Quality score by category\n",
        "    quality_by_category = df.groupby('category')['quality_score'].mean().reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=quality_by_category['category'], y=quality_by_category['quality_score'],\n",
        "               name='Quality Score', marker_color='lightblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Workflow time by category\n",
        "    time_by_category = df.groupby('category')['workflow_time'].mean().reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=time_by_category['category'], y=time_by_category['workflow_time'],\n",
        "               name='Workflow Time', marker_color='lightcoral'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # Code lines by category\n",
        "    lines_by_category = df.groupby('category')['total_lines'].mean().reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=lines_by_category['category'], y=lines_by_category['total_lines'],\n",
        "               name='Total Lines', marker_color='lightgreen'),\n",
        "        row=1, col=3\n",
        "    )\n",
        "    \n",
        "    # Complexity distribution\n",
        "    complexity_counts = df['actual_complexity'].value_counts()\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=complexity_counts.index, values=complexity_counts.values,\n",
        "               name='Complexity'),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # Quality vs Time scatter\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=df['workflow_time'], y=df['quality_score'],\n",
        "                   mode='markers', name='Quality vs Time',\n",
        "                   text=df['category'], marker=dict(size=10, color=df['tokens_used'],\n",
        "                   colorscale='Viridis', showscale=True)),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    # Code metrics\n",
        "    metrics_data = [\n",
        "        df['has_docstrings'].sum(),\n",
        "        df['has_type_hints'].sum(),\n",
        "        df['has_error_handling'].sum()\n",
        "    ]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=['Docstrings', 'Type Hints', 'Error Handling'], y=metrics_data,\n",
        "               name='Code Features', marker_color='gold'),\n",
        "        row=2, col=3\n",
        "    )\n",
        "    \n",
        "    # PEP8 scores\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df['category'], y=df['pep8_score'],\n",
        "               name='PEP8 Score', marker_color='purple'),\n",
        "        row=3, col=1\n",
        "    )\n",
        "    \n",
        "    # Token usage\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df['category'], y=df['tokens_used'],\n",
        "               name='Token Usage', marker_color='orange'),\n",
        "        row=3, col=2\n",
        "    )\n",
        "    \n",
        "    # Success rate by category (assuming all tasks in df succeeded)\n",
        "    success_by_category = df.groupby('category').size().reset_index(name='count')\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=success_by_category['category'], y=success_by_category['count'],\n",
        "               name='Task Count', marker_color='pink'),\n",
        "        row=3, col=3\n",
        "    )\n",
        "    \n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=\"Comprehensive Code Generation Analysis\",\n",
        "        title_x=0.5,\n",
        "        height=1200,\n",
        "        showlegend=False\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Display summary statistics\n",
        "    print(\"\\nüìä Summary Statistics:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"‚Ä¢ Average Quality Score: {df['quality_score'].mean():.2f} ¬± {df['quality_score'].std():.2f}\")\n",
        "    print(f\"‚Ä¢ Average Workflow Time: {df['workflow_time'].mean():.2f}s ¬± {df['workflow_time'].std():.2f}s\")\n",
        "    print(f\"‚Ä¢ Average Code Lines: {df['total_lines'].mean():.0f} ¬± {df['total_lines'].std():.0f}\")\n",
        "    print(f\"‚Ä¢ Average Functions: {df['function_count'].mean():.1f} ¬± {df['function_count'].std():.1f}\")\n",
        "    print(f\"‚Ä¢ Average Classes: {df['class_count'].mean():.1f} ¬± {df['class_count'].std():.1f}\")\n",
        "    print(f\"‚Ä¢ Docstring Coverage: {df['has_docstrings'].mean()*100:.1f}%\")\n",
        "    print(f\"‚Ä¢ Type Hint Coverage: {df['has_type_hints'].mean()*100:.1f}%\")\n",
        "    print(f\"‚Ä¢ Error Handling Coverage: {df['has_error_handling'].mean()*100:.1f}%\")\n",
        "else:\n",
        "    print(\"‚ùå No data available for visualization\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
