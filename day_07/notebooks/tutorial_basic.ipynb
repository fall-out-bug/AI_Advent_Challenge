{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StarCoder Multi-Agent System - Basic Tutorial\n",
        "\n",
        "This notebook provides a hands-on introduction to the StarCoder Multi-Agent System. You'll learn how to:\n",
        "\n",
        "1. Set up and start the system\n",
        "2. Generate Python code using AI agents\n",
        "3. Review and analyze generated code\n",
        "4. Understand the workflow and results\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, make sure you have:\n",
        "\n",
        "- Docker and Docker Compose installed\n",
        "- NVIDIA GPU with CUDA support\n",
        "- Python 3.11+ with required packages\n",
        "- StarCoder model running locally\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. **Start StarCoder Service:**\n",
        "   ```bash\n",
        "   cd ../local_models\n",
        "   docker-compose up -d starcoder-chat\n",
        "   ```\n",
        "\n",
        "2. **Start Agent Services:**\n",
        "   ```bash\n",
        "   cd ../day_07\n",
        "   docker-compose up -d\n",
        "   ```\n",
        "\n",
        "3. **Verify Services:**\n",
        "   ```bash\n",
        "   make health\n",
        "   ```\n",
        "\n",
        "Let's begin!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import asyncio\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "from orchestrator import process_simple_task\n",
        "from communication.message_schema import OrchestratorRequest\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üìÅ Working directory: {Path.cwd()}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Basic Code Generation\n",
        "\n",
        "Let's start with a simple example - generating a function to calculate Fibonacci numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our first task\n",
        "task_description = \"Create a function to calculate the nth Fibonacci number\"\n",
        "\n",
        "print(f\"üìù Task: {task_description}\")\n",
        "print(\"‚è≥ Generating code...\")\n",
        "\n",
        "# Process the task\n",
        "result = await process_simple_task(\n",
        "    task_description=task_description,\n",
        "    language=\"python\",\n",
        "    requirements=[\"Include type hints\", \"Handle edge cases\"]\n",
        ")\n",
        "\n",
        "if result.success:\n",
        "    print(\"‚úÖ Code generated successfully!\")\n",
        "    print(f\"‚è±Ô∏è  Workflow time: {result.workflow_time:.2f}s\")\n",
        "    print(f\"üìä Code quality score: {result.review_result.code_quality_score}/10\")\n",
        "else:\n",
        "    print(f\"‚ùå Task failed: {result.error_message}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the generated code\n",
        "if result.success:\n",
        "    print(\"üìÑ Generated Code:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(result.generation_result.generated_code)\n",
        "    \n",
        "    print(\"\\nüß™ Generated Tests:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(result.generation_result.tests)\n",
        "    \n",
        "    print(\"\\nüìä Metadata:\")\n",
        "    print(\"=\" * 50)\n",
        "    metadata = result.generation_result.metadata\n",
        "    print(f\"‚Ä¢ Complexity: {metadata.complexity}\")\n",
        "    print(f\"‚Ä¢ Lines of code: {metadata.lines_of_code}\")\n",
        "    print(f\"‚Ä¢ Estimated time: {metadata.estimated_time}\")\n",
        "    print(f\"‚Ä¢ Dependencies: {', '.join(metadata.dependencies)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display review results\n",
        "if result.success:\n",
        "    print(\"üîç Code Review Results:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Overall Quality Score: {result.review_result.code_quality_score}/10\")\n",
        "    \n",
        "    print(\"\\nüìä Detailed Metrics:\")\n",
        "    metrics = result.review_result.metrics\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"‚Ä¢ {key}: {value}\")\n",
        "    \n",
        "    print(\"\\n‚ö†Ô∏è  Issues Found:\")\n",
        "    for issue in result.review_result.issues:\n",
        "        print(f\"‚Ä¢ {issue}\")\n",
        "    \n",
        "    print(\"\\nüí° Recommendations:\")\n",
        "    for rec in result.review_result.recommendations:\n",
        "        print(f\"‚Ä¢ {rec}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Testing Generated Code\n",
        "\n",
        "Let's test the generated code to make sure it works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the generated code\n",
        "if result.success:\n",
        "    # Extract and execute the generated function\n",
        "    exec(result.generation_result.generated_code)\n",
        "    \n",
        "    # Test the function\n",
        "    print(\"üß™ Testing the generated function:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Test cases\n",
        "    test_cases = [0, 1, 5, 10, 15]\n",
        "    \n",
        "    for n in test_cases:\n",
        "        try:\n",
        "            fib_result = fibonacci(n)\n",
        "            print(f\"fibonacci({n}) = {fib_result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"fibonacci({n}) = Error: {e}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Function executed successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot test - code generation failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Custom Requirements\n",
        "\n",
        "Now let's try a more complex task with specific requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a more complex task\n",
        "complex_task = \"Create a REST API client for a weather service\"\n",
        "\n",
        "requirements = [\n",
        "    \"Use httpx library for HTTP requests\",\n",
        "    \"Implement exponential backoff for retries\",\n",
        "    \"Add proper error handling for HTTP errors\",\n",
        "    \"Include type hints for all functions\",\n",
        "    \"Add logging for debugging\",\n",
        "    \"Handle rate limiting gracefully\",\n",
        "    \"Return structured data (Pydantic models)\"\n",
        "]\n",
        "\n",
        "print(f\"üìù Complex Task: {complex_task}\")\n",
        "print(\"\\nüìã Requirements:\")\n",
        "for i, req in enumerate(requirements, 1):\n",
        "    print(f\"   {i}. {req}\")\n",
        "\n",
        "print(\"\\n‚è≥ Generating code...\")\n",
        "\n",
        "# Process the complex task\n",
        "complex_result = await process_simple_task(\n",
        "    task_description=complex_task,\n",
        "    language=\"python\",\n",
        "    requirements=requirements\n",
        ")\n",
        "\n",
        "if complex_result.success:\n",
        "    print(\"‚úÖ Complex code generated successfully!\")\n",
        "    print(f\"‚è±Ô∏è  Workflow time: {complex_result.workflow_time:.2f}s\")\n",
        "    print(f\"üìä Code quality score: {complex_result.review_result.code_quality_score}/10\")\n",
        "else:\n",
        "    print(f\"‚ùå Complex task failed: {complex_result.error_message}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the complex generated code\n",
        "if complex_result.success:\n",
        "    print(\"üìÑ Generated Complex Code:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(complex_result.generation_result.generated_code)\n",
        "    \n",
        "    print(\"\\nüß™ Generated Tests:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(complex_result.generation_result.tests)\n",
        "    \n",
        "    print(\"\\nüìä Complex Code Metadata:\")\n",
        "    print(\"=\" * 50)\n",
        "    metadata = complex_result.generation_result.metadata\n",
        "    print(f\"‚Ä¢ Complexity: {metadata.complexity}\")\n",
        "    print(f\"‚Ä¢ Lines of code: {metadata.lines_of_code}\")\n",
        "    print(f\"‚Ä¢ Estimated time: {metadata.estimated_time}\")\n",
        "    print(f\"‚Ä¢ Dependencies: {', '.join(metadata.dependencies)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Performance Analysis\n",
        "\n",
        "Let's analyze the performance of our code generation tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create performance comparison\n",
        "if result.success and complex_result.success:\n",
        "    # Prepare data for visualization\n",
        "    tasks_data = [\n",
        "        {\n",
        "            \"Task\": \"Simple Fibonacci\",\n",
        "            \"Workflow Time\": result.workflow_time,\n",
        "            \"Quality Score\": result.review_result.code_quality_score,\n",
        "            \"Lines of Code\": result.generation_result.metadata.lines_of_code,\n",
        "            \"Complexity\": result.generation_result.metadata.complexity\n",
        "        },\n",
        "        {\n",
        "            \"Task\": \"Complex Weather API\",\n",
        "            \"Workflow Time\": complex_result.workflow_time,\n",
        "            \"Quality Score\": complex_result.review_result.code_quality_score,\n",
        "            \"Lines of Code\": complex_result.generation_result.metadata.lines_of_code,\n",
        "            \"Complexity\": complex_result.generation_result.metadata.complexity\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    df = pd.DataFrame(tasks_data)\n",
        "    \n",
        "    print(\"üìä Performance Comparison:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Create visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    fig.suptitle('Code Generation Performance Analysis', fontsize=16)\n",
        "    \n",
        "    # Workflow time comparison\n",
        "    axes[0, 0].bar(df['Task'], df['Workflow Time'], color=['skyblue', 'lightcoral'])\n",
        "    axes[0, 0].set_title('Workflow Time (seconds)')\n",
        "    axes[0, 0].set_ylabel('Time (s)')\n",
        "    \n",
        "    # Quality score comparison\n",
        "    axes[0, 1].bar(df['Task'], df['Quality Score'], color=['lightgreen', 'gold'])\n",
        "    axes[0, 1].set_title('Code Quality Score')\n",
        "    axes[0, 1].set_ylabel('Score (/10)')\n",
        "    axes[0, 1].set_ylim(0, 10)\n",
        "    \n",
        "    # Lines of code comparison\n",
        "    axes[1, 0].bar(df['Task'], df['Lines of Code'], color=['plum', 'orange'])\n",
        "    axes[1, 0].set_title('Lines of Code Generated')\n",
        "    axes[1, 0].set_ylabel('Lines')\n",
        "    \n",
        "    # Complexity comparison\n",
        "    complexity_map = {'low': 1, 'medium': 2, 'high': 3}\n",
        "    df['Complexity Numeric'] = df['Complexity'].map(complexity_map)\n",
        "    axes[1, 1].bar(df['Task'], df['Complexity Numeric'], color=['lightblue', 'darkblue'])\n",
        "    axes[1, 1].set_title('Code Complexity')\n",
        "    axes[1, 1].set_ylabel('Complexity Level')\n",
        "    axes[1, 1].set_yticks([1, 2, 3])\n",
        "    axes[1, 1].set_yticklabels(['Low', 'Medium', 'High'])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüìà Key Insights:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"‚Ä¢ Simple task completed in {result.workflow_time:.2f}s\")\n",
        "    print(f\"‚Ä¢ Complex task completed in {complex_result.workflow_time:.2f}s\")\n",
        "    print(f\"‚Ä¢ Quality scores: {result.review_result.code_quality_score:.1f} vs {complex_result.review_result.code_quality_score:.1f}\")\n",
        "    print(f\"‚Ä¢ Code complexity: {result.generation_result.metadata.complexity} vs {complex_result.generation_result.metadata.complexity}\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot analyze - some tasks failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to JSON file\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_file = f\"tutorial_basic_results_{timestamp}.json\"\n",
        "\n",
        "results_data = {\n",
        "    \"timestamp\": timestamp,\n",
        "    \"simple_task\": {\n",
        "        \"description\": task_description,\n",
        "        \"success\": result.success,\n",
        "        \"workflow_time\": result.workflow_time if result.success else 0,\n",
        "        \"quality_score\": result.review_result.code_quality_score if result.success else 0,\n",
        "        \"generated_code\": result.generation_result.generated_code if result.success else None,\n",
        "        \"tests\": result.generation_result.tests if result.success else None,\n",
        "        \"metadata\": result.generation_result.metadata.__dict__ if result.success else None\n",
        "    },\n",
        "    \"complex_task\": {\n",
        "        \"description\": complex_task,\n",
        "        \"requirements\": requirements,\n",
        "        \"success\": complex_result.success,\n",
        "        \"workflow_time\": complex_result.workflow_time if complex_result.success else 0,\n",
        "        \"quality_score\": complex_result.review_result.code_quality_score if complex_result.success else 0,\n",
        "        \"generated_code\": complex_result.generation_result.generated_code if complex_result.success else None,\n",
        "        \"tests\": complex_result.generation_result.tests if complex_result.success else None,\n",
        "        \"metadata\": complex_result.generation_result.metadata.__dict__ if complex_result.success else None\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(results_file, 'w') as f:\n",
        "    json.dump(results_data, f, indent=2, default=str)\n",
        "\n",
        "print(f\"üíæ Results saved to: {results_file}\")\n",
        "print(f\"üìÅ File size: {Path(results_file).stat().st_size} bytes\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nüìã Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚Ä¢ Simple task: {'‚úÖ Success' if result.success else '‚ùå Failed'}\")\n",
        "print(f\"‚Ä¢ Complex task: {'‚úÖ Success' if complex_result.success else '‚ùå Failed'}\")\n",
        "print(f\"‚Ä¢ Total workflow time: {(result.workflow_time if result.success else 0) + (complex_result.workflow_time if complex_result.success else 0):.2f}s\")\n",
        "print(f\"‚Ä¢ Average quality score: {((result.review_result.code_quality_score if result.success else 0) + (complex_result.review_result.code_quality_score if complex_result.success else 0)) / 2:.1f}/10\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
