#!/usr/bin/env python3
"""
–¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π —á–∞—Ç v4: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π, —Ä–µ–∂–∏–º ¬´–æ–±—ä—è—Å–Ω—è–π¬ª,
–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –∏ —Ä–µ–∂–∏–º ¬´–¥–∞–π —Å–æ–≤–µ—Ç¬ª.

–ö–æ–º–∞–Ω–¥—ã:
- temp <value>      ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: temp 0.7)
- –æ–±—ä—è—Å–Ω—è–π          ‚Äî –≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π (–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –∏ –º–æ–¥–µ–ª—å)
- –Ω–∞–¥–æ–µ–ª            ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π
- –¥–∞–π —Å–æ–≤–µ—Ç         ‚Äî –≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Å–æ–≤–µ—Ç—á–∏–∫–∞
- —Å—Ç–æ–ø —Å–æ–≤–µ—Ç        ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Å–æ–≤–µ—Ç—á–∏–∫–∞
- –ø–æ–∫–µ–¥–∞            ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
"""
import asyncio
import sys
import os
import unicodedata
import shutil
import textwrap
import time
import httpx

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import get_api_key, is_api_key_configured
from day_04.advice_mode import AdviceMode
from day_04.temperature_utils import resolve_effective_temperature, clamp_temperature


API_URL = "https://api.perplexity.ai/chat/completions"
MODEL = "sonar-pro"
CHAD_URL = 'https://ask.chadgpt.ru/api/public/gpt-5-mini'


def _contains_any(haystack: str, needles: list[str]) -> bool:
	s = haystack.lower()
	return any(n in s for n in needles)


def _normalize_for_trigger(text: str) -> str:
	"""
	Purpose: Normalize unicode and punctuation to improve trigger matching.
	"""
	if not text:
		return ""
	# Unicode normalize and lower
	norm = unicodedata.normalize('NFKC', text).lower()
	# Replace common separators with space
	for ch in ["\u2013", "\u2014", "-", "_", "|", ",", ".", "!", "?", "\u00A0", "\u2019", "\u2018", "\u201c", "\u201d", "\"", "'", ":", ";", "(", ")", "[", "]", "{" , "}"]:
		norm = norm.replace(ch, " ")
	# Collapse spaces
	norm = " ".join(norm.split())
	return norm


class DedChatV4:
	"""
	Purpose: Terminal chat with temperature control, interactive switching and experiment runner.
	"""

	def __init__(self):
		self.api_key = None
		self.client = None
		self.default_temperature = 0.7
		self.explain_mode = False
		self.current_api = None  # "chadgpt" or "perplexity"
		self._system_prompt = "–¢—ã –ø–æ–∂–∏–ª–æ–π —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –µ—Ö–∏–¥–Ω–æ –ø–æ–¥—à—É—á–∏–≤–∞–µ—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –ª–∞–∫–æ–Ω–∏—á–Ω–æ, –±–µ–∑ —Å—Å—ã–ª–æ–∫."
		self.advice_mode: AdviceMode | None = None

	async def __aenter__(self):
		self.client = httpx.AsyncClient(timeout=30.0)
		return self

	async def __aexit__(self, exc_type, exc_val, exc_tb):
		if self.client:
			await self.client.aclose()

	def setup(self) -> bool:
		"""
		Purpose: Ensure Perplexity API key is configured.
		Returns:
			bool: True if configured
		"""
		# Prefer ChadGPT as primary API if configured
		if is_api_key_configured("chadgpt"):
			self.current_api = "chadgpt"
			self.api_key = get_api_key("chadgpt")
			return True
		# Fallback to Perplexity
		if is_api_key_configured("perplexity"):
			self.current_api = "perplexity"
			self.api_key = get_api_key("perplexity")
			return True
		print("‚ùå –ù–∏ –æ–¥–∏–Ω API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CHAD_API_KEY –∏–ª–∏ PERPLEXITY_API_KEY")
		return False

	def print_welcome(self) -> None:
		"""
		Purpose: Print welcome and help.
		"""
		print("üë¥" + "=" * 60)
		print("üë¥  –î–ï–î–£–®–ö–ê AI v4 ‚Äî –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –ü–æ—è—Å–Ω—è–π –∏ –°–æ–≤–µ—Ç—á–∏–∫")
		print("üë¥" + "=" * 60)
		print("üë£ –ö–∞–∫ –æ–±—â–∞—Ç—å—Å—è:")
		print("  ‚Ä¢ –ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã. –Ø –æ—Ç–≤–µ—á—É –µ—Ö–∏–¥–Ω–æ –∏ –ø–æ –¥–µ–ª—É.")
		print("  ‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: –Ω–∏–∂–µ ‚Äî —Ç–æ—á–Ω–µ–µ, –≤—ã—à–µ ‚Äî —Å–º–µ–ª–µ–µ.")
		print()
		print("üîß –ö–æ–º–∞–Ω–¥—ã:")
		print("  ‚Ä¢ temp <value>         ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (0.0‚Äì1.5)")
		print("  ‚Ä¢ –æ–±—ä—è—Å–Ω—è–π             ‚Äî –≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π (–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å T –∏ –º–æ–¥–µ–ª—å)")
		print("  ‚Ä¢ –Ω–∞–¥–æ–µ–ª               ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏—è –∏/–∏–ª–∏ —Å–æ–≤–µ—Ç—á–∏–∫–∞")
		print("  ‚Ä¢ –¥–∞–π —Å–æ–≤–µ—Ç            ‚Äî –≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Å–æ–≤–µ—Ç—á–∏–∫–∞")
		print("  ‚Ä¢ –ø–æ–∫–µ–¥–∞               ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä")
		print("  ‚Ä¢ api chadgpt|perplexity ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ API")
		print()
		print("üì¶ –¢—Ä–∏–≥–≥–µ—Ä—ã –∞–≤—Ç–æ‚Äë—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (–ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–≤–µ—Ç–∞):")
		print("  ‚Ä¢ ‚Äò–Ω–µ –¥—É—à–Ω–∏‚Äô ‚Üí T=0.0   ‚Ä¢ ‚Äò–ø–æ—Ç–∏—à–µ‚Äô ‚Üí T=0.7   ‚Ä¢ ‚Äò—Ä–∞–∑–≥–æ–Ω—è–π‚Äô ‚Üí T=1.2")
		print()

	async def call_perplexity(self, message: str, temperature: float, system_prompt: str | None = None) -> str:
		"""
		Purpose: Call Perplexity chat completion with given temperature.
		Args:
			message: User prompt
			temperature: Effective temperature
		Returns:
			str: Model reply
		Exceptions:
			Returns error string on non-200 or malformed response
		Example:
			await call_perplexity("–ü—Ä–∏–≤–µ—Ç", 0.7)
		"""
		payload = {
			"model": MODEL,
			"messages": [
				{"role": "system", "content": (system_prompt or self._system_prompt)},
				{"role": "user", "content": message}
			],
			"max_tokens": 800,
			"temperature": temperature
		}
		try:
			r = await self.client.post(
				API_URL,
				headers={
					"Authorization": f"Bearer {self.api_key}",
					"Content-Type": "application/json"
				},
				json=payload
			)
			if r.status_code != 200:
				# include snippet of error body for diagnostics
				body = r.text
				preview = body[:240].replace("\n", " ") if body else ""
				return f"‚ùå –û—à–∏–±–∫–∞ API Perplexity: {r.status_code} {preview}"
			data = r.json()
			if "choices" not in data or not data["choices"]:
				return "‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API Perplexity"
			return data["choices"][0]["message"]["content"].strip()
		except Exception as e:
			return f"‚ùå –û—à–∏–±–∫–∞ Perplexity: {e}"

	async def call_chadgpt(self, message: str, temperature: float, system_prompt: str | None = None) -> str:
		"""
		Purpose: Call ChadGPT API. Temperature is not supported by API; retained for display.
		Args:
			message: User message
			temperature: Effective temperature (display only)
		Returns:
			str: Model reply
		"""
		# Pass a composed prompt without history in normal conversation
		prompt_text = f"{(system_prompt or self._system_prompt)}\n\n–í–æ–ø—Ä–æ—Å: {message}"
		request_json = {
			"message": prompt_text,
			"api_key": self.api_key,
			"temperature": float(f"{temperature:.2f}"),
			"max_tokens": 800
		}
		try:
			async with httpx.AsyncClient(timeout=30.0) as client:
				resp = await client.post(CHAD_URL, json=request_json)
				if resp.status_code != 200:
					return f"‚ùå –û—à–∏–±–∫–∞ API: {resp.status_code}"
				data = resp.json()
				# Expected format from day_03 code: {'is_success': bool, 'response': str}
				if data.get('is_success') and isinstance(data.get('response'), str):
					return data['response'].strip()
				return "‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
		except Exception as e:
			return f"‚ùå –û—à–∏–±–∫–∞: {e}"

	async def call_model(self, message: str, temperature: float, system_prompt: str | None = None) -> str:
		"""
		Purpose: Route call to current API (chadgpt/perplexity).
		"""
		if self.current_api == "chadgpt":
			return await self.call_chadgpt(message, temperature, system_prompt)
		return await self.call_perplexity(message, temperature, system_prompt)

	def parse_temp_override(self, user_message: str):
		"""
		Purpose: Parse one-off override in 'temp=<v> <text>'.
		Args:
			user_message: Raw input
		Returns:
			(override: float|None, clean_text: str)
		"""
		msg = user_message.strip()
		if not msg.lower().startswith("temp="):
			return None, msg
		try:
			head, rest = msg.split(maxsplit=1)
		except ValueError:
			head, rest = msg, ""
		try:
			override = float(head.split("=", 1)[1])
			override = clamp_temperature(override)
		except Exception as e:
			print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç temp=<value>: {e}")
			return None, rest.strip()
		return override, rest.strip()

	def apply_interactive_temperature(self, reply_text: str) -> None:
		"""
		Purpose: Adjust default_temperature based on reply content.
		Rules:
			- contains "–Ω–µ –¥—É—à–Ω–∏" -> 0.0
			- contains "—Ä–∞–∑–≥–æ–Ω—è–π" -> 1.2
			- contains "–ø–æ—Ç–∏—à–µ"   -> 0.7
		"""
		txt = _normalize_for_trigger(reply_text)
		if "–Ω–µ –¥—É—à–Ω–∏" in txt:
			self.default_temperature = clamp_temperature(0.0)
			print("üîß –ê–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ: —Ç–µ–º–ø. = 0.0 (–ø–æ —Ñ—Ä–∞–∑–µ '–Ω–µ –¥—É—à–Ω–∏')\n")
		elif "—Ä–∞–∑–≥–æ–Ω—è–π" in txt:
			self.default_temperature = clamp_temperature(1.2)
			print("üîß –ê–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ: —Ç–µ–º–ø. = 1.2 (–ø–æ —Ñ—Ä–∞–∑–µ '—Ä–∞–∑–≥–æ–Ω—è–π')\n")
		elif "–ø–æ—Ç–∏—à–µ" in txt:
			self.default_temperature = clamp_temperature(0.7)
			print("üîß –ê–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ: —Ç–µ–º–ø. = 0.7 (–ø–æ —Ñ—Ä–∞–∑–µ '–ø–æ—Ç–∏—à–µ')\n")

    # experiment feature removed per request

	def print_ded_message(self, message: str, eff_temp: float | None = None) -> None:
		"""
		Purpose: Pretty-print model message with optional T-indicator.
		In explain_mode, temperature is always shown.
		Args:
			message: Text to print
			eff_temp: Effective temperature indicator
		"""
		# Better readability: wrap to terminal width and add spacing, show model
		width = shutil.get_terminal_size((100, 20)).columns
		prefix = "üë¥ –î–µ–¥—É—à–∫–∞"
		model_label = self.get_model_label()
		if self.explain_mode:
			t = eff_temp if eff_temp is not None else self.default_temperature
			prefix = f"{prefix} [T={t:.2f} ‚Ä¢ {model_label}]"
		suffix = ""
		if not self.explain_mode:
			# In normal mode, do not show temperature or model
			suffix = ""
		wrapped = textwrap.fill(f"{prefix}: {message}{suffix}", width=width)
		print(wrapped)
		print()

	def get_model_label(self) -> str:
		"""
		Purpose: Human-readable model label for indicators.
		"""
		if self.current_api == "chadgpt":
			return "chadgpt:gpt-5-mini"
		return f"perplexity:{MODEL}"

	def get_api_endpoint(self) -> str:
		"""
		Purpose: Return API endpoint URL for current provider.
		"""
		return CHAD_URL if self.current_api == "chadgpt" else API_URL

	def print_debug_info(self, user_message: str, reply: str, eff_temp: float, sys_prompt: str | None, duration_ms: int) -> None:
		"""
		Purpose: Print extended debug info in explain mode.
		"""
		if not self.explain_mode:
			return
		width = shutil.get_terminal_size((100, 20)).columns
		model_label = self.get_model_label()
		endpoint = self.get_api_endpoint()
		mode = "advice" if sys_prompt else "normal"
		prompt_preview = (sys_prompt or self._system_prompt)[:120].replace("\n", " ")
		lines = [
			"üîç Debug:",
			f"  api: {self.current_api}",
			f"  endpoint: {endpoint}",
			f"  model: {model_label}",
			f"  temperature: {eff_temp:.2f}",
			f"  mode: {mode}",
			f"  prompt(sys)‚âà: {prompt_preview}",
			f"  req_len: {len(user_message)} chars",
			f"  resp_len: {len(reply)} chars",
			f"  time: {duration_ms} ms",
		]
		print(textwrap.fill("\n".join(lines), width=width))
		print()

	def get_user_input(self) -> str:
		"""
		Purpose: Read user input with temperature indicator.
		Returns:
			str: Raw input
		"""
		try:
			t = f"{self.default_temperature:.2f}"
			mode = " [–ü–û–Ø–°–ù–Ø–ô]" if self.explain_mode else ""
			model_label = self.get_model_label()
			return input(f"ü§î –í—ã{mode} [T={t} ‚Ä¢ {model_label}]: ").strip()
		except KeyboardInterrupt:
			print("\nüë¥ –î–µ–¥—É—à–∫–∞: –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
			sys.exit(0)
		except EOFError:
			print("\nüë¥ –î–µ–¥—É—à–∫–∞: –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
			sys.exit(0)

	async def run(self):
		"""
		Purpose: Main loop.
		"""
		if not self.setup():
			return
		self.print_welcome()
		# init advice mode helper (idle by default)
		self.advice_mode = AdviceMode(self.api_key, self.current_api)
		welcome = await self.call_model("–ü—Ä–∏–≤–µ—Ç! –î–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –µ—Ö–∏–¥–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ.", self.default_temperature)
		self.print_ded_message(welcome, self.default_temperature)
		self.apply_interactive_temperature(welcome)

		while True:
			user_message = self.get_user_input()
			if not user_message:
				continue

			low = user_message.lower()

			# exit by substring (only "–ø–æ–∫–µ–¥–∞")
			if _contains_any(low, ["–ø–æ–∫–µ–¥–∞"]):
				bye = await self.call_model("–°–∫–∞–∂–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –µ—Ö–∏–¥–Ω–æ–µ –ø—Ä–æ—â–∞–Ω–∏–µ.", self.default_temperature)
				self.print_ded_message(bye, self.default_temperature)
				self.apply_interactive_temperature(bye)
				break

			# API switching: 'api chadgpt' or 'api perplexity'
			if low.startswith("api "):
				new_api = low.split()[1]
				if new_api in ("chadgpt", "perplexity"):
					if not is_api_key_configured(new_api):
						print(f"‚ùå API '{new_api}' –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á.")
						print()
					else:
						self.current_api = new_api
						self.api_key = get_api_key(new_api)
						# Re-init advice mode helper with new API
						self.advice_mode = AdviceMode(self.api_key, self.current_api)
						print(f"üë¥ –î–µ–¥—É—à–∫–∞: –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ {new_api}!")
						print()
				continue

			# explain mode on/off by substring
			if "–æ–±—ä—è—Å–Ω—è–π" in low:
				self.explain_mode = True
				print("üë¥ –î–µ–¥—É—à–∫–∞: –í–∫–ª—é—á–∏–ª —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è).")
				print()
				continue

			if "–Ω–∞–¥–æ–µ–ª" in low:
				# Only turns off explain mode (not advice)
				self.explain_mode = False
				print("üë¥ –î–µ–¥—É—à–∫–∞: –í—ã–∫–ª—é—á–∏–ª —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π.")
				print()
				# do not continue; allow message to be processed below

			# help by substring
			if "–ø–æ–º–æ–≥–∞–π" in low:
				print("üîß –ö–æ–º–∞–Ω–¥—ã:")
				print("  ‚Ä¢ temp <value>         ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (0.0‚Äì1.5)")
				print("  ‚Ä¢ –æ–±—ä—è—Å–Ω—è–π             ‚Äî –≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π (–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å T –∏ –º–æ–¥–µ–ª—å)")
				print("  ‚Ä¢ –Ω–∞–¥–æ–µ–ª               ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ—è—Å–Ω–µ–Ω–∏–π")
				print("  ‚Ä¢ –ø–æ–∫–µ–¥–∞               ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä")
				print("  ‚Ä¢ api chadgpt|perplexity ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ API")
				print()
				print("üì¶ –¢—Ä–∏–≥–≥–µ—Ä—ã –∞–≤—Ç–æ‚Äë—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (–ø–æ —Ç–µ–∫—Å—Ç—É): ‚Äò–Ω–µ –¥—É—à–Ω–∏‚Äô ‚Üí 0.0, ‚Äò–ø–æ—Ç–∏—à–µ‚Äô ‚Üí 0.7, ‚Äò—Ä–∞–∑–≥–æ–Ω—è–π‚Äô ‚Üí 1.2")
				print()
				# continue but do not block sending the same message if it has content
				continue

			if low.startswith("temp "):
				try:
					value = float(user_message.split()[1])
					self.default_temperature = clamp_temperature(value)
					print(f"üë¥ –î–µ–¥—É—à–∫–∞: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {self.default_temperature}")
				except Exception as e:
					print(f"‚ùå {e}")
				print()
				continue

			# experiment command removed

			# Apply temperature triggers from USER message as well
			self.apply_interactive_temperature(user_message)
			# If user message contained any control words, do not forward it to API
			if any(k in low for k in ["–æ–±—ä—è—Å–Ω—è–π", "–Ω–∞–¥–æ–µ–ª", "–ø–æ–º–æ–≥–∞–π"]) or low.startswith("temp "):
				continue

			# Advice mode triggers and routing (from day_03 behavior)
			if "–¥–∞–π —Å–æ–≤–µ—Ç" in low:
				print("üë¥ –î–µ–¥—É—à–∫–∞: –í–∫–ª—é—á–∞—é —Ä–µ–∂–∏–º —Å–æ–≤–µ—Ç—á–∏–∫–∞...")
				print()
				# Prime advice mode with the user message
				print("üë¥ –î–µ–¥—É—à–∫–∞ –ø–µ—á–∞—Ç–∞–µ—Ç...", end="", flush=True)
				reply = await self.advice_mode.handle_advice_request(user_message)
				print("\r" + " " * 30 + "\r", end="")
				self.print_ded_message(rely := reply, self.default_temperature)
				self.apply_interactive_temperature(rely)
				continue


			# unified "–Ω–∞–¥–æ–µ–ª" handled above

			if self.advice_mode and self.advice_mode.is_advice_mode_active():
				print("üë¥ –î–µ–¥—É—à–∫–∞ –ø–µ—á–∞—Ç–∞–µ—Ç...", end="", flush=True)
				reply = await self.advice_mode.handle_advice_request(user_message)
				print("\r" + " " * 30 + "\r", end="")
				self.print_ded_message(rely2 := reply, self.default_temperature)
				self.apply_interactive_temperature(rely2)
				# If advice session ended internally after final advice, continue to next turn
				if not self.advice_mode.is_advice_mode_active():
					print()
				continue

			# per-message temp override removed; always use default_temperature
			eff = self.default_temperature
			print("üë¥ –î–µ–¥—É—à–∫–∞ –ø–µ—á–∞—Ç–∞–µ—Ç...", end="", flush=True)
			start_ts = time.time()
			reply = await self.call_model(user_message, eff)
			duration_ms = int((time.time() - start_ts) * 1000)
			print("\r" + " " * 30 + "\r", end="")
			self.print_ded_message(reply, eff)
			# Debug info (explain mode only)
			self.print_debug_info(user_message, reply, eff, None, duration_ms)
			self.apply_interactive_temperature(reply)


async def main():
	chat = DedChatV4()
	async with chat:
		await chat.run()


if __name__ == "__main__":
	asyncio.run(main())


