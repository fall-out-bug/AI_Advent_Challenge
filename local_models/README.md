# üè† Local Models - –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –û–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π API –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ª—é–±—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.

## üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

- **–ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π API**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- **Docker-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏ —Å –º–æ–¥–µ–ª—è–º–∏
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: –õ–µ–≥–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
- **–ò–∑–æ–ª—è—Ü–∏—è**: –ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö API –∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
local_models/
‚îú‚îÄ‚îÄ chat_api.py          # FastAPI —Å–µ—Ä–≤–µ—Ä –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ docker-compose.yml   # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Docker Compose
‚îú‚îÄ‚îÄ Dockerfile          # –û–±—Ä–∞–∑ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ download_model.py   # –°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
‚îî‚îÄ‚îÄ README.md           # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

```bash
# –ò–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
cd local_models
docker-compose up -d
```

### 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
curl http://localhost:8000/chat  # Qwen
curl http://localhost:8001/chat  # Mistral  
curl http://localhost:8002/chat  # TinyLlama
```

### 3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö

```python
# –í –ª—é–±–æ–º –ø—Ä–æ–µ–∫—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
import httpx

async def call_local_model(model_name: str, messages: list):
    port = {"qwen": 8000, "mistral": 8001, "tinyllama": 8002}[model_name]
    url = f"http://localhost:{port}/chat"
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, json={
            "messages": messages,
            "max_tokens": 500,
            "temperature": 0.7
        })
        return response.json()
```

## ü§ñ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

| –ú–æ–¥–µ–ª—å | –ü–æ—Ä—Ç | RAM | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|------|-----|----------|
| **Qwen-4B** | 8000 | ~8GB | –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã, —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| **Mistral-7B** | 8001 | ~14GB | –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ |
| **TinyLlama-1.1B** | 8002 | ~4GB | –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è, –±—ã—Å—Ç—Ä–∞—è |

## üîß –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### FastAPI –°–µ—Ä–≤–µ—Ä (`chat_api.py`)

- **–ï–¥–∏–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç**: `/chat` –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
- **OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤
- **–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è**: 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏

### Docker –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è

- **–û–±—â–∏–π –∫—ç—à**: –í—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±—â–∏–π volume –¥–ª—è HuggingFace –∫—ç—à–∞
- **GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ NVIDIA GPU
- **–ò–∑–æ–ª—è—Ü–∏—è**: –ö–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ

### –§–æ—Ä–º–∞—Ç—ã –ø—Ä–æ–º–ø—Ç–æ–≤

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏:

- **Mistral**: `<s>[INST] <<SYS>>...<</SYS>>...[/INST]`
- **Qwen**: `<|im_start|>system...<|im_end|>...`
- **TinyLlama**: `<|system|>...<|user|>...<|assistant|>`

## üìä API –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è

### –ó–∞–ø—Ä–æ—Å

```json
POST /chat
{
    "messages": [
        {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"},
        {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}
    ],
    "max_tokens": 500,
    "temperature": 0.7
}
```

### –û—Ç–≤–µ—Ç

```json
{
    "response": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
    "response_tokens": 5,
    "input_tokens": 12,
    "total_tokens": 17
}
```

## üõ†Ô∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

### –ö–æ–º–∞–Ω–¥—ã Docker Compose

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
docker-compose up -d

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π  
docker-compose down

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
docker-compose logs -f

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
docker-compose restart qwen-chat
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
docker-compose ps

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
docker stats

# –õ–æ–≥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
docker-compose logs qwen-chat
```

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

- `MODEL_NAME`: –ò–º—è –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace
- `HF_TOKEN`: –¢–æ–∫–µ–Ω –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–∏–≤–∞—Ç–Ω—ã–º –º–æ–¥–µ–ª—è–º
- `CUDA_VISIBLE_DEVICES`: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

1. –î–æ–±–∞–≤–∏—Ç—å —Å–µ—Ä–≤–∏—Å –≤ `docker-compose.yml`:
```yaml
new-model-chat:
  build: .
  ports:
    - "8003:8000"
  environment:
    - MODEL_NAME=your/model-name
```

2. –û–±–Ω–æ–≤–∏—Ç—å –º–∞–ø–ø–∏–Ω–≥ –ø–æ—Ä—Ç–æ–≤ –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö:
```python
MODEL_PORTS = {
    "qwen": 8000,
    "mistral": 8001, 
    "tinyllama": 8002,
    "new-model": 8003  # –ù–æ–≤—ã–π –ø–æ—Ä—Ç
}
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

```bash
# –¢–µ—Å—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
for port in 8000 8001 8002; do
  echo "Testing port $port..."
  curl -X POST http://localhost:$port/chat \
    -H "Content-Type: application/json" \
    -d '{"messages":[{"role":"user","content":"Hello"}],"max_tokens":10}'
done
```

### –ë–µ–Ω—á–º–∞—Ä–∫–∏

```python
import asyncio
import time
import httpx

async def benchmark_model(model_name: str, num_requests: int = 10):
    port = {"qwen": 8000, "mistral": 8001, "tinyllama": 8002}[model_name]
    url = f"http://localhost:{port}/chat"
    
    start_time = time.time()
    async with httpx.AsyncClient() as client:
        tasks = []
        for _ in range(num_requests):
            task = client.post(url, json={
                "messages": [{"role": "user", "content": "Test message"}],
                "max_tokens": 50
            })
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks)
    
    total_time = time.time() - start_time
    avg_time = total_time / num_requests
    
    print(f"{model_name}: {avg_time:.2f}s per request")
    return avg_time
```

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU:
```bash
nvidia-smi
```

2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–æ–±–æ–¥–Ω—É—é –ø–∞–º—è—Ç—å:
```bash
free -h
```

3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏:
```bash
docker-compose logs model-name
```

### –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã

1. –£–≤–µ–ª–∏—á–∏—Ç—å `max_tokens` –¥–ª—è –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
2. –£–º–µ–Ω—å—à–∏—Ç—å `temperature` –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É GPU: `nvidia-smi`

### –û—à–∏–±–∫–∏ –ø–∞–º—è—Ç–∏

1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (TinyLlama)
2. –£–º–µ–Ω—å—à–∏—Ç—å `max_tokens`
3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

- **–î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏**: TinyLlama (–±—ã—Å—Ç—Ä–æ, –º–∞–ª–æ –ø–∞–º—è—Ç–∏)
- **–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞**: Mistral (–∫–∞—á–µ—Å—Ç–≤–æ/—Å–∫–æ—Ä–æ—Å—Ç—å)
- **–î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤**: Qwen (–±–∞–ª–∞–Ω—Å)

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SSD –¥–ª—è –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π
- –í—ã–¥–µ–ª–∏—Ç–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM (16GB+ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `CUDA_VISIBLE_DEVICES` –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ GPU

## üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤:
- `day_05/` - –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —á–∞—Ç-–±–æ—Ç–æ–º
- –ë—É–¥—É—â–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –º–æ–≥—É—Ç –ª–µ–≥–∫–æ –ø–æ–¥–∫–ª—é—á–∞—Ç—å—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º

### –ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

```python
# –í –ª—é–±–æ–º –ø—Ä–æ–µ–∫—Ç–µ
from local_models.client import LocalModelClient

client = LocalModelClient()
response = await client.chat("qwen", [
    {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}
])
```

---

**üí° –°–æ–≤–µ—Ç**: –≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ –±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞. –î–æ–±–∞–≤–ª—è–π—Ç–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏!
