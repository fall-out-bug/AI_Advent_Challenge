# AI Advent Challenge

[English](README.md) | [Русский](README.ru.md)

> Ежедневные AI-проекты для изучения языковых моделей и мульти-агентных систем

## 🤖 Быстрое понимание для AI-агентов

**Структура репозитория:**
- `local_models/` - Инфраструктура локальных языковых моделей (общий модуль)
- `shared/` - SDK для унифицированной работы с моделями (общий модуль)
- `day_01/` - `day_04/` - Обучающие проекты для изучения основ
- `day_05/`, `day_06/` - Продуктивные проекты с использованием SDK
- `day_07/` - Мульти-агентная система для генерации и ревью кода
- Каждый `day_XX/` - самостоятельный проект с собственными зависимостями и тестами

**Ключевые компоненты:**
- **Локальные модели**: FastAPI серверы в `local_models/` (порты 8000-8002)
- **SDK**: Унифицированный интерфейс для работы с моделями в `shared/`
- **Чат-боты**: Терминальные приложения с AI-взаимодействием
- **Режим советчика**: Структурированный диалог с ограничениями модели
- **Единообразное API**: Команда `api <provider>` для всех моделей
- **Мульти-агентная система**: Специализированные агенты для генерации и ревью кода

**Быстрый старт для агентов:**
1. Изучить `local_models/README.md` - архитектура локальных моделей
2. Выбрать проект `day_XX/` по сложности
3. Запустить `make install && make run` в выбранном проекте

## 📁 Структура проекта

```
AI_Advent_Challenge/
├── .gitignore              # Игнорируемые файлы
├── config.py              # Конфигурация API ключей (общая)
├── api_key.txt.example    # Шаблон для API ключей
├── Makefile              # Команды для настройки проекта
├── README.md             # Этот файл (английский)
├── README.ru.md          # Русская версия
├── AGENTS.md             # Документация AI агентов (английский)
├── AGENTS.ru.md          # Документация AI агентов (русский)
├── AGENTS_QUICK_REFERENCE.md # Быстрая справка (английский)
├── AGENTS_QUICK_REFERENCE.ru.md # Быстрая справка (русский)
├── local_models/         # 🏠 Инфраструктура локальных языковых моделей
│   ├── chat_api.py       # FastAPI сервер для локальных моделей
│   ├── docker-compose.yml # Конфигурация Docker Compose
│   ├── Dockerfile        # Образ для запуска моделей
│   ├── download_model.py # Скрипт для предварительной загрузки
│   └── README.md         # Документация локальных моделей
├── shared/               # 🛠️ SDK для унифицированной работы с моделями
│   ├── config/          # Конфигурация моделей и константы
│   ├── clients/         # Клиенты для работы с моделями
│   ├── exceptions/      # Стандартизированные исключения
│   ├── tests/           # Тесты SDK (покрытие 98.59%)
│   ├── pyproject.toml   # Зависимости SDK
│   └── README.md        # Документация SDK
├── day_01/               # День 1 - Терминальный чат с AI
│   ├── terminal_chat.py  # Основное приложение
│   ├── pyproject.toml    # Зависимости Poetry
│   ├── .venv/           # Виртуальное окружение Poetry
│   ├── Makefile         # Команды для разработки
│   └── README.md        # Документация проекта
├── day_02/               # День 2 - Улучшенный чат с JSON-ответами
│   ├── terminal_chat_v2.py # Улучшенное приложение
│   ├── pyproject.toml    # Зависимости Poetry
│   ├── .venv/           # Виртуальное окружение Poetry
│   ├── Makefile         # Команды для разработки
│   └── README.md        # Документация проекта
├── day_03/               # День 3 - Режим советчика с ограничениями модели
│   ├── terminal_chat_v3.py # Чат с режимом советчика
│   ├── advice_session.py   # Управление состоянием сессии
│   ├── advice_mode.py      # Логика режима советчика
│   ├── tests/             # Тесты для всех компонентов
│   ├── pyproject.toml     # Зависимости Poetry
│   ├── Makefile          # Команды для разработки
│   └── README.md         # Документация проекта
├── day_04/               # День 4 - Улучшенный режим советчика с температурой
│   ├── terminal_chat_v4.py # Чат с улучшенным режимом советчика
│   ├── advice_mode.py      # Логика режима советчика
│   ├── advice_session.py   # Управление состоянием сессии
│   ├── temperature_utils.py # Утилиты для работы с температурой
│   ├── experiment_temperature.py # Эксперименты с температурой
│   ├── tests/             # Тесты для всех компонентов
│   ├── pyproject.toml     # Зависимости Poetry
│   ├── Makefile          # Команды для разработки
│   └── README.md         # Документация проекта
├── day_05/               # День 5 - Локальные модели и история сообщений
│   ├── terminal_chat_v5.py # Чат с поддержкой локальных моделей
│   ├── advice_mode_v5.py   # Режим советчика для локальных моделей
│   ├── advice_session.py   # Управление состоянием сессии
│   ├── temperature_utils.py # Утилиты для работы с температурой
│   ├── check_models.py     # Проверка доступности локальных моделей
│   ├── demo_*.py          # Демонстрационные скрипты
│   ├── tests/             # Тесты для всех компонентов
│   ├── requirements.txt   # Зависимости проекта
│   ├── Makefile          # Команды для разработки
│   └── README.md         # Документация проекта
├── day_06/               # День 6 - Тестирование локальных моделей на логических загадках
│   ├── src/              # Исходный код системы тестирования
│   │   ├── main.py       # Основной модуль тестирования
│   │   ├── model_client.py # Клиент для работы с локальными моделями
│   │   ├── riddles.py    # Коллекция логических загадок
│   │   ├── report_generator.py # Генератор отчетов
│   │   └── __init__.py   # Инициализация пакета
│   ├── tests/           # Тесты для всех компонентов
│   ├── pyproject.toml   # Зависимости Poetry
│   ├── Makefile         # Команды для разработки
│   └── README.md        # Документация проекта
└── day_07/               # День 7 - Мульти-агентная система для генерации и ревью кода
    ├── agents/          # Агенты системы
    │   ├── api/        # FastAPI сервисы агентов
    │   │   ├── generator_api.py # API агента-генератора
    │   │   └── reviewer_api.py  # API агента-ревьюера
    │   └── core/       # Ядро агентов (генератор, ревьюер)
    │       ├── base_agent.py # Базовый класс агента
    │       ├── code_generator.py # Агент-генератор кода
    │       ├── code_reviewer.py # Агент-ревьюер кода
    │       └── model_client_adapter.py # Интеграция с моделями
    ├── communication/   # Слой коммуникации между агентами
    │   ├── agent_client.py # HTTP клиент с retry логикой
    │   └── message_schema.py # Модели запросов/ответов
    ├── prompts/        # Шаблоны промптов для моделей
    │   ├── generator_prompts.py # Промпты для генерации
    │   └── reviewer_prompts.py  # Промпты для ревью
    ├── tests/          # Тесты системы
    │   ├── test_generator.py
    │   ├── test_reviewer.py
    │   └── test_orchestrator.py
    ├── examples/       # Примеры использования
    ├── orchestrator.py # Оркестратор workflow
    ├── main.py         # CLI интерфейс
    ├── demo.py         # Демонстрационные примеры
    ├── Dockerfile      # Multi-stage Docker образ
    ├── docker-compose*.yml # Конфигурации развертывания
    ├── README.md       # Документация проекта (EN)
    ├── README.ru.md    # Документация проекта (RU)
    ├── DEVELOPER_GUIDE.md # Руководство разработчика (EN)
    ├── DEVELOPER_GUIDE.ru.md # Руководство разработчика (RU)
    ├── ARCHITECTURE.md # Архитектура системы (EN)
    ├── ARCHITECTURE.ru.md # Архитектура системы (RU)
    ├── DEPLOYMENT.md   # Руководство по развертыванию (EN)
    ├── DEPLOYMENT.ru.md # Руководство по развертыванию (RU)
    ├── TROUBLESHOOTING.md # Руководство по устранению неполадок (EN)
    ├── TROUBLESHOOTING.ru.md # Руководство по устранению неполадок (RU)
    ├── pyproject.toml  # Зависимости Poetry
    ├── Makefile        # Команды для разработки
    └── constants.py    # Константы конфигурации
```

## 🚀 Быстрый старт

### 1. Настройка API ключей

```bash
make setup  # Создаст api_key.txt из шаблона
# Добавьте ваши API ключи в файл api_key.txt:
# perplexity:ваш_ключ_perplexity
# chadgpt:ваш_ключ_chadgpt
```

### 2. Запуск локальных моделей (опционально)

```bash
# Запуск всех локальных моделей
cd local_models
docker-compose up -d

# Проверка доступности
curl http://localhost:8000/chat  # Qwen
curl http://localhost:8001/chat  # Mistral
curl http://localhost:8002/chat  # TinyLlama
```

### 3. Выбор проекта

```bash
# День 1 - простой чат
cd day_01
make install
make chat

# День 2 - улучшенный чат с JSON-ответами
cd ../day_02
make install
make chat

# День 3 - режим советчика с ограничениями модели
cd ../day_03
make install
make run

# День 4 - улучшенный режим советчика с температурой
cd ../day_04
make install
make run

# День 5 - локальные модели и история сообщений
cd ../day_05
make install
make run

# День 6 - тестирование локальных моделей на логических загадках
cd ../day_06
make install
make run

# День 7 - Мульти-агентная система для генерации и ревью кода
cd ../day_07

# Запуск StarCoder (требуется)
cd ../local_models
docker-compose up -d starcoder-chat

# Запуск агентов через Docker Compose
cd ../day_07
make start-bridge  # Простой запуск
# или
make start-traefik # С Traefik reverse proxy

# CLI использование
make demo          # Запуск демо
make run-simple    # Простая генерация кода
```

## 📊 Сравнение проектов

| Проект | Сложность | Технологии | Модели | Особенности |
|--------|-----------|------------|--------|-------------|
| day_01 | ⭐ | Python, API | Perplexity | Простой чат |
| day_02 | ⭐⭐ | Python, JSON | Perplexity | JSON ответы |
| day_03 | ⭐⭐ | Python, State | Perplexity | Режим советчика |
| day_04 | ⭐⭐⭐ | Python, Temperature | Perplexity | Эксперименты с температурой |
| day_05 | ⭐⭐⭐ | Python, SDK, Docker | Локальные | Интеграция SDK |
| day_06 | ⭐⭐⭐⭐ | Python, SDK, Testing | Локальные | Тестирование моделей |
| day_07 | ⭐⭐⭐⭐⭐ | FastAPI, Docker, Traefik | 4 модели | Мульти-агентная система |

## 📚 Описание проектов

### Local Models - Инфраструктура локальных языковых моделей

🏠 **Общий модуль** для работы с локальными языковыми моделями. Предоставляет единообразный API для различных моделей и может использоваться любыми проектами в репозитории.

**Технологии:**
- FastAPI (API сервер)
- Docker Compose (оркестрация)
- HuggingFace Transformers
- NVIDIA CUDA (GPU ускорение)
- 4-bit квантизация (экономия памяти)

**Поддерживаемые модели:**
- **Qwen-4B** (порт 8000) - Быстрые ответы, ~8GB RAM
- **Mistral-7B** (порт 8001) - Высокое качество, ~14GB RAM  
- **TinyLlama-1.1B** (порт 8002) - Компактная, ~4GB RAM

**Ключевые особенности:**
- 🔄 **Единообразный API**: Стандартный OpenAI-совместимый интерфейс
- 🐳 **Docker-оркестрация**: Автоматическое управление контейнерами
- 🎯 **Автоформатирование**: Поддержка разных форматов промптов
- ⚡ **GPU ускорение**: Автоматическое использование NVIDIA GPU
- 🔒 **Приватность**: Данные не покидают локальную машину
- 💰 **Экономия**: Нет расходов на внешние API

**Быстрый старт:**
```bash
cd local_models
docker-compose up -d
curl http://localhost:8000/chat  # Тест Qwen
```

**Интеграция:**
Используется в `day_05/` и может быть легко подключен к любым будущим проектам.

### Shared SDK - Унифицированная работа с моделями

🛠️ **Унифицированный SDK** для работы с различными языковыми моделями. Предоставляет единообразный интерфейс независимо от провайдера модели (Perplexity, ChatGPT или локальные модели).

**Ключевые особенности:**
- 🔄 **Унифицированный интерфейс**: Одинаковый API для всех моделей
- 🎯 **Абстракция провайдера**: Легкое переключение между провайдерами
- 📊 **Статистика использования**: Подсчет токенов и отслеживание затрат
- 🔧 **Управление конфигурацией**: Централизованные настройки
- 🛡️ **Обработка ошибок**: Стандартизированная обработка исключений
- 📈 **Мониторинг производительности**: Отслеживание времени ответа

**Поддерживаемые провайдеры:**
- **Perplexity**: Высококачественные ответы
- **ChatGPT**: Флагманская модель OpenAI
- **Локальные модели**: Qwen, Mistral, TinyLlama

**Использование:**
```python
from shared.clients.model_client import ModelClient

client = ModelClient(provider="perplexity")
response = await client.chat("Привет, мир!")
```

**Интеграция:**
Используется в `day_05/` и `day_06/` для взаимодействия с моделями.

### День 01 - Терминальный чат с AI

**Назначение**: Введение в AI-управляемый терминальный чат

**Особенности:**
- Простой терминальный интерфейс
- Чат с AI в реальном времени
- Базовая обработка ошибок
- Функция чистого выхода

**Технологии:**
- Python 3.10+
- Perplexity API
- Терминальный интерфейс

**Быстрый старт:**
```bash
cd day_01
make install
make chat
```

### День 02 - Улучшенный чат с JSON-ответами

**Назначение**: Улучшенный чат со структурированными JSON-ответами

**Особенности:**
- JSON-форматированные ответы
- Улучшенная обработка ошибок
- Лучший пользовательский опыт
- Валидация ответов

**Технологии:**
- Python 3.10+
- Perplexity API
- Обработка JSON
- Валидация Pydantic

**Быстрый старт:**
```bash
cd day_02
make install
make chat
```

### День 03 - Режим советчика с ограничениями модели

**Назначение**: Структурированный диалог с режимом AI-советчика

**Особенности:**
- Режим советчика с ограничениями
- Управление состоянием сессии
- Сохранение контекста
- Структурированные ответы

**Технологии:**
- Python 3.10+
- Perplexity API
- Управление состоянием
- Обработка контекста

**Быстрый старт:**
```bash
cd day_03
make install
make run
```

### День 04 - Улучшенный режим советчика с температурой

**Назначение**: Улучшенный режим советчика с контролем температуры

**Особенности:**
- Вариация ответов на основе температуры
- Расширенный режим советчика
- Инструменты экспериментирования
- Метрики производительности

**Технологии:**
- Python 3.10+
- Perplexity API
- Утилиты температуры
- Фреймворк экспериментирования

**Быстрый старт:**
```bash
cd day_04
make install
make run
```

### День 05 - Локальные модели и история сообщений

**Назначение**: Интеграция с локальными моделями и историей сообщений

**Особенности:**
- Поддержка локальных моделей
- История сообщений
- Унифицированный API
- Интеграция SDK

**Технологии:**
- Python 3.10+
- Shared SDK
- Локальные модели
- Интеграция Docker

**Быстрый старт:**
```bash
cd day_05
make install
make run
```

### День 06 - Тестирование локальных моделей на логических загадках

**Назначение**: Комплексное тестирование локальных моделей на логических загадках

**Особенности:**
- Тестирование логических загадок
- Сравнение моделей
- Генерация отчетов
- Анализ производительности

**Технологии:**
- Python 3.10+
- Shared SDK
- Фреймворк тестирования
- Генерация отчетов

**Быстрый старт:**
```bash
cd day_06
make install
make run
```

### День 07 - Мульти-агентная система для генерации и ревью кода

🤖 **Профессиональная система** для автоматической генерации Python кода и его ревью с использованием специализированных AI-агентов. Поддержка нескольких языковых моделей (StarCoder, Mistral, Qwen, TinyLlama).

#### Архитектура

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Orchestrator  │    │  Code Generator │    │  Code Reviewer  │
│                 │    │     Agent       │    │     Agent       │
│  - Coordinates  │◄──►│  - Generates    │◄──►│  - Reviews      │
│  - Manages      │    │  - Creates      │    │  - Analyzes     │
│  - Saves        │    │  - Validates    │    │  - Scores       │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
                    ┌─────────────────┐
                    │  Shared SDK     │
                    │  - StarCoder    │
                    │  - Mistral      │
                    │  - Qwen         │
                    │  - TinyLlama    │
                    └─────────────────┘
```

#### Технологии
- FastAPI (REST API для агентов)
- Docker Compose (оркестрация сервисов)
- Traefik (reverse proxy и load balancer)
- Poetry (управление зависимостями)
- Shared SDK (унифицированная работа с моделями)
- Pydantic (валидация данных)
- pytest (тестирование)

#### Поддерживаемые модели
- **StarCoder-7B** (по умолчанию) - специализирован для генерации кода
- **Mistral-7B** - высокое качество, универсальная модель
- **Qwen-4B** - быстрые ответы, хорошее качество
- **TinyLlama-1.1B** - компактная и быстрая

#### Ключевые компоненты

**1. Агент-генератор кода (порт 9001)**
- Генерация Python функций по описанию
- Создание комплексных тестов
- Валидация сгенерированного кода
- Поддержка рефайнинга кода
- API endpoints: /generate, /refine, /validate

**2. Агент-ревьюер кода (порт 9002)**
- Анализ качества кода
- Проверка PEP8 соответствия
- Оценка покрытия тестами
- Расчет сложности кода
- API endpoints: /review, /analyze-pep8, /calculate-complexity

**3. Оркестратор**
- Координация workflow между агентами
- Управление обработкой задач
- Сохранение результатов
- Сбор статистики
- Обработка ошибок с retry логикой

**4. Слой коммуникации**
- HTTP клиент с retry логикой
- Exponential backoff для устойчивости
- Pydantic модели для валидации
- Структурированные запросы/ответы

#### Ключевые особенности

- ✨ **Поддержка множественных моделей**: Выбор из 4 языковых моделей
- 🤖 **Специализированные агенты**: Отдельные агенты для генерации и ревью
- 🔄 **Оркестрация workflow**: Автоматическая координация агентов
- 📊 **Метрики качества**: PEP8, покрытие тестами, сложность
- 🐳 **Развертывание Docker**: Несколько вариантов развертывания
- 🔍 **Мониторинг здоровья**: Endpoints для проверки состояния
- 📈 **Статистика**: Детальная статистика работы агентов
- 🛡️ **Обработка ошибок**: Retry логика с exponential backoff
- 📝 **Комплексная документация**: 5 документов включая архитектуру и развертывание
- 🔒 **Безопасность**: Multi-stage Docker builds, non-root пользователи

#### Варианты развертывания

**Bridge Network (простой)**:
```bash
make start-bridge
```
- Generator: http://localhost:9001
- Reviewer: http://localhost:9002

**Traefik Reverse Proxy (продакшн)**:
```bash
make start-traefik
```
- Generator: http://generator.localhost
- Reviewer: http://reviewer.localhost
- Traefik Dashboard: http://localhost:8080

#### Примеры использования

**CLI генерация**:
```bash
python main.py "Создать функцию для вычисления чисел Фибоначчи"
```

**Python API**:
```python
from orchestrator import MultiAgentOrchestrator
from communication.message_schema import OrchestratorRequest

orchestrator = MultiAgentOrchestrator()

# Простая генерация
request = OrchestratorRequest(
    task_description="Создать REST API endpoint",
    model_name="starcoder"
)
result = await orchestrator.process_task(request)

# Разные модели для генерации и ревью
request = OrchestratorRequest(
    task_description="Создать pipeline обработки данных",
    model_name="starcoder",
    reviewer_model_name="mistral"
)
result = await orchestrator.process_task(request)
```

#### Процесс workflow

1. **Отправка задачи**: Пользователь отправляет описание задачи
2. **Генерация кода**: Агент-генератор создает код и тесты
3. **Ревью кода**: Агент-ревьюер анализирует качество
4. **Агрегация результатов**: Оркестратор собирает результаты
5. **Сохранение**: Результаты сохраняются в JSON
6. **Обновление статистики**: Обновляются метрики производительности

#### API Endpoints

**Агент-генератор (9001)**:
- POST /generate - генерация кода
- POST /refine - улучшение кода
- POST /validate - валидация кода
- GET /health - проверка здоровья
- GET /stats - статистика производительности

**Агент-ревьюер (9002)**:
- POST /review - полный ревью кода
- POST /analyze-pep8 - анализ PEP8
- POST /analyze-test-coverage - анализ покрытия
- POST /calculate-complexity - расчет сложности
- GET /health - проверка здоровья
- GET /stats - статистика производительности

#### Тестирование

```bash
# Все тесты
make test

# С покрытием
make test-coverage

# Только unit тесты
make test-unit

# Только integration тесты
make test-integration
```

#### Документация

Проект включает полный набор документации:

- **README.md** - Основная документация и quick start
- **DEVELOPER_GUIDE.md** - Руководство для разработчиков
- **ARCHITECTURE.md** - Детальная архитектура системы
- **DEPLOYMENT.md** - Руководство по развертыванию
- **TROUBLESHOOTING.md** - Руководство по устранению неполадок
- **API.md** - Документация API endpoints

#### Интеграция с SDK

Использует `shared/` SDK для унифицированной работы с моделями:
- Единый интерфейс для всех моделей
- Автоматическая конфигурация
- Обработка ошибок
- Retry логика

#### Производительность

**Типичное время генерации**:
- StarCoder: 5-10 секунд
- Mistral: 6-12 секунд
- Qwen: 3-8 секунд
- TinyLlama: 2-5 секунд

**Требования к ресурсам**:
- CPU: 4+ cores (рекомендуется)
- RAM: 16GB+ (32GB для StarCoder)
- GPU: NVIDIA с 12GB+ VRAM (для StarCoder)
- Disk: 20GB+ (для моделей)

#### Масштабирование

Поддержка горизонтального масштабирования:
```bash
docker-compose up -d --scale generator-agent=3 --scale reviewer-agent=2
```

#### Безопасность

- Multi-stage Docker builds для минимального размера
- Non-root пользователи в контейнерах
- Health checks для мониторинга
- Resource limits для всех сервисов
- Traefik для защищенного routing

#### Мониторинг

- Health endpoints для проверки состояния
- Статистика работы агентов
- Сохранение всех результатов workflow
- Логирование всех операций

#### Готовность к продакшну

- ✅ Комплексная документация
- ✅ Unit и integration тесты
- ✅ Обработка ошибок с retry
- ✅ Мониторинг здоровья
- ✅ Docker multi-stage builds
- ✅ Управление ресурсами
- ✅ Лучшие практики безопасности
- ✅ Логирование и метрики

#### Следующие шаги

1. Изучить документацию в `day_07/DEVELOPER_GUIDE.md`
2. Запустить demo для понимания workflow
3. Экспериментировать с разными моделями
4. Интегрировать в собственные проекты
5. Расширить функциональность новыми агентами

## 🛠️ Технологии и зависимости

### Основные технологии
- **Python 3.10+**: Основной язык программирования
- **Poetry**: Управление зависимостями
- **Docker**: Контейнеризация
- **Docker Compose**: Оркестрация сервисов
- **FastAPI**: Веб-фреймворк для API
- **Pydantic**: Валидация данных
- **pytest**: Фреймворк тестирования

### AI/ML технологии
- **HuggingFace Transformers**: Интеграция моделей
- **NVIDIA CUDA**: GPU ускорение
- **4-bit квантизация**: Оптимизация памяти
- **Локальные модели**: Qwen, Mistral, TinyLlama, StarCoder

### Инфраструктурные технологии
- **Traefik**: Reverse proxy и load balancer
- **NVIDIA Container Toolkit**: Поддержка GPU
- **Multi-stage Docker builds**: Безопасность и оптимизация

## 🤝 Вклад в проект

Мы приветствуем вклад в проект! Пожалуйста, ознакомьтесь с README файлами отдельных проектов для конкретных руководящих принципов вклада.

### Общие принципы
1. Форкните репозиторий
2. Создайте ветку функции
3. Внесите изменения
4. Добавьте тесты, если применимо
5. Отправьте pull request

### Стандарты кода
- Следуйте PEP 8 для Python кода
- Используйте type hints
- Пишите комплексные тесты
- Документируйте изменения
- Следуйте существующим паттернам

## 📄 Лицензия

Этот проект лицензирован под лицензией MIT - см. файл LICENSE для деталей.

## 🙏 Благодарности

- HuggingFace за хостинг моделей и библиотеку transformers
- OpenAI за вдохновение API
- Сообщество open-source за инструменты и библиотеки
- Участники и пользователи этого проекта

---

**Примечание**: Это обучающий проект для изучения AI и языковых моделей. Используйте ответственно и в соответствии с применимыми условиями обслуживания.
