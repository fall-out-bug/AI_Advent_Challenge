#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
"""
import asyncio
import httpx
import sys


LOCAL_MODELS = {
    "qwen": "http://localhost:8000",
    "mistral": "http://localhost:8001", 
    "tinyllama": "http://localhost:8002"
}


async def check_model(model_name: str, url: str) -> bool:
    """
    Purpose: Check if local model is available.
    Args:
        model_name: Name of the model
        url: URL of the model API
    Returns:
        bool: True if model is available
    """
    try:
        async with httpx.AsyncClient(timeout=None) as client:
            response = await client.post(
                f"{url}/chat",
                json={
                    "messages": [{"role": "user", "content": "test"}],
                    "max_tokens": 10,
                    "temperature": 0.7
                }
            )
            return response.status_code == 200
    except Exception:
        return False


async def main():
    """Check all local models."""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
    print()
    
    available_models = []
    
    for model_name, url in LOCAL_MODELS.items():
        print(f"–ü—Ä–æ–≤–µ—Ä—è—é {model_name} ({url})...", end=" ")
        
        is_available = await check_model(model_name, url)
        
        if is_available:
            print("‚úÖ –¥–æ—Å—Ç—É–ø–Ω–∞")
            available_models.append(model_name)
        else:
            print("‚ùå –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
    
    print()
    
    if available_models:
        print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(available_models)}")
        print("–ú–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç—å —á–∞—Ç: python terminal_chat_v5.py")
    else:
        print("‚ùå –ù–∏ –æ–¥–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞!")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª–∏: make run-models")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
