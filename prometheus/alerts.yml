groups:
  - name: worker_alerts
    interval: 30s
    rules:
      - alert: UnifiedWorkerDown
        expr: up{job="unified-task-worker"} == 0
        for: 2m
        labels:
          severity: critical
          service: unified-task-worker
        annotations:
          summary: "Unified worker metrics endpoint is down"
          description: "The unified task worker metrics endpoint has been unavailable for more than 2 minutes. Check container status and logs."

      - alert: UnifiedWorkerHighErrorRate
        expr: |
          rate(unified_worker_tasks_total{status="error"}[5m])
          /
          clamp_min(rate(unified_worker_tasks_total[5m]), 1e-6) > 0.10
        for: 10m
        labels:
          severity: warning
          service: unified-task-worker
        annotations:
          summary: "Unified worker error rate exceeds 10%"
          description: "More than 10% of unified worker tasks failed during the last 10 minutes. Inspect worker logs for failing task types."

      - alert: UnifiedWorkerBacklog
        expr: |
          unified_worker_queue_depth{task_type="code_review"} > 50
        for: 15m
        labels:
          severity: warning
          service: unified-task-worker
        annotations:
          summary: "Unified worker queue backlog exceeds threshold"
          description: "Code review queue depth has been above 50 tasks for 15 minutes. Scale workers or investigate upstream bottlenecks."

      - alert: UnifiedWorkerHighLatency
        expr: |
          histogram_quantile(0.95, rate(unified_worker_task_duration_seconds_bucket[5m])) > 300
        for: 10m
        labels:
          severity: warning
          service: unified-task-worker
        annotations:
          summary: "Unified worker latency exceeds 5 minutes (P95)"
          description: "95th percentile unified worker task duration is above 5 minutes for the last 10 minutes. Investigate slow tasks or external dependencies."

  - name: mcp_alerts
    interval: 30s
    rules:
      # MCP Server Alerts
      - alert: MCPServerDown
        expr: |
          up{job="mcp-server"} == 0
        for: 2m
        labels:
          severity: critical
          service: mcp-server
          component: mcp-server
        annotations:
          summary: "MCP server is down"
          description: "MCP server has been unavailable for more than 2 minutes. Check container status and logs."

      - alert: MCPServerHighErrorRate
        expr: |
          rate(mcp_requests_total{status="error"}[5m])
          /
          clamp_min(rate(mcp_requests_total[5m]), 1e-6) > 0.10
        for: 5m
        labels:
          severity: warning
          service: mcp-server
          component: mcp-server
        annotations:
          summary: "MCP server error rate exceeds 10%"
          description: "MCP server error rate exceeds 10% of total requests in the last 5 minutes. Check logs for error details."

      - alert: MCPServerHighLatency
        expr: |
          histogram_quantile(0.95, rate(mcp_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
          service: mcp-server
          component: mcp-server
        annotations:
          summary: "MCP server request latency exceeds 5 seconds (P95)"
          description: "95th percentile of MCP server request time exceeds 5 seconds for the last 5 minutes. Check tool performance and dependencies."

  - name: butler_alerts
    interval: 30s
    rules:
      # Butler Bot Service Alerts
      - alert: ButlerBotDown
        expr: |
          up{job="butler-bot"} == 0
        for: 2m
        labels:
          severity: critical
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot service is down"
          description: "Butler bot service has been unavailable for more than 2 minutes. Check container status and logs."

      - alert: ButlerBotUnhealthy
        expr: |
          butler_bot_healthy == 0
        for: 3m
        labels:
          severity: critical
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot reports unhealthy status"
          description: "Butler bot health check indicates unhealthy status for more than 3 minutes. Check application logs."

      - alert: ButlerHighErrorRate
        expr: |
          rate(butler_errors_total[5m]) / rate(butler_messages_total[5m]) > 0.10
        for: 5m
        labels:
          severity: warning
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot error rate exceeds 10%"
          description: "Butler bot error rate exceeds 10% of total messages in the last 5 minutes. Check logs for error details."

      - alert: ButlerHighLatency
        expr: |
          histogram_quantile(0.95, rate(butler_message_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot message processing latency exceeds 5 seconds (P95)"
          description: "95th percentile of message processing time exceeds 5 seconds for the last 5 minutes. Check handler performance and dependencies."

      - alert: ButlerMongoDBConnectionFailed
        expr: |
          rate(butler_errors_total{error_type=~".*Connection.*|.*MongoDB.*|.*Database.*"}[5m]) > 0
        for: 2m
        labels:
          severity: critical
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot MongoDB connection failures detected"
          description: "Butler bot is experiencing MongoDB connection failures. Check MongoDB service status and network connectivity."

      - alert: ButlerLLMUnavailable
        expr: |
          rate(butler_errors_total{error_type=~".*LLM.*|.*Mistral.*|.*ConnectionError.*|.*TimeoutError.*"}[5m]) / rate(butler_messages_total[5m]) > 0.20
        for: 3m
        labels:
          severity: warning
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot LLM client unavailable (high error rate)"
          description: "Butler bot is experiencing high LLM-related error rate (>20%) in the last 3 minutes. Check Mistral API service availability."

      - alert: ButlerNoMessages
        expr: |
          rate(butler_messages_total[10m]) == 0
        for: 15m
        labels:
          severity: info
          service: butler-bot
          component: butler-agent
        annotations:
          summary: "Butler bot has not processed any messages in 10 minutes"
          description: "Butler bot has not processed any messages for more than 10 minutes. This may indicate a quiet period or connectivity issue."

  - name: epic23_observability_alerts
    interval: 30s
    rules:
      # Epic 23 Observability Metrics Alerts
      - alert: SharedInfraBootstrapFailed
        expr: |
          shared_infra_bootstrap_status{step="mongo"} == 0
          OR
          shared_infra_bootstrap_status{step="mock_services"} == 0
        for: 2m
        labels:
          severity: critical
          service: shared-infra
          component: bootstrap
        annotations:
          summary: "Shared infrastructure bootstrap step failed"
          description: "Shared infrastructure bootstrap step (mongo or mock_services) failed. Check CI logs and bootstrap script execution."

      - alert: BenchmarkExportSlow
        expr: |
          histogram_quantile(0.95, rate(benchmark_export_duration_seconds_bucket[5m])) > 60
        for: 5m
        labels:
          severity: warning
          service: benchmark
          component: exporter
        annotations:
          summary: "Benchmark export duration exceeds 60 seconds (P95)"
          description: "95th percentile benchmark export duration exceeds 60 seconds for the last 5 minutes. Check dataset size and export script performance."

      - alert: StructuredLogsVolumeSpike
        expr: |
          rate(structured_logs_total[5m]) > 1000
        for: 10m
        labels:
          severity: warning
          service: observability
          component: logging
        annotations:
          summary: "Structured logs volume spike detected"
          description: "Structured logs emission rate exceeds 1000 logs/second for the last 10 minutes. Check for logging loops or excessive verbosity."

      - alert: RAGVarianceThresholdExceeded
        expr: |
          rag_variance_ratio{window="current"} > 0.50
        for: 15m
        labels:
          severity: warning
          service: rag
          component: reranker
        annotations:
          summary: "RAG variance ratio exceeds threshold"
          description: "RAG reranker variance ratio exceeds 0.50 for the last 15 minutes. Check RAG++ configuration and reranking stability (owner-only metric)."

  - name: loki_alerts
    interval: 30s
    rules:
      # Loki log aggregation alerts (via Prometheus)
      - alert: LokiHighErrorRate
        expr: |
          rate(loki_request_duration_seconds_count{status=~"5.."}[5m])
          /
          rate(loki_request_duration_seconds_count[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: loki
          component: log-aggregation
        annotations:
          summary: "Loki error rate exceeds 5%"
          description: "Loki log aggregation error rate exceeds 5% of total requests in the last 5 minutes. Check Loki service health and log ingestion pipeline."

      - alert: LokiIngestionBacklog
        expr: |
          loki_ingester_ring_members{state="ACTIVE"} < loki_ingester_ring_members{state="JOINING"}
        for: 10m
        labels:
          severity: warning
          service: loki
          component: ingestion
        annotations:
          summary: "Loki ingestion backlog detected"
          description: "Loki ingestion ring shows backlog with members in JOINING state for more than 10 minutes. Check ingester capacity and storage."
