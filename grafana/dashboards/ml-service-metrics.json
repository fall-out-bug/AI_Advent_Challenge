{
    "id": null,
    "uid": "ml-service-metrics",
    "title": "ML Service Metrics",
    "tags": ["ml", "llm", "monitoring"],
    "timezone": "browser",
    "schemaVersion": 38,
    "version": 1,
    "refresh": "30s",
    "editable": true,
    "time": {
      "from": "now-6h",
      "to": "now"
    },
    "timepicker": {},
    "templating": {
      "list": []
    },
    "annotations": {
      "list": []
    },
    "panels": [
      {
        "id": 1,
        "title": "Model Performance",
        "type": "row",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "LLM Inference Latency P95",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(llm_inference_latency_seconds_bucket[5m]))",
            "legendFormat": "P95 Latency"
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 0, "y": 1}
      },
      {
        "id": 3,
        "title": "LLM Inference Latency P50",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(llm_inference_latency_seconds_bucket[5m]))",
            "legendFormat": "P50 Latency"
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 8, "y": 1}
      },
      {
        "id": 4,
        "title": "LLM Inference Latency P99",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, rate(llm_inference_latency_seconds_bucket[5m]))",
            "legendFormat": "P99 Latency"
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 16, "y": 1}
      },
      {
        "id": 5,
        "title": "Request Volume",
        "type": "row",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 9}
      },
      {
        "id": 6,
        "title": "Prediction Volume",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(llm_inference_latency_seconds_count[5m]))",
            "legendFormat": "Requests/min"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 10}
      },
      {
        "id": 7,
        "title": "Token Generation Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(llm_token_generation_rate_total[5m])) by (model_name)",
            "legendFormat": "{{model_name}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 10}
      },
      {
        "id": 8,
        "title": "Errors",
        "type": "row",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 18}
      },
      {
        "id": 9,
        "title": "Error Rate by Type",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(llm_error_rate_total[5m])) by (error_type)",
            "legendFormat": "{{error_type}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 19}
      },
      {
        "id": 10,
        "title": "Model Metadata",
        "type": "row",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 27}
      },
      {
        "id": 11,
        "title": "Model Version",
        "type": "stat",
        "targets": [
          {
            "expr": "llm_model_version",
            "legendFormat": "{{model_name}}"
          }
        ],
        "gridPos": {"h": 4, "w": 8, "x": 0, "y": 28}
      },
      {
        "id": 12,
        "title": "Model Deployed At",
        "type": "stat",
        "targets": [
          {
            "expr": "llm_model_deployed_at_seconds",
            "legendFormat": "{{model_name}}"
          }
        ],
        "gridPos": {"h": 4, "w": 8, "x": 8, "y": 28}
      }
    ],
    "links": []
}
