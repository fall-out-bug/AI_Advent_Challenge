services:
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - ./minio/data:/data
    command: server /data --console-address ":9001"
    networks: [mlsd_hw2]
    healthcheck:
      test: ["CMD-SHELL", "sh -c '(exec 3<>/dev/tcp/127.0.0.1/9000) >/dev/null 2>&1'"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 5s

  createbuckets:
    image: minio/mc
    depends_on: [minio]
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set local http://minio:9000 $${MINIO_ROOT_USER} $${MINIO_ROOT_PASSWORD}); do
        echo 'Waiting for minio...'; sleep 2;
      done;
      /usr/bin/mc mb -p local/movielens || true;
      /usr/bin/mc mb -p local/features || true;
      exit 0
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    networks: [mlsd_hw2]

  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    networks: [mlsd_hw2]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 2s
      retries: 10
      start_period: 2s

  spark-master:
    build:
      context: ./spark
    image: mlsd_spark:GAS_mlsd_hw2
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - JAVA_TOOL_OPTIONS=-Dlog4j2.disable.jmx=true -Dcom.sun.management.jmxremote=false -XX:-UseContainerSupport
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_LOCAL_HOSTNAME=spark-master
    command: ["/entrypoint.sh", "master"]
    ports:
      - "7077:7077"
      - "8080:8080"
    networks: [mlsd_hw2]
    healthcheck:
      # мастер «жив», когда процесс Master запущен и порт 7077 слушается
      test: ["CMD-SHELL", "bash -lc 'pgrep -f org.apache.spark.deploy.master.Master >/dev/null && (echo > /dev/tcp/127.0.0.1/7077) >/dev/null 2>&1'"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 5s
    depends_on: [minio]

  spark-worker-1:
    build:
      context: ./spark
    image: mlsd_spark:GAS_mlsd_hw2
    container_name: spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - JAVA_TOOL_OPTIONS=-Dlog4j2.disable.jmx=true -Dcom.sun.management.jmxremote=false -XX:-UseContainerSupport
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8g
      - SPARK_DAEMON_MEMORY=1g
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_LOCAL_HOSTNAME=spark-worker-1
    command: ["/entrypoint.sh", "worker"]
    ports:
      - "8081:8081"
    networks: [mlsd_hw2]
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'pgrep -f org.apache.spark.deploy.worker.Worker >/dev/null && (echo > /dev/tcp/127.0.0.1/8081) >/dev/null 2>&1'"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 5s
    depends_on:
      - spark-master

  airflow:
    build:
      context: ./airflow
    image: mlsd_airflow:GAS_mlsd_hw2
    container_name: airflow
    environment:
      - AIRFLOW_HOME=/opt/airflow
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.session,airflow.api.auth.backend.basic_auth
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW_API_USER=hw2user
      - AIRFLOW_API_PASS=hw2pass
    command: ["bash","-lc","set -e; airflow db migrate; airflow scheduler & exec airflow webserver --port 8080"]
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./spark-jobs:/opt/airflow/spark-jobs
      - airflow_home:/opt/airflow
    ports:
      - "8088:8080"
    networks: [mlsd_hw2]
    healthcheck:
      # НЕ ищем конкретный процесс — просто ждём, пока порт 8080 начнёт слушаться
      test: ["CMD-SHELL", "bash -lc '(exec 3<>/dev/tcp/127.0.0.1/8080) >/dev/null 2>&1'"]
      interval: 5s
      timeout: 5s
      retries: 120
      start_period: 120s
    depends_on:
      - minio
      - redis
      - spark-master
      - spark-worker-1

networks:
  mlsd_hw2:
    driver: bridge

volumes:
  airflow_home:
    driver: local
