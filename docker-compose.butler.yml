services:
  # =============================================
  # MCP Server (connects to shared infrastructure)
  # =============================================
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile.mcp
    image: ai-challenge-mcp:latest
    container_name: mcp-server
    env_file:
      - .env
    environment:
      - MONGODB_URL=${MONGODB_URL:-mongodb://shared-mongo:27017/butler?authSource=admin}
      - DB_NAME=${DB_NAME:-butler}
      - LLM_URL=${MISTRAL_API_URL:-http://mistral-chat:8001}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
      # Agent parsing and pipeline
      - AGENT_DECISION_TEMPERATURE=${AGENT_DECISION_TEMPERATURE:-0.2}
      - AGENT_DECISION_MAX_TOKENS=${AGENT_DECISION_MAX_TOKENS:-256}
      - AGENT_FORMATTING_TEMPERATURE=${AGENT_FORMATTING_TEMPERATURE:-0.7}
      - AGENT_FORMATTING_MAX_TOKENS=${AGENT_FORMATTING_MAX_TOKENS:-1024}
      - PARSER_STRICT_MODE=${PARSER_STRICT_MODE:-false}
      - PARSER_MAX_ATTEMPTS=${PARSER_MAX_ATTEMPTS:-3}
      - TELEGRAM_API_ID=${TELEGRAM_API_ID}
      - TELEGRAM_API_HASH=${TELEGRAM_API_HASH}
      - TELEGRAM_SESSION_STRING=${TELEGRAM_SESSION_STRING}
      # Evaluation and fine-tuning settings
      - ENABLE_QUALITY_EVALUATION=${ENABLE_QUALITY_EVALUATION:-true}
      - EVALUATION_MIN_SCORE_FOR_DATASET=${EVALUATION_MIN_SCORE_FOR_DATASET:-0.7}
      - ENABLE_AUTO_FINETUNING=${ENABLE_AUTO_FINETUNING:-true}
      - FINETUNING_MIN_SAMPLES=${FINETUNING_MIN_SAMPLES:-100}
      - FINETUNING_MODEL_OUTPUT_DIR=/models/fine_tuned
      - FINETUNING_BASE_MODEL=${FINETUNING_BASE_MODEL:-mistralai/Mistral-7B-Instruct-v0.2}
      - FINETUNING_NUM_EPOCHS=${FINETUNING_NUM_EPOCHS:-3}
      - FINETUNING_BATCH_SIZE=${FINETUNING_BATCH_SIZE:-4}
      - FINETUNING_LEARNING_RATE=${FINETUNING_LEARNING_RATE:-2e-5}
      # Review API settings
      - EXTERNAL_API_URL=${EXTERNAL_API_URL:-}
      - EXTERNAL_API_KEY=${EXTERNAL_API_KEY:-}
      - EXTERNAL_API_ENABLED=${EXTERNAL_API_ENABLED:-false}
      - EXTERNAL_API_TIMEOUT=${EXTERNAL_API_TIMEOUT:-30}
      - HW_CHECKER_MCP_URL=${HW_CHECKER_MCP_URL:-http://mcp-server:8005}
      - HW_CHECKER_MCP_ENABLED=${HW_CHECKER_MCP_ENABLED:-true}
      - REVIEW_LLM_TIMEOUT=${REVIEW_LLM_TIMEOUT:-120}
      - REVIEW_MAX_RETRIES=${REVIEW_MAX_RETRIES:-3}
      - ARCHIVE_MAX_TOTAL_SIZE_MB=${ARCHIVE_MAX_TOTAL_SIZE_MB:-100}
    ports:
      - "8004:8004"  # Review API will be on /api/v1/reviews
    volumes:
      # Mount Pyrogram session directory (created by init_pyrogram.py)
      - ./sessions:/app/sessions:rw
      # Mount models directory for fine-tuned models
      - ./models:/models/fine_tuned:rw
      # Mount data directory for datasets
      - ./data:/app/data:rw
      # Volume for review archives (read-only for security)
      - ./review_archives:/app/review_archives:ro
      # Source code volumes for hotreload (can be overridden by dev compose)
      # - ./src:/app/src:ro  # Uncomment for development hotreload
      # - ./shared:/app/shared:ro  # Uncomment for development hotreload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    restart: unless-stopped
    networks:
      - butler-network
      - infra_app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

  # =============================================
  # Butler Bot (Telegram Bot with ButlerOrchestrator)
  # =============================================
  butler-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    image: ai-challenge-bot:latest
    container_name: butler-bot
    ports:
      - "9091:9091"  # Metrics endpoint for Prometheus
    env_file:
      - .env
    environment:
      # Required: Telegram bot token from @BotFather
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      # Required: MongoDB connection URL
      # Use credentials from shared MongoDB instance
      - MONGODB_URL=${MONGODB_URL:-mongodb://admin:secure_mongo_password_456@shared-mongo:27017/butler?authSource=admin}
      # Required: Mistral API URL
      - MISTRAL_API_URL=${MISTRAL_API_URL:-http://llm-api:8000}
      # MCP Server URLs (supports multiple servers)
      # Default: local MCP server
      # Format: comma-separated URLs or JSON array
      # Example: MCP_SERVER_URLS=http://mcp-server:8004,http://external-mcp:8005
      # Or: MCP_SERVER_URLS='["http://mcp-server:8004", "http://external-mcp:8005"]'
      - MCP_SERVER_URLS=${MCP_SERVER_URLS:-http://mcp-server:8004}
      # Backward compatibility: single server
      - MCP_SERVER_URL=${MCP_SERVER_URL:-}
      # Whisper STT configuration (separate from LLM service)
      # LLM uses Mistral/Ollama (MISTRAL_API_URL), STT uses Whisper (WHISPER_HOST/PORT)
      # Note: External port is 8006, internal is 8005 (for Docker network)
      - WHISPER_HOST=${WHISPER_HOST:-whisper-stt}
      - WHISPER_PORT=${WHISPER_PORT:-8005}
      - STT_MODEL=${STT_MODEL:-base}
      # Redis configuration for voice command store
      # Use container name for Docker network access
      - REDIS_HOST=${REDIS_HOST:-shared-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-secure_redis_password_789}
      # Note: If REDIS_PASSWORD is empty in .env, default above is used
      # To override, set REDIS_PASSWORD in .env or pass via command line
      # Optional: Logging and configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - METRICS_PORT=9091
      - MISTRAL_TIMEOUT=${MISTRAL_TIMEOUT:-30}
      - MISTRAL_MAX_RETRIES=${MISTRAL_MAX_RETRIES:-3}
    # Temporarily remove mcp-server dependency for voice testing
    # depends_on:
    #   mcp-server:
    #     condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import sys; sys.exit(0)' && curl -f http://localhost:9091/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - butler-network
      - infra_app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          memory: 128M
    labels:
      - "service=butler-bot"
      - "layer=presentation"
      - "component=butler-agent"

  # =============================================
  # Unified Task Worker (Summarization + Code Review)
  # =============================================
  unified-task-worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    image: ai-challenge-worker:latest
    container_name: unified-task-worker
    command: ["python", "-m", "src.workers"]  # Uses unified_task_worker_main via __main__.py
    env_file:
      - .env
    environment:
      # Required: Telegram bot token from @BotFather (same as bot)
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - MCP_SERVER_URL=http://mcp-server:8004
      - LLM_URL=${MISTRAL_API_URL:-http://mistral-chat:8001}
      - MONGODB_URL=${MONGODB_URL:-mongodb://shared-mongo:27017/butler?authSource=admin}
      - DB_NAME=${DB_NAME:-butler}
      # Summary-specific
      - MORNING_SUMMARY_TIME=${MORNING_SUMMARY_TIME:-09:00}
      - EVENING_DIGEST_TIME=${EVENING_DIGEST_TIME:-20:00}
      - QUIET_HOURS_START=${QUIET_HOURS_START:-22}
      - QUIET_HOURS_END=${QUIET_HOURS_END:-8}
      - DEBUG_NOTIFICATION_INTERVAL_MINUTES=${DEBUG_NOTIFICATION_INTERVAL_MINUTES:-0}
      - ENABLE_ASYNC_LONG_SUMMARIZATION=${ENABLE_ASYNC_LONG_SUMMARIZATION:-true}
      # Review-specific
      - EXTERNAL_API_URL=${EXTERNAL_API_URL:-}
      - EXTERNAL_API_KEY=${EXTERNAL_API_KEY:-}
      - EXTERNAL_API_ENABLED=${EXTERNAL_API_ENABLED:-false}
      - EXTERNAL_API_TIMEOUT=${EXTERNAL_API_TIMEOUT:-30}
      - HW_CHECKER_MCP_URL=${HW_CHECKER_MCP_URL:-http://mcp-server:8005}
      - HW_CHECKER_MCP_ENABLED=${HW_CHECKER_MCP_ENABLED:-true}
      - REVIEW_LLM_TIMEOUT=${REVIEW_LLM_TIMEOUT:-120}
      - REVIEW_MAX_RETRIES=${REVIEW_MAX_RETRIES:-3}
      - REVIEW_WORKER_POLL_INTERVAL=${REVIEW_WORKER_POLL_INTERVAL:-5}
      - REVIEW_WORKER_MAX_BACKOFF=${REVIEW_WORKER_MAX_BACKOFF:-60}
      - ARCHIVE_MAX_TOTAL_SIZE_MB=${ARCHIVE_MAX_TOTAL_SIZE_MB:-100}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    volumes:
      # Volume for review archives (read-only for security)
      - ./review_archives:/app/review_archives:ro
    depends_on:
      mcp-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - butler-network
      - infra_app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          memory: 64M

  # =============================================
  # Post Fetcher Worker (Post Collection)
  # =============================================
  post-fetcher-worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    image: ai-challenge-worker:latest
    container_name: post-fetcher-worker
    command: ["python", "-m", "src.workers.post_fetcher_worker_main"]
    env_file:
      - .env
    environment:
      - MCP_SERVER_URL=http://mcp-server:8004
      - MONGODB_URL=${MONGODB_URL:-mongodb://shared-mongo:27017/butler?authSource=admin}
      - DB_NAME=${DB_NAME:-butler}
      - POST_FETCH_INTERVAL_HOURS=${POST_FETCH_INTERVAL_HOURS:-1}
      - POST_TTL_DAYS=${POST_TTL_DAYS:-7}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    depends_on:
      mcp-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - butler-network
      - infra_app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          memory: 64M

  # =============================================
  # Whisper STT Server (Speech-to-Text)
  # =============================================
  whisper-stt:
    # Use pre-built image or build from Dockerfile
    # If build fails, use: docker pull onerahmet/openai-whisper-asr-webservice:latest-gpu
    build:
      context: .
      dockerfile: docker/whisper-server/Dockerfile
    image: ai-challenge-whisper:latest
    container_name: whisper-stt
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-base}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    ports:
      - "8006:8005"  # Whisper API endpoint (8006 external, 8005 internal)
    volumes:
      # Persist Whisper model cache between container restarts
      # This prevents re-downloading models every time
      - whisper-model-cache:/root/.cache/whisper
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # Base model loads in ~30-45s on GPU
    restart: unless-stopped
    networks:
      - butler-network
      - infra_app-network
    # GPU support (requires nvidia-docker or Docker with GPU runtime)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        # Remove CPU limits for GPU usage
        # limits:
        #   cpus: '1.0'
        #   memory: 2G
        # reservations:
        #   memory: 1G

  # =============================================
  # Loki log aggregation backend
  # =============================================
  loki:
    image: grafana/loki:2.9.4
    container_name: loki
    command: -config.file=/etc/loki/local-config.yml
    volumes:
      - ./loki/loki-config.yml:/etc/loki/local-config.yml:ro
      - loki-data:/loki
    ports:
      - "3100:3100"
    restart: unless-stopped
    networks:
      - butler-network

  # =============================================
  # Promtail log shipper
  # =============================================
  promtail:
    image: grafana/promtail:2.9.4
    container_name: promtail
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    depends_on:
      - loki
    networks:
      - butler-network

networks:
  butler-network:
    driver: bridge
  infra_app-network:
    external: true
    name: infra_infra_app-network

volumes:
  loki-data:
    driver: local
  whisper-model-cache:
    driver: local
