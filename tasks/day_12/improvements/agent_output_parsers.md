# üîß –ü–∞—Ä—Å–µ—Ä—ã –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è Agent Output

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON –∏–∑ "—Å—Ç–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞" –º–æ–¥–µ–ª–∏.

---

## –ü—Ä–æ–±–ª–µ–º–∞: Model Output Parsing

Mistral —á–∞—Å—Ç–æ –≤—ã–¥–∞—ë—Ç —Ç–∞–∫–æ–µ:

```
–•–æ—Ä–æ—à–æ, —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å–æ–∑–¥–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –∫–∞–Ω–∞–ª—É –ù–∞–±–æ–∫–∞.

–Ø –∏—Å–ø–æ–ª—å–∑—É—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–æ—Å—Ç–æ–≤:
{
  "tool": "get_channel_digest_by_name",
  "params": {
    "channel_name": "–ù–∞–±–æ–∫–∞",
    "days": 3
  }
}

–≠—Ç–æ –¥–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –º–Ω–µ –≤—Å–µ –ø–æ—Å—Ç—ã –∏–∑ –∫–∞–Ω–∞–ª–∞...
```

**–ó–∞–¥–∞—á–∞**: –ò–∑–≤–ª–µ—á—å JSON –∏–∑ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 1: Robust JSON Parser

```python
"""
–ù–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏
"""

import json
import re
import logging
from typing import Optional, Dict, Any, List

logger = logging.getLogger(__name__)


def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """–ò–∑–≤–ª–µ—á—å JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏.
    
    –ü—ã—Ç–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:
    1. –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ JSON (–µ—Å–ª–∏ –≤–µ—Å—å –æ—Ç–≤–µ—Ç ‚Äî JSON)
    2. JSON –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö (```json ... ```)
    3. JSON-–±–ª–æ–∫ –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö (–æ—Ç –ø–µ—Ä–≤–æ–π { –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π })
    4. Multiline JSON (—Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏)
    
    Args:
        text: –¢–µ–∫—Å—Ç —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º JSON
        
    Returns:
        –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON –∏–ª–∏ None
    """
    if not text or not isinstance(text, str):
        return None
    
    text = text.strip()
    
    # ===== –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ =====
    try:
        result = json.loads(text)
        logger.debug(f"‚úì Direct JSON parse successful")
        return result
    except json.JSONDecodeError:
        pass
    
    # ===== –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: JSON –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö =====
    # –ò—â–µ–º ```json ... ``` –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ ``` ... ```
    patterns_triple = [
        r'```json\s*\n(.*?)\n```',   # ```json
        r'```\s*\n(.*?)\n```',        # –ø—Ä–æ—Å—Ç–æ ```
        r'```(.*?)```'                # –±–µ–∑ –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫
    ]
    
    for pattern in patterns_triple:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            json_str = match.group(1).strip()
            try:
                result = json.loads(json_str)
                logger.debug(f"‚úì JSON from triple-quotes parse successful")
                return result
            except json.JSONDecodeError:
                logger.debug(f"Failed to parse from triple-quotes: {json_str[:50]}")
                continue
    
    # ===== –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: JSON-–±–ª–æ–∫ (–æ—Ç { –¥–æ }) =====
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ {...} –±–ª–æ–∫–∏ –∏ –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å
    brace_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    matches = re.finditer(brace_pattern, text)
    
    for match in matches:
        json_str = match.group(0)
        try:
            result = json.loads(json_str)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
            if "tool" in result or "params" in result:
                logger.debug(f"‚úì JSON from braces parse successful")
                return result
        except json.JSONDecodeError:
            logger.debug(f"Failed to parse from braces: {json_str[:50]}")
            continue
    
    # ===== –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: Multiline JSON =====
    # –ü—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –æ—Ç –ø–µ—Ä–≤–æ–π { –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π }
    first_brace = text.find("{")
    last_brace = text.rfind("}")
    
    if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
        json_str = text[first_brace:last_brace + 1]
        try:
            result = json.loads(json_str)
            logger.debug(f"‚úì JSON from multiline parse successful")
            return result
        except json.JSONDecodeError:
            logger.debug(f"Failed to parse multiline JSON: {json_str[:50]}")
    
    logger.warning(f"Could not extract JSON from text: {text[:100]}")
    return None


def extract_and_validate(
    text: str,
    required_fields: List[str] = None,
    allow_empty_params: bool = False
) -> Optional[Dict[str, Any]]:
    """–ò–∑–≤–ª–µ—á—å JSON –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –æ–Ω –≤–∞–ª–∏–¥–µ–Ω.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        required_fields: –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –≤ JSON
        allow_empty_params: –†–∞–∑—Ä–µ—à–∏—Ç—å –ø—É—Å—Ç—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        
    Returns:
        –í–∞–ª–∏–¥–∞–Ω–Ω—ã–π JSON –∏–ª–∏ None
    """
    required_fields = required_fields or ["tool", "params"]
    
    json_data = extract_json_from_text(text)
    
    if not json_data:
        return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    for field in required_fields:
        if field not in json_data:
            logger.warning(f"Missing required field: {field}")
            return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ params –Ω–µ None
    if not allow_empty_params and json_data.get("params") is None:
        logger.warning("params field is None")
        return None
    
    return json_data


# ===== –¢–µ—Å—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞ =====

def test_json_extraction():
    """–¢–µ—Å—Ç –ø–∞—Ä—Å–µ—Ä–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö."""
    
    test_cases = [
        # –ü—Ä—è–º–æ–π JSON
        (
            '{"tool": "get_channel_digest_by_name", "params": {"channel_name": "–ù–∞–±–æ–∫–∞"}}',
            {"tool": "get_channel_digest_by_name", "params": {"channel_name": "–ù–∞–±–æ–∫–∞"}}
        ),
        # JSON –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö
        (
            '''–•–æ—Ä–æ—à–æ, –≤–æ—Ç JSON:
```json
{"tool": "list_channels", "params": {}}
```
–≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç...''',
            {"tool": "list_channels", "params": {}}
        ),
        # JSON –≤ —Ç–µ–∫—Å—Ç–µ
        (
            '''–Ø –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:
{"tool": "add_channel", "params": {"channel_name": "python"}}
–≠—Ç–æ –ø–æ–¥–ø–∏—à–µ—Ç –≤–∞—Å –Ω–∞ –∫–∞–Ω–∞–ª...''',
            {"tool": "add_channel", "params": {"channel_name": "python"}}
        ),
        # Multiline JSON
        (
            '''{
  "tool": "get_channel_digest_by_name",
  "params": {
    "channel_name": "–ù–∞–±–æ–∫–∞",
    "days": 3
  }
}''',
            {"tool": "get_channel_digest_by_name", "params": {"channel_name": "–ù–∞–±–æ–∫–∞", "days": 3}}
        ),
    ]
    
    for i, (input_text, expected) in enumerate(test_cases, 1):
        result = extract_json_from_text(input_text)
        assert result == expected, f"Test {i} failed: {result} != {expected}"
        print(f"‚úì Test {i} passed")
    
    print(f"\n‚úÖ All {len(test_cases)} tests passed!")
```

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 2: Fallback Parser (–∫–æ–≥–¥–∞ JSON –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è)

```python
"""
Fallback –ø–∞—Ä—Å–µ—Ä: –µ—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å regex + heuristics
"""

import re
from typing import Optional, Dict, Any


def extract_tool_from_text_heuristic(text: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è heuristics.
    
    –ï—Å–ª–∏ JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
    –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    
    Args:
        text: –¢–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏
        
    Returns:
        Dict —Å tool –∏ params –∏–ª–∏ None
    """
    
    # ===== –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ =====
    tools_map = {
        "get_channel_digest_by_name": ["digest.*channel", "–¥–∞–π–¥–∂–µ—Å—Ç.*–∫–∞–Ω–∞–ª–∞?"],
        "get_channel_digest": ["digest.*all", "–¥–∞–π–¥–∂–µ—Å—Ç.*–≤—Å–µ"],
        "list_channels": ["list.*channel", "—Å–ø–∏—Å–æ–∫.*–∫–∞–Ω–∞–ª–æ–≤?"],
        "add_channel": ["add.*channel", "–¥–æ–±–∞–≤–∏—Ç—å.*–∫–∞–Ω–∞–ª"],
        "get_channel_metadata": ["metadata.*channel", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.*–∫–∞–Ω–∞–ª–∞?"],
    }
    
    text_lower = text.lower()
    detected_tool = None
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
    for tool_name, patterns in tools_map.items():
        for pattern in patterns:
            if re.search(pattern, text_lower):
                detected_tool = tool_name
                break
        if detected_tool:
            break
    
    if not detected_tool:
        return None
    
    # ===== –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã =====
    params = {}
    
    # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
    channel_patterns = [
        r'canal[" ]*:?\s*["\']?([^"\'}\n]+)',  # "canal": "name"
        r'–∫–∞–Ω–∞–ª\s*["\']?([^"\'}\n]+)',          # –∫–∞–Ω–∞–ª "name"
        r'["\']?channel_name["\']?\s*:\s*["\']?([^"\'}\n]+)',  # channel_name: name
    ]
    
    for pattern in channel_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            channel_name = match.group(1).strip().strip('"\'')
            params["channel_name"] = channel_name
            break
    
    # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
    days_patterns = [
        r'(\d+)\s*(?:–¥–Ω|–¥–µ–Ω—å|–¥–Ω—è)',        # 3 –¥–Ω—è
        r'days?["\']?\s*:\s*(\d+)',        # days: 3
    ]
    
    for pattern in days_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            params["days"] = int(match.group(1))
            break
    
    if not params and detected_tool not in ["list_channels"]:
        return None
    
    return {
        "tool": detected_tool,
        "params": params
    }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–ª—É—á–∞–π –∫–æ–≥–¥–∞ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω
    messy_output = """
    –•–æ—Ä–æ—à–æ, —è –ø–æ–º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –∫–∞–Ω–∞–ª—É –ù–∞–±–æ–∫–∞ –∑–∞ 3 –¥–Ω—è.
    –≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...
    """
    
    result = extract_tool_from_text_heuristic(messy_output)
    print(f"Extracted: {result}")
    # Output: {'tool': 'get_channel_digest_by_name', 'params': {'channel_name': '–ù–∞–±–æ–∫–∞', 'days': 3}}
```

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 3: Complete Parser Pipeline

```python
"""
–ü–æ–ª–Ω—ã–π pipeline –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å fallback-–∞–º–∏
"""

from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)


class ToolCallParser:
    """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    
    @staticmethod
    def parse(text: str, strict: bool = False) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç—å –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏
            strict: –ï—Å–ª–∏ True, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ JSON –ø–∞—Ä—Å–µ—Ä (–±–µ–∑ heuristics)
            
        Returns:
            Dict {"tool": "...", "params": {...}} –∏–ª–∏ None
        """
        
        # ===== –ü–æ–ø—ã—Ç–∫–∞ 1: JSON –ø–∞—Ä—Å–µ—Ä =====
        json_result = extract_json_from_text(text)
        if json_result:
            if ToolCallParser._validate_tool_call(json_result):
                logger.info(f"‚úì JSON parse successful: {json_result['tool']}")
                return json_result
            else:
                logger.warning(f"JSON validation failed: {json_result}")
        
        # ===== –ï—Å–ª–∏ strict mode –∏–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω =====
        if strict:
            return None
        
        # ===== –ü–æ–ø—ã—Ç–∫–∞ 2: Heuristic –ø–∞—Ä—Å–µ—Ä =====
        heuristic_result = extract_tool_from_text_heuristic(text)
        if heuristic_result:
            logger.info(f"‚úì Heuristic parse successful: {heuristic_result['tool']}")
            return heuristic_result
        
        logger.warning("Could not parse tool call from text")
        return None
    
    @staticmethod
    def _validate_tool_call(tool_call: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ tool_call –≤–∞–ª–∏–¥–µ–Ω.
        
        Args:
            tool_call: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
            
        Returns:
            True –µ—Å–ª–∏ –≤–∞–ª–∏–¥–µ–Ω
        """
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª—è tool –∏ params
        if "tool" not in tool_call or "params" not in tool_call:
            return False
        
        # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
        if not isinstance(tool_call["tool"], str):
            return False
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º –∏–ª–∏ –ø—É—Å—Ç—ã–º
        if tool_call["params"] is not None and not isinstance(tool_call["params"], dict):
            return False
        
        return True
    
    @staticmethod
    def parse_with_fallback(
        text: str,
        max_attempts: int = 3
    ) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ fallback-–∞–º–∏.
        
        Args:
            text: –¢–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏
            max_attempts: –ú–∞–∫—Å –ø–æ–ø—ã—Ç–∫–∏
            
        Returns:
            –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–ª–∏ None
        """
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        text = ToolCallParser._clean_text(text)
        
        # –ü–æ–ø—ã—Ç–∫–∞ 1: –°—Ç—Ä–æ–≥–∏–π –ø–∞—Ä—Å–∏–Ω–≥
        result = ToolCallParser.parse(text, strict=True)
        if result:
            return result
        
        # –ü–æ–ø—ã—Ç–∫–∞ 2: –ü–∞—Ä—Å–∏–Ω–≥ —Å heuristics
        result = ToolCallParser.parse(text, strict=False)
        if result:
            return result
        
        # –ü–æ–ø—ã—Ç–∫–∞ 3: –ü–∞—Ä—Å–∏–Ω–≥ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞
        # –ú–æ–∂–µ—Ç –ø–æ–º–æ—á—å –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤—ã–¥–∞–ª–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫
        fragments = text.split("\n\n")
        for fragment in fragments:
            result = ToolCallParser.parse(fragment, strict=False)
            if result:
                logger.debug(f"Parsed from fragment: {result}")
                return result
        
        return None
    
    @staticmethod
    def _clean_text(text: str) -> str:
        """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–¥–∞–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        remove_patterns = [
            r"Available tools:.*?(?=\n\n|\Z)",
            r"<\|im_start\|>.*?<\|im_end\|>",
            r"\[INST\].*?\[/INST\]",
            r">>>.*?<<<",
        ]
        
        for pattern in remove_patterns:
            text = re.sub(pattern, "", text, flags=re.DOTALL | re.IGNORECASE)
        
        return text.strip()


# ===== –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ =====

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä 1: JSON –µ—Å—Ç—å
    output1 = '{"tool": "get_channel_digest_by_name", "params": {"channel_name": "–ù–∞–±–æ–∫–∞", "days": 3}}'
    result1 = ToolCallParser.parse_with_fallback(output1)
    print(f"Result 1: {result1}")
    
    # –ü—Ä–∏–º–µ—Ä 2: JSON –≤ —Ç–µ–∫—Å—Ç–µ
    output2 = """
    –•–æ—Ä–æ—à–æ, —è –ø–æ–º–æ–≥—É.
    {"tool": "list_channels", "params": {}}
    –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–Ω–∞–ª—ã...
    """
    result2 = ToolCallParser.parse_with_fallback(output2)
    print(f"Result 2: {result2}")
    
    # –ü—Ä–∏–º–µ—Ä 3: –ù–µ—Ç JSON, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
    output3 = """
    –Ø –ø–æ–ª—É—á—É –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –∫–∞–Ω–∞–ª—É –ù–∞–±–æ–∫–∞ –∑–∞ 3 –¥–Ω—è.
    """
    result3 = ToolCallParser.parse_with_fallback(output3)
    print(f"Result 3: {result3}")
```

---

## üß™ Integration Test

```python
"""
–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–µ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∞–≥–µ–Ω—Ç–∞
"""

import asyncio
from typing import Optional, Dict, Any


class AgentWithRobustParsing:
    """–ê–≥–µ–Ω—Ç —Å robust –ø–∞—Ä—Å–∏–Ω–≥–æ–º."""
    
    def __init__(self, mcp_client, model_client):
        self.mcp_client = mcp_client
        self.model_client = model_client
    
    async def process(self, user_input: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —Å robust –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
        
        Args:
            user_input: –¢–µ–∫—Å—Ç –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        response = await self.model_client.create_completion(
            messages=[
                {"role": "system", "content": DECISION_ONLY_SYSTEM_PROMPT},
                {"role": "user", "content": user_input}
            ],
            temperature=0.2,
            max_tokens=256
        )
        
        model_output = response["choices"][0]["message"]["content"]
        
        # ===== Robust –ø–∞—Ä—Å–∏–Ω–≥ =====
        tool_call = ToolCallParser.parse_with_fallback(model_output)
        
        if not tool_call:
            logger.error(f"Failed to parse tool call from: {model_output}")
            return {
                "success": False,
                "error": "Could not understand request",
                "debug": model_output[:200]
            }
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        tool_name = tool_call["tool"]
        tool_params = tool_call["params"]
        
        try:
            result = await self.mcp_client.execute_tool(tool_name, **tool_params)
            
            return {
                "success": True,
                "tool": tool_name,
                "params": tool_params,
                "result": result
            }
        
        except Exception as e:
            logger.error(f"Tool execution failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "tool": tool_name
            }


# ===== Test Suite =====

async def test_agent_parsing():
    """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –≤—ã—Ö–æ–¥–∞–º–∏ –º–æ–¥–µ–ª–∏."""
    
    agent = AgentWithRobustParsing(mock_mcp_client, mock_model_client)
    
    test_cases = [
        {
            "input": "–î–∞–π–¥–∂–µ—Å—Ç –ø–æ –ù–∞–±–æ–∫–∞ –∑–∞ 3 –¥–Ω—è",
            "model_output": '{"tool": "get_channel_digest_by_name", "params": {"channel_name": "–ù–∞–±–æ–∫–∞", "days": 3}}',
            "expected_tool": "get_channel_digest_by_name"
        },
        {
            "input": "–ö–∞–∫–∏–µ –∫–∞–Ω–∞–ª—ã?",
            "model_output": """
            –°–µ–π—á–∞—Å —è –ø–æ–ª—É—á—É —Å–ø–∏—Å–æ–∫ –≤–∞—à–∏—Ö –∫–∞–Ω–∞–ª–æ–≤...
            
            ```json
            {"tool": "list_channels", "params": {}}
            ```
            
            –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç...
            """,
            "expected_tool": "list_channels"
        },
        {
            "input": "–î–æ–±–∞–≤—å –∫–∞–Ω–∞–ª python",
            "model_output": """
            –û–∫–µ–π, —è –ø–æ–¥–ø–∏—à—É –≤–∞—Å –Ω–∞ –∫–∞–Ω–∞–ª python.
            
            {
              "tool": "add_channel",
              "params": {
                "channel_name": "python"
              }
            }
            """,
            "expected_tool": "add_channel"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nTest {i}: {test_case['input']}")
        
        # –ú–æ–∫–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        mock_model_client.model_output = test_case["model_output"]
        
        result = await agent.process(test_case["input"])
        
        assert result["success"], f"Test {i} failed: {result.get('error')}"
        assert result["tool"] == test_case["expected_tool"], f"Wrong tool: {result['tool']}"
        
        print(f"  ‚úì Passed")
    
    print(f"\n‚úÖ All {len(test_cases)} tests passed!")


# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
if __name__ == "__main__":
    asyncio.run(test_agent_parsing())
```

---

## üìù –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ Cursor

–ü–æ–ø—Ä–æ—Å–∏ Cursor:

```
–ò—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∏–º–µ—Ä—ã –ø–∞—Ä—Å–µ—Ä–æ–≤ –∏–∑ agent_output_parsers.md:

1. –°–æ–∑–¥–∞–π —Ñ–∞–π–ª src/domain/parsers/tool_call_parser.py
   - ToolCallParser —Å –º–µ—Ç–æ–¥–∞–º–∏ parse(), _validate_tool_call(), _clean_text()
   - –§—É–Ω–∫—Ü–∏–∏ extract_json_from_text() –∏ extract_tool_from_text_heuristic()

2. –û–±–Ω–æ–≤–∏ MCPAwareAgent.process():
   - –ò—Å–ø–æ–ª—å–∑—É–π ToolCallParser.parse_with_fallback() –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
   - –î–æ–±–∞–≤—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –ø–∞—Ä—Å–∏–Ω–≥–∞

3. –°–æ–∑–¥–∞–π tests/test_parser.py:
   - Unit —Ç–µ—Å—Ç—ã –¥–ª—è extract_json_from_text() (10+ cases)
   - Integration —Ç–µ—Å—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ pipeline
   - Edge cases: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON, multiline –∏ —Ç.–¥.

4. –û–±–Ω–æ–≤–ª—è–µ–º—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é:
   - PARSER_STRICT_MODE (bool) –¥–ª—è —Ä–µ–∂–∏–º–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
   - PARSER_MAX_ATTEMPTS (int) –¥–ª—è fallback-–æ–≤

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- Type hints –≤–µ–∑–¥–µ
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö edge cases
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ DEBUG —É—Ä–æ–≤–Ω–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–∏
- –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ > 90%
```

–≠—Ç–æ —Ä–µ—à–∏—Ç –ø—Ä–æ–±–ª–µ–º—É "—Å—Ç–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞" –∏ –¥–∞—Å—Ç –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥! ‚úÖ
