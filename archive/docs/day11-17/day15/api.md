# API Documentation - –î–µ–Ω—å 15

## Evaluation API

### SummarizationEvaluator

–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM.

#### `evaluate()`

```python
async def evaluate(
    self,
    original_text: str,
    summary_text: str,
    context: SummarizationContext,
    summary_metadata: dict[str, Any],
) -> SummarizationEvaluation
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `original_text` - –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
- `summary_text` - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
- `context` - –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
- `summary_metadata` - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `SummarizationEvaluation` —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º

**–ü—Ä–∏–º–µ—Ä:**
```python
evaluator = SummarizationEvaluator(llm_client, token_counter)

evaluation = await evaluator.evaluate(
    original_text="–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç...",
    summary_text="–ö—Ä–∞—Ç–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è...",
    context=SummarizationContext(
        source_type="telegram_posts",
        language="ru",
        max_output_length=1500,
    ),
    summary_metadata={"method": "map_reduce", "chunks": 3},
)

print(f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {evaluation.overall_score:.2f}")
print(f"–ü–æ–ª–Ω–æ—Ç–∞: {evaluation.coverage_score:.2f}")
print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {evaluation.accuracy_score:.2f}")
```

## Fine-tuning API

### FineTuningService

–°–µ—Ä–≤–∏—Å –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π.

#### `fine_tune()`

```python
async def fine_tune(
    self,
    task: FineTuningTask,
) -> FineTuningResult
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `task` - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `FineTuningResult` —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä:**
```python
from src.domain.value_objects.finetuning import FineTuningTask
from src.infrastructure.finetuning import FineTuningService

service = FineTuningService()

task = FineTuningTask(
    task_type="summarization",
    model_name="mistralai/Mistral-7B-Instruct-v0.2",
    dataset_path="/app/data/fine_tuning_dataset.jsonl",
    output_dir="/models/fine_tuned/summarization",
    num_epochs=3,
    batch_size=4,
    learning_rate=2e-5,
)

result = await service.fine_tune(task)

print(f"Training loss: {result.training_loss:.4f}")
print(f"Trained on {result.num_samples} samples")
print(f"Duration: {result.training_duration_seconds:.0f}s")
```

## Repository API

### SummarizationEvaluationRepository

–†–∞–±–æ—Ç–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ MongoDB.

#### `save_evaluation()`

```python
async def save_evaluation(
    self,
    evaluation: SummarizationEvaluation,
) -> str
```

–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ü–µ–Ω–∫—É –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏

#### `count_by_score()`

```python
async def count_by_score(
    self,
    min_score: float = 0.0,
    max_score: float = 1.0,
) -> int
```

–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ.

#### `export_to_fine_tuning_dataset()`

```python
async def export_to_fine_tuning_dataset(
    self,
    output_path: str,
    min_score: float = 0.7,
    limit: int | None = None,
) -> int
```

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –≤ JSONL –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞.

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤

**–ü—Ä–∏–º–µ—Ä:**
```python
from src.infrastructure.database.mongo import get_db
from src.infrastructure.repositories import SummarizationEvaluationRepository

db = await get_db()
repo = SummarizationEvaluationRepository(db)

# –ü–æ–¥—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
count = await repo.count_by_score(min_score=0.7)
print(f"High-quality samples: {count}")

# –≠–∫—Å–ø–æ—Ä—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞
exported = await repo.export_to_fine_tuning_dataset(
    output_path="/app/data/fine_tuning_dataset.jsonl",
    min_score=0.8,
    limit=500,
)
print(f"Exported {exported} samples")
```

#### `should_trigger_finetuning()`

```python
async def should_trigger_finetuning(
    self,
    min_samples: int,
    min_score: float,
) -> bool
```

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞.

## Value Objects

### SummarizationEvaluation

```python
@dataclass
class SummarizationEvaluation:
    summary_id: str
    original_text: str
    summary_text: str
    coverage_score: float        # 0.0-1.0
    accuracy_score: float        # 0.0-1.0
    coherence_score: float       # 0.0-1.0
    informativeness_score: float # 0.0-1.0
    overall_score: float         # 0.0-1.0
    evaluation_method: str
    evaluator_model: str
    evaluation_prompt: str
    raw_response: str
    summarization_context: dict[str, Any]
    summary_metadata: dict[str, Any]
    evaluated_at: datetime

    def to_fine_tuning_sample(self) -> dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞."""
```

### FineTuningTask

```python
@dataclass
class FineTuningTask:
    task_type: str              # "summarization" | "classification" | "qa"
    model_name: str
    dataset_path: str
    output_dir: str
    num_epochs: int = 3
    batch_size: int = 4
    learning_rate: float = 2e-5
    max_steps: int | None = None
    task_specific_config: dict[str, Any] | None = None
```

### FineTuningResult

```python
@dataclass
class FineTuningResult:
    task_type: str
    model_name: str
    fine_tuned_model_path: str
    training_loss: float
    validation_loss: float | None
    num_samples: int
    num_epochs: int
    training_duration_seconds: float
    started_at: datetime
    completed_at: datetime
    metadata: dict[str, Any] | None = None
```

## Scripts

### export_fine_tuning_dataset.py

–≠–∫—Å–ø–æ—Ä—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ MongoDB –≤ JSONL.

```bash
python scripts/export_fine_tuning_dataset.py \
  --min-score 0.8 \
  --limit 500 \
  --output /app/data/fine_tuning_dataset.jsonl
```

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `--min-score` - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (default: 0.7)
- `--limit` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ (optional)
- `--output` - –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (default: /app/data/fine_tuning_dataset.jsonl)

## Async Long Summarization API

### request_channel_digest_async

MCP tool –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞.

```python
@mcp.tool()
async def request_channel_digest_async(
    user_id: int,
    chat_id: int,
    channel_username: str | None = None,
    hours: int = 72,
    language: str = "ru",
    max_sentences: int = 8,
) -> Dict[str, Any]
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `user_id` - Telegram user ID
- `chat_id` - Telegram chat ID –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- `channel_username` - –ò–º—è –∫–∞–Ω–∞–ª–∞ (None = –≤—Å–µ –∫–∞–Ω–∞–ª—ã)
- `hours` - –í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –≤ —á–∞—Å–∞—Ö (default: 72)
- `language` - –Ø–∑—ã–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ ("ru" | "en", default: "ru")
- `max_sentences` - –ú–∞–∫—Å–∏–º—É–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (default: 8)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
```python
{
    "task_id": "digest_abc123_1234567890",
    "ack_message": "–ü—Ä–∏–Ω—è–ª –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞..."
}
```

**–ü—Ä–∏–º–µ—Ä:**
```python
result = await request_channel_digest_async(
    user_id=123,
    chat_id=456,
    channel_username="channel_name",
    hours=72,
    language="ru",
    max_sentences=8
)
# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç: "–ü—Ä–∏–Ω—è–ª –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∫–∞–Ω–∞–ª–∞ channel_name –∑–∞ 72 —á–∞—Å–æ–≤. –ü—Ä–∏—à–ª—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º."
# Worker –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á—É —Å —Ç–∞–π–º–∞—É—Ç–æ–º 600s
# –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º: "üìã –î–∞–π–¥–∂–µ—Å—Ç –∫–∞–Ω–∞–ª–∞ channel_name:\n\n..."
```

### LongSummarizationTask

–°—É—â–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –¥–ª—è –¥–ª–∏–Ω–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.

```python
@dataclass
class LongSummarizationTask:
    task_id: str
    user_id: int
    chat_id: int
    channel_username: str | None = None
    context: SummarizationContext
    status: TaskStatus  # QUEUED, RUNNING, SUCCEEDED, FAILED
    result_text: str | None = None
    error: str | None = None
    created_at: datetime
    started_at: datetime | None = None
    finished_at: datetime | None = None
```

### LongTasksRepository

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏.

```python
class LongTasksRepository:
    async def create(task: LongSummarizationTask) -> str
    async def pick_next_queued() -> LongSummarizationTask | None
    async def mark_running(task_id: str) -> None
    async def complete(task_id: str, result_text: str) -> None
    async def fail(task_id: str, error: str) -> None
    async def get_by_id(task_id: str) -> LongSummarizationTask | None
    async def get_by_user(user_id: int, limit: int, status: TaskStatus | None) -> list[LongSummarizationTask]
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ê—Ç–æ–º–∞—Ä–Ω—ã–π `pick_next_queued()` –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥–≤–æ–π–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
- –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ MongoDB
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π TTL 7 –¥–Ω–µ–π –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á

### –ú–µ—Ç—Ä–∏–∫–∏

**Prometheus –º–µ—Ç—Ä–∏–∫–∏:**
- `long_tasks_total{status}` - —Å—á–µ—Ç—á–∏–∫ –∑–∞–¥–∞—á –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º (queued, running, succeeded, failed)
- `long_tasks_duration_seconds{status}` - –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á
- `long_tasks_queue_size` - —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏

```python
summarizer_timeout_seconds_long: float = 600.0  # –¢–∞–π–º–∞—É—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
long_tasks_poll_interval_seconds: int = 5  # –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–ø—Ä–æ—Å–∞ –æ—á–µ—Ä–µ–¥–∏ worker'–æ–º
long_tasks_max_retries: int = 1  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–≤—Ç–æ—Ä–æ–≤
enable_async_long_summarization: bool = True  # Feature flag
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

–ü—Ä–∏ –æ—à–∏–±–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:
1. –ó–∞–¥–∞—á–∞ –ø–æ–º–µ—á–∞–µ—Ç—Å—è –∫–∞–∫ FAILED –≤ MongoDB
2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –æ—à–∏–±–∫–∏ –∏ task_id
3. –ú–µ—Ç—Ä–∏–∫–∏ —Ñ–∏–∫—Å–∏—Ä—É—é—Ç –Ω–µ—É—Å–ø–µ—à–Ω—É—é –∑–∞–¥–∞—á—É
4. –õ–æ–≥–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª–Ω—ã–π traceback –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

## MongoDB Schema

### Collection: `summarization_evaluations`

```javascript
{
  _id: ObjectId,
  summary_id: String,
  original_text: String,
  summary_text: String,
  coverage_score: Number,
  accuracy_score: Number,
  coherence_score: Number,
  informativeness_score: Number,
  overall_score: Number,
  evaluation_method: String,
  evaluator_model: String,
  evaluation_prompt: String,
  raw_response: String,
  summarization_context: Object,
  summary_metadata: Object,
  evaluated_at: ISODate
}
```

**–ò–Ω–¥–µ–∫—Å—ã:**
- `overall_score` (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤)
- `evaluated_at` (–¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
- `summary_id` (–¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏)

## Environment Variables

```bash
# Evaluation settings
ENABLE_QUALITY_EVALUATION=true
EVALUATION_MIN_SCORE_FOR_DATASET=0.7

# Fine-tuning settings
ENABLE_AUTO_FINETUNING=true
FINETUNING_MIN_SAMPLES=100
FINETUNING_MODEL_OUTPUT_DIR=/models/fine_tuned
FINETUNING_BASE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
FINETUNING_NUM_EPOCHS=3
FINETUNING_BATCH_SIZE=4
FINETUNING_LEARNING_RATE=2e-5
```

## Docker Compose Services

### mcp-server (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞)

```yaml
mcp-server:
  volumes:
    - ./models/fine_tuned:/models/fine_tuned:rw
    - ./data:/app/data:rw
  environment:
    - ENABLE_QUALITY_EVALUATION=true
    - ENABLE_AUTO_FINETUNING=true
    - FINETUNING_MIN_SAMPLES=100
  deploy:
    resources:
      limits:
        memory: 8G  # –î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
```

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞

```python
from src.infrastructure.repositories import SummarizationEvaluationRepository

# –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
evaluations = await repo.get_recent_evaluations(limit=10)

for eval in evaluations:
    print(f"Summary: {eval.summary_id}")
    print(f"  Overall: {eval.overall_score:.2f}")
    print(f"  Coverage: {eval.coverage_score:.2f}")
    print(f"  Accuracy: {eval.accuracy_score:.2f}")
```

### –ü—Ä–∏–º–µ—Ä 2: –†—É—á–Ω–æ–π —Ç—Ä–∏–≥–≥–µ—Ä —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞

```python
from src.workers.finetuning_worker import FineTuningWorker

worker = FineTuningWorker(
    evaluation_repo=repo,
    finetuning_service=service,
    settings=settings,
)

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥
await worker.check_and_run_finetuning()
```

### –ü—Ä–∏–º–µ—Ä 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥—É

```python
# –ü–æ–¥—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
count = await repo.count_by_score(min_score=0.7)
min_required = settings.finetuning_min_samples

if count >= min_required:
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ –∫ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥—É: {count}/{min_required}")
else:
    print(f"‚è≥ –ù—É–∂–Ω–æ –µ—â–µ –æ–±—Ä–∞–∑—Ü–æ–≤: {count}/{min_required}")
```

## –û—à–∏–±–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞

### Evaluation Errors

```python
try:
    evaluation = await evaluator.evaluate(...)
except json.JSONDecodeError:
    logger.error("Failed to parse LLM response as JSON")
except ValueError as e:
    logger.error(f"Invalid evaluation scores: {e}")
```

### Fine-tuning Errors

```python
try:
    result = await service.fine_tune(task)
except ImportError:
    logger.error("Transformers not installed")
except RuntimeError as e:
    logger.error(f"Training failed: {e}")
```

## Best Practices

1. **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞**: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ fire-and-forget –¥–ª—è –æ—Ü–µ–Ω–∫–∏
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –°–ª–µ–¥–∏—Ç–µ –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
3. **–†–µ—Å—É—Ä—Å—ã**: –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏, –ø–ª–∞–Ω–∏—Ä—É–π—Ç–µ —Ä–µ—Å—É—Ä—Å—ã
4. **–í–∞–ª–∏–¥–∞—Ü–∏—è**: –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
5. **–ë—ç–∫–∞–ø—ã**: –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–æ–º

