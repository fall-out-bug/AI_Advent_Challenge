{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StarCoder Multi-Agent System - Advanced Tutorial\n",
        "\n",
        "This notebook demonstrates advanced features of the StarCoder Multi-Agent System including:\n",
        "\n",
        "1. Batch processing multiple tasks\n",
        "2. Error handling and recovery\n",
        "3. Performance optimization\n",
        "4. Custom orchestration patterns\n",
        "5. Result analysis and visualization\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Complete the Basic Tutorial first\n",
        "- All services running (StarCoder + Agents)\n",
        "- Additional Python packages: `matplotlib`, `pandas`, `seaborn`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import asyncio\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "from orchestrator import MultiAgentOrchestrator\n",
        "from communication.message_schema import OrchestratorRequest\n",
        "from exceptions import CodeGenerationError, CodeReviewError\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Advanced libraries imported successfully!\")\n",
        "print(f\"üìÅ Working directory: {Path.cwd()}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Batch Processing\n",
        "\n",
        "Let's process multiple tasks in parallel to demonstrate efficiency gains.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define multiple tasks for batch processing\n",
        "batch_tasks = [\n",
        "    {\n",
        "        \"description\": \"Create a sorting algorithm using quicksort\",\n",
        "        \"requirements\": [\"Use recursive approach\", \"Include type hints\", \"Handle edge cases\"]\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Implement a binary search algorithm\",\n",
        "        \"requirements\": [\"Handle edge cases\", \"Add comprehensive tests\", \"Optimize for performance\"]\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Create a simple hash table implementation\",\n",
        "        \"requirements\": [\"Use chaining for collision resolution\", \"Include resize functionality\", \"Add load factor monitoring\"]\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Write a function to find the longest common subsequence\",\n",
        "        \"requirements\": [\"Use dynamic programming\", \"Optimize for space\", \"Include memoization\"]\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Implement a basic graph traversal (BFS)\",\n",
        "        \"requirements\": [\"Use adjacency list representation\", \"Handle disconnected graphs\", \"Return shortest path\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìù Processing {len(batch_tasks)} tasks in batch:\")\n",
        "for i, task in enumerate(batch_tasks, 1):\n",
        "    print(f\"   {i}. {task['description']}\")\n",
        "\n",
        "# Initialize orchestrator\n",
        "orchestrator = MultiAgentOrchestrator()\n",
        "\n",
        "# Process tasks in parallel\n",
        "print(\"\\n‚è≥ Processing tasks in parallel...\")\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Create requests\n",
        "    requests = []\n",
        "    for task_data in batch_tasks:\n",
        "        request = OrchestratorRequest(\n",
        "            task_description=task_data[\"description\"],\n",
        "            language=\"python\",\n",
        "            requirements=task_data[\"requirements\"]\n",
        "        )\n",
        "        requests.append(request)\n",
        "    \n",
        "    # Process all tasks concurrently\n",
        "    results = await asyncio.gather(*[orchestrator.process_task(req) for req in requests], return_exceptions=True)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    \n",
        "    print(f\"‚úÖ Batch processing completed in {total_time:.2f}s\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Batch processing failed: {e}\")\n",
        "    results = []\n",
        "finally:\n",
        "    await orchestrator.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze batch processing results\n",
        "successful_results = []\n",
        "failed_results = []\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    if isinstance(result, Exception):\n",
        "        failed_results.append({\n",
        "            \"task\": batch_tasks[i][\"description\"],\n",
        "            \"error\": str(result)\n",
        "        })\n",
        "    elif result.success:\n",
        "        successful_results.append({\n",
        "            \"task\": batch_tasks[i][\"description\"],\n",
        "            \"workflow_time\": result.workflow_time,\n",
        "            \"quality_score\": result.review_result.code_quality_score,\n",
        "            \"lines_of_code\": result.generation_result.metadata.lines_of_code,\n",
        "            \"complexity\": result.generation_result.metadata.complexity,\n",
        "            \"tokens_used\": result.generation_result.tokens_used\n",
        "        })\n",
        "    else:\n",
        "        failed_results.append({\n",
        "            \"task\": batch_tasks[i][\"description\"],\n",
        "            \"error\": result.error_message\n",
        "        })\n",
        "\n",
        "print(\"üìä Batch Processing Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚Ä¢ Total tasks: {len(batch_tasks)}\")\n",
        "print(f\"‚Ä¢ Successful: {len(successful_results)}\")\n",
        "print(f\"‚Ä¢ Failed: {len(failed_results)}\")\n",
        "print(f\"‚Ä¢ Success rate: {len(successful_results)/len(batch_tasks)*100:.1f}%\")\n",
        "print(f\"‚Ä¢ Total time: {total_time:.2f}s\")\n",
        "print(f\"‚Ä¢ Average time per task: {total_time/len(batch_tasks):.2f}s\")\n",
        "\n",
        "if successful_results:\n",
        "    avg_quality = sum(r[\"quality_score\"] for r in successful_results) / len(successful_results)\n",
        "    avg_time = sum(r[\"workflow_time\"] for r in successful_results) / len(successful_results)\n",
        "    total_tokens = sum(r[\"tokens_used\"] for r in successful_results)\n",
        "    \n",
        "    print(f\"‚Ä¢ Average quality score: {avg_quality:.1f}/10\")\n",
        "    print(f\"‚Ä¢ Average workflow time: {avg_time:.2f}s\")\n",
        "    print(f\"‚Ä¢ Total tokens used: {total_tokens}\")\n",
        "\n",
        "# Display failed tasks\n",
        "if failed_results:\n",
        "    print(\"\\n‚ùå Failed Tasks:\")\n",
        "    for failed in failed_results:\n",
        "        print(f\"   ‚Ä¢ {failed['task']}: {failed['error']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations for batch processing results\n",
        "if successful_results:\n",
        "    df = pd.DataFrame(successful_results)\n",
        "    \n",
        "    # Create comprehensive visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('Batch Processing Analysis', fontsize=16)\n",
        "    \n",
        "    # Task completion time\n",
        "    axes[0, 0].bar(range(len(df)), df['workflow_time'], color='skyblue')\n",
        "    axes[0, 0].set_title('Workflow Time by Task')\n",
        "    axes[0, 0].set_xlabel('Task Index')\n",
        "    axes[0, 0].set_ylabel('Time (seconds)')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Quality scores\n",
        "    axes[0, 1].bar(range(len(df)), df['quality_score'], color='lightgreen')\n",
        "    axes[0, 1].set_title('Quality Score by Task')\n",
        "    axes[0, 1].set_xlabel('Task Index')\n",
        "    axes[0, 1].set_ylabel('Quality Score (/10)')\n",
        "    axes[0, 1].set_ylim(0, 10)\n",
        "    \n",
        "    # Lines of code\n",
        "    axes[0, 2].bar(range(len(df)), df['lines_of_code'], color='orange')\n",
        "    axes[0, 2].set_title('Lines of Code by Task')\n",
        "    axes[0, 2].set_xlabel('Task Index')\n",
        "    axes[0, 2].set_ylabel('Lines of Code')\n",
        "    \n",
        "    # Complexity distribution\n",
        "    complexity_counts = df['complexity'].value_counts()\n",
        "    axes[1, 0].pie(complexity_counts.values, labels=complexity_counts.index, autopct='%1.1f%%')\n",
        "    axes[1, 0].set_title('Complexity Distribution')\n",
        "    \n",
        "    # Time vs Quality scatter\n",
        "    axes[1, 1].scatter(df['workflow_time'], df['quality_score'], \n",
        "                      c=df['lines_of_code'], cmap='viridis', s=100)\n",
        "    axes[1, 1].set_title('Time vs Quality Score')\n",
        "    axes[1, 1].set_xlabel('Workflow Time (s)')\n",
        "    axes[1, 1].set_ylabel('Quality Score (/10)')\n",
        "    \n",
        "    # Token usage\n",
        "    axes[1, 2].bar(range(len(df)), df['tokens_used'], color='purple')\n",
        "    axes[1, 2].set_title('Token Usage by Task')\n",
        "    axes[1, 2].set_xlabel('Task Index')\n",
        "    axes[1, 2].set_ylabel('Tokens Used')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Display detailed results table\n",
        "    print(\"\\nüìã Detailed Results:\")\n",
        "    print(\"=\" * 80)\n",
        "    display_df = df[['task', 'workflow_time', 'quality_score', 'lines_of_code', 'complexity', 'tokens_used']]\n",
        "    print(display_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ùå No successful results to visualize\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
