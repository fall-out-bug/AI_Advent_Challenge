# Local Models Strategy
> Style: EN only, concise. Use this summary; details below are appendix.

## Summary (1‚Äëscreen)
- Local for: formatting, lint checks, boilerplate tests, structured refactors, first drafts.
- Cloud for: architecture/security decisions, complex reviews, stakeholder docs.
- Recommended: DeepSeek Coder V2 (code), Qwen2.5‚ÄëCoder (fast drafts), MiniLM‚Äërerank (RAG).
- Guardrails: no secrets in prompts; pin model/version; log decisions as MADR when switching stacks.

**Hybrid Approach: Cloud + Local Models**

---

## üéØ Philosophy

**Cloud models (Sonnet 4.5, GPT-5):** Complex reasoning, architecture decisions, security analysis
**Local models (Ollama, LM Studio):** Structured tasks, validation, formatting, first drafts

---

## üìä Task Delegation Matrix

| Task Type | Cloud | Local | Why Local Works |
|-----------|-------|-------|-----------------|
| **Architecture decisions** | ‚úÖ | ‚ùå | Requires deep reasoning |
| **Requirements elicitation** | ‚úÖ | ‚ùå | Needs business context understanding |
| **Code review (complex)** | ‚úÖ | ‚ùå | Requires security & pattern knowledge |
| **Security analysis** | ‚úÖ | ‚ùå | Needs vulnerability expertise |
| | | | |
| **Code formatting check** | ‚ùå | ‚úÖ | Rules-based, can load linting rules |
| **Docstring validation** | ‚ùå | ‚úÖ | Template matching, structural check |
| **Test generation (boilerplate)** | ‚ùå | ‚úÖ | Pattern-following with examples |
| **Code cleanup (imports, unused vars)** | ‚ùå | ‚úÖ | Rules-based refactoring |
| **First draft implementation** | ‚ùå | ‚úÖ | Following clear specifications |
| **Commit message generation** | ‚ùå | ‚úÖ | Conventional commits template |
| **Documentation updates** | ‚ùå | ‚úÖ | Following documentation template |
| **Type hint generation** | ‚ùå | ‚úÖ | Structural analysis + project patterns |

---

## üîß Recommended Local Models (Updated 2025)

### **For Code Tasks** (Developer role automation)

**DeepSeek Coder V2 236B** (Best overall - 2025)
- Latest DeepSeek model with superior code understanding
- Excellent at complex refactoring and architecture patterns
- Strong at following Clean Architecture principles
- **Use for:** Implementation, large refactoring, test generation, security code

**Qwen2.5-Coder 32B** (Excellent alternative)
- Alibaba's latest code model
- Very strong code quality and pattern recognition
- Good at long context and multi-file understanding
- **Use for:** Large refactoring, multi-file changes, complex algorithms

**CodeLlama 70B** (Established choice)
- Meta's proven code model
- Strong at understanding large codebases
- Good at Python ecosystem and frameworks
- **Use for:** Complex implementations, legacy code analysis

**StarCoder2 15B** (Lightweight option)
- Specialized for code completion and debugging
- Fast inference, good for routine tasks
- **Use for:** Quick fixes, code completion, simple refactoring

**Practical choice:** DeepSeek Coder V2 236B (if hardware allows) or Qwen2.5-Coder 32B

---

### **For Documentation/Planning** (Analyst/Tech Lead automation)

**Llama 3.3 70B Instruct** (Best for planning - 2025)
- Latest Llama with excellent reasoning and instruction following
- Strong at complex planning and technical documentation
- Good at understanding project context and requirements
- **Use for:** Requirements analysis, project planning, technical documentation

**Qwen2.5 72B Instruct** (Excellent alternative)
- Strong at structured output and template following
- Good at business analysis and stakeholder communication
- Excellent for planning documents and review notes
- **Use for:** Requirements drafts, planning documents, stakeholder summaries

**Mistral Large 2 123B** (Established choice)
- Proven instruction following and structured output
- Good at technical documentation and planning
- **Use for:** Review notes, checklists, technical planning

**Gemma 2 27B** (Lightweight option)
- Google's efficient model for documentation tasks
- Good at template-based content generation
- **Use for:** Basic documentation, checklists, simple planning

**Practical choice:** Llama 3.3 70B (for complex planning) or Qwen2.5 72B (balanced performance)

---

### üîÅ Extended Reasoning Replacements (2025 Update)

–ï—Å–ª–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ ¬´–æ–±–ª–∞—á–Ω—ã–π¬ª —É—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–µ:

- **Llama 3.3 70B Instruct** ‚Äî –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è complex reasoning; –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏, security analysis, –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

- **Qwen2.5 72B Instruct** ‚Äî —Å–∏–ª—å–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ GPT/Claude –¥–ª—è –¥–∏–∑–∞–π–Ω–∞, —Ä–µ–≤—å—é, –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏; –æ—Å–æ–±–µ–Ω–Ω–æ —Ö–æ—Ä–æ—à —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏ –∏ business context.

- **DeepSeek V3 671B** ‚Äî breakthrough –º–æ–¥–µ–ª—å –¥–ª—è deep reasoning; –º–æ–∂–µ—Ç –∑–∞–º–µ–Ω—è—Ç—å cloud –º–æ–¥–µ–ª–∏ –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤.

- **Grok-2 314B** (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ) ‚Äî xAI's latest –¥–ª—è complex reasoning –∏ technical discussions.

- **Mixtral 8√ó22B** ‚Äî proven choice –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (–∫–æ–¥ + —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è); —Ö–æ—Ä–æ—à –¥–ª—è tech lead –∑–∞–¥–∞—á.

**Hardware Requirements (2025):**
- 70B models: 48GB+ VRAM, 128K+ context
- 200B+ models: 96GB+ VRAM, optimized quantization needed
- 600B+ models: Multiple GPUs or specialized hardware

**–°–æ–≤–µ—Ç—ã –ø–æ —Ä–∞–±–æ—Ç–µ —Å –±–æ–ª—å—à–∏–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏:**
1. –°—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π —Ñ–∞–π–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, `prompts/{role}_system.md`) —Å –º–∏—Å—Å–∏–µ–π —Ä–æ–ª–∏, —á–µ–∫–ª–∏—Å—Ç–∞–º–∏, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏.
2. –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–æ–¥–º–µ—à–∏–≤–∞–π—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–ø–µ–∫–∏, —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞) —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π RAG/–∏–Ω–¥–µ–∫—Å.
3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: `temperature=0‚Äì0.4` –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, `top_p=0.8`, `max_tokens` –ø–æ —Ä–∞–∑–º–µ—Ä—É –∑–∞–¥–∞—á–∏.
4. –î–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ quantization (Q4_K_M –∏–ª–∏ Q5_K_M) ‚Äî —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å –∏—Ö –Ω–∞ 24‚Äì32‚ÄØGB VRAM.

---

## üöÄ 2025 Local Model Setup Guide

### **Recommended Stack**
1. **Ollama + Open WebUI** - easiest setup for most users
2. **LM Studio** - good for development and testing
3. **vLLM** - production deployment with high throughput
4. **Oobabooga WebUI** - advanced customization options

### **Model Download Strategy**
- **Start with smaller models** (7B-15B) for testing prompts
- **Scale up gradually** to larger models as needed
- **Use quantization** to fit larger models on available hardware
- **Cache frequently used models** for faster startup

### **Context Management**
- **Load project rules** (.cursorrules, architecture docs) into system prompt
- **Use RAG** for dynamic context (code snippets, recent changes)
- **Implement context windows** of 32K-128K minimum
- **Version control prompts** alongside code

### **Performance Optimization**
- **Batch processing** for routine tasks (linting, formatting)
- **GPU acceleration** for inference speed
- **Model caching** to reduce startup time
- **Parallel processing** for independent tasks

### **Integration with Cloud Workflow**
1. **Local models** handle routine tasks and first drafts
2. **Cloud models** validate critical decisions and complex reasoning
3. **Hybrid approach** maximizes efficiency and cost-effectiveness
4. **Fallback strategy** ensures work continues even with network issues

---

## üìã Specific Use Cases for Local Models

### **1. Code Quality Automation (Developer)**

**Task:** Validate code before sending to cloud for review

**Local model prompt:**
```
You are a code quality validator for a Python Clean Architecture project.

PROJECT RULES:
[Load entire .cursorrules file]

YOUR TASK:
1. Check if code follows layer boundaries (Domain ‚Üí Application ‚Üí Infrastructure)
2. Validate all functions have type hints
3. Check all public functions have docstrings with required sections
4. Verify no print() statements (use logging)
5. Check line length <88 characters
6. Validate imports are organized (stdlib ‚Üí third-party ‚Üí local)

REPORT FORMAT:
- ‚úÖ PASS: [what passed]
- ‚ùå FAIL: [what failed with line numbers]
- üí° SUGGESTION: [improvements]

CODE TO REVIEW:
[paste code]
```

**Why this works locally:**
- Rules-based validation
- Pattern matching
- No complex reasoning needed
- Can load full project rules into context

---

### **2. Docstring Generation (Developer)**

**Task:** Generate docstrings following project template

**Local model prompt:**
```
Generate Google-style docstring for Python function following this template:

TEMPLATE:
"""Brief description.

Purpose:
    Detailed explanation of what the function does.

Args:
    param_name: Parameter description.

Returns:
    Return value description.

Raises:
    ExceptionType: When this exception is raised.

Example:
    >>> result = function_name("example")
    >>> result
    'expected_output'
"""

PROJECT CONTEXT:
[Load examples from existing codebase]

FUNCTION TO DOCUMENT:
[paste function signature]

Generate ONLY the docstring, no other text.
```

**Why this works locally:**
- Template-based generation
- Examples from codebase provide patterns
- Structured output
- No complex reasoning required

---

### **3. Test Generation (Developer)**

**Task:** Generate boilerplate unit tests

**Local model prompt:**
```
Generate pytest unit tests following this structure:

PROJECT TEST PATTERNS:
[Load 2-3 example test files from tests/unit/]

REQUIREMENTS:
1. Use AAA pattern (Arrange, Act, Assert)
2. Mock external dependencies
3. Test edge cases
4. Use descriptive test names
5. Add docstrings to test functions

FUNCTION TO TEST:
[paste function code]

Generate complete test file with:
- Fixtures
- Test cases (happy path + edge cases + error cases)
- Mocks for dependencies
```

**Why this works locally:**
- Pattern-following from examples
- Structural generation
- Can load test examples into context
- Boilerplate code generation

---

### **4. First Draft Implementation (Developer)**

**Task:** Implement function following specification

**Local model prompt:**
```
Implement Python function following Clean Architecture principles.

PROJECT STRUCTURE:
[Load relevant interface/protocol definitions]

ARCHITECTURE RULES:
- Domain layer: No external dependencies
- Use dependency injection
- Type hints required (100%)
- Docstrings required for public functions
- Error handling with specific exceptions

CODING STANDARDS:
- PEP 8 compliance
- Line length <88 characters
- Functions ‚â§15 lines where practical

SPECIFICATION:
[Detailed spec from Tech Lead document]

Generate implementation with:
1. Function signature with type hints
2. Complete docstring
3. Implementation
4. Error handling
```

**Why this works locally:**
- Clear specification to follow
- Project patterns loaded as examples
- Structural code generation
- Can be reviewed by cloud model after

---

### **5. Commit Message Generation (Developer)**

**Task:** Generate conventional commit messages

**Local model prompt:**
```
Generate conventional commit message following this format:

FORMAT:
<type>(<scope>): <subject>

<body>

<footer>

TYPES: feat, fix, docs, style, refactor, test, chore

EXAMPLE:
feat(auth): add JWT token validation

Implement JWT token validation for API endpoints.
- Add token validation middleware
- Add unit tests for token validation
- Update documentation

JIRA-123

CHANGED FILES:
[git diff --name-only]

FILE CHANGES:
[git diff]

Generate commit message following the format above.
```

**Why this works locally:**
- Template-based
- Git diff provides all context
- Structured output
- Fast (no cloud API needed)

---

### **6. Documentation Updates (Analyst/Tech Lead)**

**Task:** Update README/docs after code changes

**Local model prompt:**
```
Update project documentation based on code changes.

DOCUMENTATION TEMPLATE:
[Load existing README.md structure]

DOCUMENTATION RULES:
- Keep consistent structure
- Update API references
- Add examples for new features
- Update installation if dependencies changed

CODE CHANGES:
[git diff or description of changes]

Update these sections:
1. API Reference (if public functions changed)
2. Usage Examples (if new features added)
3. Installation (if dependencies changed)

Generate updated documentation sections.
```

**Why this works locally:**
- Template-based updates
- Clear structure from existing docs
- Pattern-following
- Can load entire existing docs for context

---

### **7. Requirements First Draft (Analyst)**

**Task:** Create first draft of 1-pager from rough notes

**Local model prompt:**
```
Create requirements document (1-pager) from rough notes.

TEMPLATE:
# Epic [Number] ¬∑ [Title]

## Problem
[What problem are we solving?]

## Scope
**Must Have:**
- [List]

**Should Have:**
- [List]

**Out of Scope:**
- [List]

## Success Criteria
- [Measurable criteria]

## Constraints
- Security: [List]
- Operations: [List]
- Architecture: [List]

EXAMPLE 1-PAGER:
[Load example from previous epic]

ROUGH NOTES:
[User's brainstorming notes]

Generate 1-pager following the template. Keep it concise (max 1 page).
```

**Why this works locally:**
- Clear template to follow
- Example provides pattern
- Structured output
- First draft (will be refined by cloud model)

---

### **8. Code Review Checklist (Tech Lead)**

**Task:** Run automated checklist before human review

**Local model prompt:**
```
Run code review checklist for Clean Architecture project.

CHECKLIST:
‚úÖ Layer Boundaries
- [ ] No upward dependencies (Domain ‚Üí Application ‚Üí Infrastructure)
- [ ] Interfaces defined in domain layer
- [ ] Implementations in infrastructure layer

‚úÖ Code Quality
- [ ] Type hints 100%
- [ ] Docstrings for public functions
- [ ] No print() statements
- [ ] Functions ‚â§15 lines where practical
- [ ] No hardcoded secrets

‚úÖ Testing
- [ ] Unit tests for new functions
- [ ] Tests follow AAA pattern
- [ ] Mocks for external dependencies

‚úÖ Security
- [ ] Input validation present
- [ ] No SQL injection risks
- [ ] No path traversal risks
- [ ] Exceptions wrapped (no info leakage)

CODE TO REVIEW:
[paste code or git diff]

REPORT:
For each checklist item:
‚úÖ PASS or ‚ùå FAIL with line numbers and explanation
```

**Why this works locally:**
- Checklist-based validation
- Clear rules to follow
- Pattern matching
- Fast automated first pass

---

## üîÑ Hybrid Workflow Examples

### **Workflow 1: Code Implementation**

```
1. [CLOUD] Architect: Design interface contracts (Sonnet 4.5)
2. [CLOUD] Tech Lead: Create implementation spec (Sonnet 4.5)
3. [LOCAL] Developer: Generate first draft (DeepSeek Coder)
4. [LOCAL] Developer: Run quality checklist (DeepSeek Coder)
5. [CLOUD] Developer: Refine & complex logic (Sonnet 4.5)
6. [LOCAL] Developer: Generate tests (DeepSeek Coder)
7. [CLOUD] Tech Lead: Final review (Sonnet 4.5)
```

**Cost savings:** Steps 3, 4, 6 = 3 cloud API calls saved per implementation

---

### **Workflow 2: Epic Planning**

```
1. [LOCAL] Analyst: First draft 1-pager from notes (Mistral)
2. [CLOUD] Analyst: Refine requirements (GPT-5)
3. [CLOUD] Architect: Design architecture (Sonnet 4.5)
4. [LOCAL] Tech Lead: Generate checklist template (Mistral)
5. [CLOUD] Tech Lead: Fill in technical details (Sonnet 4.5)
6. [LOCAL] Developer: Generate task breakdown (Mistral)
```

**Cost savings:** Steps 1, 4, 6 = 3 cloud API calls saved per epic

---

### **Workflow 3: Code Review**

```
1. [LOCAL] Run automated checklist (DeepSeek Coder)
2. [LOCAL] Check docstrings & formatting (DeepSeek Coder)
3. [CLOUD] Review architecture compliance (Sonnet 4.5)
4. [CLOUD] Security analysis (Sonnet 4.5)
5. [LOCAL] Generate review summary (Mistral)
```

**Cost savings:** Steps 1, 2, 5 = 3 cloud API calls saved per review

---

## ‚öôÔ∏è Setup Guide

### **Option 1: Ollama (Easiest) - 2025 Setup**

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull recommended models (2025)
# For Code:
ollama pull deepseek-coder-v2:236b      # Best for complex code
ollama pull qwen2.5-coder:32b           # Excellent alternative
ollama pull starcoder2:15b              # Lightweight option

# For Documentation/Planning:
ollama pull llama3.3:70b-instruct       # Best for planning
ollama pull qwen2.5:72b-instruct        # Excellent alternative
ollama pull gemma2:27b                  # Lightweight option

# For Extended Reasoning:
ollama pull deepseek-v3:671b            # Advanced reasoning (requires powerful hardware)
ollama pull llama3.3:70b-instruct       # Balanced reasoning

# Use in scripts
ollama run qwen2.5-coder:32b "Your prompt here"
```

**Resource requirements (2025):**
- **15B models** (StarCoder2): 10GB RAM, 8GB VRAM (quantized: 6GB)
- **27B models** (Gemma 2): 18GB RAM, 14GB VRAM (quantized: 10GB)
- **32B models** (Qwen2.5-Coder): 20GB RAM, 18GB VRAM (quantized: 12GB)
- **70B models** (Llama 3.3): 48GB RAM, 40GB VRAM (quantized: 24GB)
- **236B models** (DeepSeek V2): 140GB RAM, 120GB VRAM (quantized: 70GB)
- **671B models** (DeepSeek V3): 400GB+ RAM, multiple GPUs required

**Quantization recommendations:**
- Use **Q4_K_M** for best balance (quality/size)
- Use **Q5_K_M** for slightly better quality
- Use **Q8_0** if you have VRAM to spare

---

### **Option 2: LM Studio (GUI)**

1. Download from lmstudio.ai
2. Download models:
   - `deepseek-ai/deepseek-coder-33b-instruct-GGUF`
   - `TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF`
3. Load model and use chat interface or API

---

### **Option 3: Text Generation Web UI**

```bash
# Clone repo
git clone https://github.com/oobabooga/text-generation-webui
cd text-generation-webui

# Install
./start_linux.sh  # or start_windows.bat

# Download models from HuggingFace
# Use web interface at localhost:7860
```

---

## üìù Integration Examples

### **Pre-commit Hook with Local Model**

```bash
#!/bin/bash
# .git/hooks/pre-commit

echo "Running local model code quality check..."

# Get staged Python files
FILES=$(git diff --cached --name-only --diff-filter=ACM | grep '\.py$')

if [ -z "$FILES" ]; then
    exit 0
fi

# Check each file with local model
for FILE in $FILES; do
    echo "Checking $FILE..."

    PROMPT="Check Python code quality following PEP 8:
$(cat .cursorrules)

CODE:
$(cat $FILE)

Report only violations, be concise."

    RESULT=$(ollama run deepseek-coder:33b-instruct "$PROMPT")

    if echo "$RESULT" | grep -q "‚ùå FAIL"; then
        echo "‚ùå Quality check failed for $FILE"
        echo "$RESULT"
        exit 1
    fi
done

echo "‚úÖ Local quality check passed"
```

---

### **Automated Docstring Generator**

```python
#!/usr/bin/env python3
"""Generate docstrings for functions missing them."""

import ast
import subprocess
from pathlib import Path

def get_functions_without_docstrings(file_path):
    """Find functions without docstrings."""
    with open(file_path) as f:
        tree = ast.parse(f.read())

    missing = []
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            if not ast.get_docstring(node):
                missing.append(node)
    return missing

def generate_docstring(function_code):
    """Generate docstring using local model."""
    prompt = f"""Generate Google-style docstring for:

{function_code}

Include: Purpose, Args, Returns, Raises, Example.
Output ONLY the docstring."""

    result = subprocess.run(
        ["ollama", "run", "deepseek-coder:33b-instruct", prompt],
        capture_output=True,
        text=True
    )
    return result.stdout.strip()

# Usage
for py_file in Path("src").rglob("*.py"):
    functions = get_functions_without_docstrings(py_file)
    for func in functions:
        docstring = generate_docstring(ast.unparse(func))
        print(f"Generated docstring for {func.name}:")
        print(docstring)
```

---

## üí∞ Cost Analysis (Updated 2025)

### **Cloud Only Approach**

Epic 21 (example):
- Architect review: 10 Sonnet calls √ó $0.015 = $0.15
- Tech Lead planning: 20 Sonnet calls √ó $0.015 = $0.30
- Developer implementation: 100 Sonnet calls √ó $0.015 = $1.50
- Code reviews: 30 Sonnet calls √ó $0.015 = $0.45

**Total: ~$2.40 per epic**

---

### **Hybrid Approach (Cloud + Local 2025)**

**Option A: Budget Setup (70B local models)**
- Architect review: 10 Sonnet calls √ó $0.015 = $0.15
- Tech Lead planning: 8 Sonnet + 12 Local (free) = $0.12
- Developer: 30 Sonnet + 70 Local (free) = $0.45
- Code reviews: 8 Sonnet + 22 Local (free) = $0.12

**Total: ~$0.84 per epic**
**Savings: 65% reduction in API costs**

**Option B: Advanced Setup (236B+ local models)**
- Architect review: 5 Sonnet + 5 Local (complex reasoning) = $0.075
- Tech Lead planning: 5 Sonnet + 15 Local = $0.075
- Developer: 20 Sonnet + 80 Local (advanced codegen) = $0.30
- Code reviews: 5 Sonnet + 25 Local = $0.075

**Total: ~$0.525 per epic**
**Savings: 78% reduction in API costs**

**Hardware Investment ROI:**
- 70B setup: ~$1,500 GPU (RTX 4090) ‚Üí Break-even at ~50 epics
- 236B setup: ~$5,000 GPU setup (2x RTX 4090) ‚Üí Break-even at ~130 epics
- 671B setup: ~$15,000+ (multiple A100/H100) ‚Üí Enterprise use only

**Monthly Comparison (10 epics):**
- Cloud only: $24.00/month
- Hybrid (70B): $8.40/month + hardware amortization
- Hybrid (236B): $5.25/month + hardware amortization

---

## üéØ Quick Decision Guide

**Use Local Models When:**
- ‚úÖ Task is template-based or rules-based
- ‚úÖ You can provide complete examples/context
- ‚úÖ Output will be reviewed anyway (first draft)
- ‚úÖ Speed is more important than perfection
- ‚úÖ Privacy is important (sensitive code)
- ‚úÖ You're doing many similar tasks (batch processing)

**Use Cloud Models When:**
- ‚úÖ Complex reasoning required
- ‚úÖ Architecture or security decisions
- ‚úÖ Novel problems (not seen before)
- ‚úÖ Final review before production
- ‚úÖ Deep understanding of business context needed

---

## üìä Recommended Split by Role (Updated 2025)

### **With 70B Local Models** (Llama 3.3, Qwen2.5)

| Role | Cloud % | Local % | Local Use Cases |
|------|---------|---------|-----------------|
| **Analyst** | 70% | 30% | First drafts, simple requirements, checklists |
| **Architect** | 90% | 10% | Diagram generation, template filling, preliminary analysis |
| **Tech Lead** | 60% | 40% | Task breakdown, checklists, planning templates, risk analysis |
| **Developer** | 40% | 60% | First drafts, tests, formatting, refactoring, boilerplate |

### **With 236B+ Local Models** (DeepSeek V2, DeepSeek V3)

| Role | Cloud % | Local % | Local Use Cases |
|------|---------|---------|-----------------|
| **Analyst** | 60% | 40% | Requirements drafts, analysis, stakeholder docs |
| **Architect** | 70% | 30% | Preliminary architecture, security analysis, design review |
| **Tech Lead** | 50% | 50% | Full planning, risk assessment, technical decisions |
| **Developer** | 30% | 70% | Complex implementations, advanced refactoring, architecture |

**Note:** Even with powerful local models, keep **critical security decisions** and **final production reviews** in cloud models (Sonnet 4.5) for highest quality assurance.

---

## üìä 2025 Local vs Cloud Comparison

| Aspect | Cloud (Sonnet 4.5, GPT-5) | Local 70B (Llama 3.3, Qwen2.5) | Local 236B+ (DeepSeek V2/V3) |
|--------|---------------------------|--------------------------------|------------------------------|
| **Code Quality** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Architecture Reasoning** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Security Analysis** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Documentation** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Speed** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Cost** | $$ per call | Free after hardware | Free after hardware |
| **Privacy** | Sends to cloud | 100% local | 100% local |
| **Context Length** | 200K+ | 128K+ | 128K-256K+ |
| **Setup Complexity** | None | Medium | High |
| **Hardware Required** | None | 40GB VRAM | 120GB+ VRAM |

---

## üéØ Final Recommendations (2025 Edition)

### **Minimum Setup (Budget: $0-1,500)**
**Use Cloud Only** or **70B Local Models**
- Qwen2.5-Coder 32B for code tasks
- Llama 3.3 70B for planning/docs
- Keep Sonnet 4.5 for critical decisions
- **Use case:** Solo developers, small teams

### **Recommended Setup (Budget: $3,000-5,000)**
**Hybrid: 70B Local + Cloud**
- Llama 3.3 70B + Qwen2.5 72B for most work
- DeepSeek Coder V2 236B for complex code (if feasible)
- Sonnet 4.5 for architecture and security
- **Use case:** Professional developers, medium teams

### **Advanced Setup (Budget: $10,000+)**
**Hybrid: 236B+ Local + Cloud**
- DeepSeek V3 671B for advanced reasoning
- DeepSeek Coder V2 236B for code
- Qwen2.5 72B for documentation
- Sonnet 4.5 only for final validation
- **Use case:** Large teams, enterprises, research

---

## üí° Key Takeaways

1. **2025 local models** (especially 70B+ class) can **replace cloud models** for 60-80% of routine tasks
2. **DeepSeek V3 671B** and **Llama 3.3 70B** offer **near-cloud quality** at zero ongoing cost
3. **Privacy-sensitive projects** can now work **entirely locally** with minimal quality loss
4. **Hardware investment** pays off after 50-130 epics depending on setup
5. **Hybrid approach remains optimal**: local for routine, cloud for critical

**Summary:** Local models are now competitive with cloud models for most tasks. Use local models for **structured, repeatable work AND complex implementations**, keeping cloud models only for **critical security decisions and final production validation**.

**2025 Strategy:** Invest in **70B+ local models** for daily work, use **cloud models** (Sonnet 4.5) as validators and for highest-stakes decisions. This maximizes both **cost efficiency** and **quality assurance**.
