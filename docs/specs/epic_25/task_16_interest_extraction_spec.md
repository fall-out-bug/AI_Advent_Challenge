# Task 16 Â· Interest Extraction & Profile Enrichment

**Epic**: EP25 - Personalised Butler
**Task**: Task 16 from Epic 25 Backlog
**Owner**: Dev A (Application) + Dev B (Infrastructure)
**Estimated Effort**: 2-3 days
**Date**: 2025-11-18

---

## Overview

Extend memory summarization to automatically extract and track user interests from conversations. Butler will adapt responses based on detected topics (e.g., "Python", "LLM orchestration", "Telegram bots").

**Key Goal**: Make Butler progressively smarter about what the user cares about, without requiring explicit configuration.

---

## Current State

### Existing Implementation âœ…
- âœ… `UserProfile.preferred_topics: List[str]` field exists but is empty by default
- âœ… Memory compression logic in `PersonalizedReplyUseCase._compress_memory()`
- âœ… Persona prompt includes `{preferred_topics}` placeholder in templates
- âœ… Memory summarization via LLM (produces summary text only)

### Gaps to Address ðŸ”§
- âŒ Summarization doesn't extract topics
- âŒ `preferred_topics` is never populated
- âŒ Topics aren't used to enrich responses (just shown in prompt)
- âŒ No validation to prevent sensitive data in topics

---

## Requirements

### Functional Requirements

**FR-1**: Extract Topics During Summarization
- During memory compression (`event_count > 50`), LLM should:
  - Analyze conversation history
  - Identify recurring topics, technologies, domains
  - Output structured data: `summary` + `interests`
- Example topics: "Python", "Docker", "Machine Learning", "API design", "Telegram bots"

**FR-2**: Update Profile with Interests
- After successful topic extraction:
  - Update `UserProfile.preferred_topics` with new list (3-7 items)
  - Preserve stability: merge new topics with existing (avoid churn)
  - Save updated profile to Mongo

**FR-3**: Use Topics in Persona Prompt
- `PersonalizationService.build_personalized_prompt()` already includes `preferred_topics`
- Ensure prompt guides Butler to:
  - Use relevant examples from user's domains
  - Suggest solutions in familiar technologies
  - Adapt wording to user's context

**FR-4**: Data Privacy & Safety
- **Never store sensitive data** as interests:
  - No API keys, tokens, passwords
  - No user IDs, names, personal info
  - No file paths, URLs with sensitive info
- Focus on **thematic topics only**: technologies, concepts, domains

**FR-5**: Validation & Testing
- Verify that after 3-5 themed conversations:
  - `preferred_topics` contains relevant topics
  - Butler replies reference these topics naturally
  - No sensitive data leaks into profile

---

## Design

### Architecture Layers

```
PersonalizedReplyUseCase
  â†“ (when event_count > 50)
_compress_memory()
  â†“
InterestExtractionService  â† NEW
  â†“
LLM (interest extraction prompt)
  â†“
Parse response (summary + interests)
  â†“
Merge topics with existing profile
  â†“
Update UserProfile.preferred_topics
  â†“
Save to Mongo via profile_repo
```

### Component Responsibilities

**1. InterestExtractionService** (NEW)
- **Location**: `src/application/personalization/interest_extraction_service.py`
- **Responsibilities**:
  - Build LLM prompt for interest extraction
  - Parse LLM response (extract `summary` + `interests`)
  - Merge new interests with existing topics (stable list)
  - Validate extracted topics (no sensitive data)
- **Interface**:
  ```python
  class InterestExtractionService:
      async def extract_interests(
          self,
          events: List[UserMemoryEvent],
          existing_topics: List[str]
      ) -> Tuple[str, List[str]]:
          """
          Extract summary and interests from conversation history.

          Args:
              events: List of memory events to analyze.
              existing_topics: Current preferred_topics from profile.

          Returns:
              Tuple of (summary_text, interests_list).
              interests_list is stable (3-7 items), no sensitive data.
          """
  ```

**2. PersonalizedReplyUseCase** (MODIFIED)
- **Changes**:
  - Inject `InterestExtractionService` dependency
  - In `_compress_memory()`:
    - Call `interest_extraction_service.extract_interests()` instead of basic summarization
    - Get both `summary` and `interests`
    - Update profile with new interests via `profile.with_topics(interests)`
    - Save updated profile

**3. UserProfile** (ENHANCED)
- **Add method**:
  ```python
  def with_topics(self, topics: List[str]) -> "UserProfile":
      """Create new profile with updated preferred_topics.

      Args:
          topics: New list of preferred topics (3-7 items).

      Returns:
          New UserProfile with updated topics and timestamp.
      """
  ```

**4. Interest Extraction Prompt** (NEW)
- **Location**: `config/persona_templates.yaml`
- **Add section**:
  ```yaml
  interest_extraction_prompt: |
    Analyze the following conversation history and extract:
    1. Summary: Brief summary of what was discussed (max 300 tokens)
    2. Interests: List of 3-7 recurring topics, technologies, or domains the user cares about

    Rules for interests:
    - Focus on technologies (Python, Docker), concepts (RAG, Clean Architecture), domains (ML, Telegram bots)
    - Use clear, canonical names (e.g., "Python" not "python coding")
    - Exclude sensitive data (API keys, passwords, personal info, file paths)
    - Prefer stability: if user mentioned topic before, keep it

    Output format (JSON):
    {
      "summary": "User discussed Python development and asked about...",
      "interests": ["Python", "Docker", "Clean Architecture", "Telegram bots"]
    }

    Conversation history:
    {events}

    Existing interests: {existing_topics}

    JSON output:
  ```

---

## Implementation Plan

### Stage 1: Interest Extraction Service (1 day, Dev A)

**Tasks**:
1. Create `InterestExtractionService` class
2. Implement `extract_interests()` method:
   - Build prompt from template
   - Call LLM with prompt
   - Parse JSON response
   - Validate topics (no sensitive data regex check)
   - Merge with existing topics (stable top-7)
3. Add interest extraction prompt to `config/persona_templates.yaml`
4. Add unit tests:
   - Test topic extraction from sample conversations
   - Test merging logic (new + existing â†’ stable list)
   - Test sensitive data filtering (API keys, tokens rejected)

**Deliverables**:
- `src/application/personalization/interest_extraction_service.py`
- Updated `config/persona_templates.yaml`
- `tests/unit/application/personalization/test_interest_extraction_service.py`

---

### Stage 2: Profile Enhancement (0.5 day, Dev A)

**Tasks**:
1. Add `with_topics()` method to `UserProfile`:
   - Immutable update pattern (like `with_summary()`)
   - Update `updated_at` timestamp
2. Add unit tests for `with_topics()`

**Deliverables**:
- Updated `src/domain/personalization/user_profile.py`
- Updated `tests/unit/domain/personalization/test_user_profile.py`

---

### Stage 3: Use Case Integration (0.5 day, Dev A)

**Tasks**:
1. Update `PersonalizedReplyUseCase.__init__()`:
   - Add `interest_extraction_service` dependency
2. Modify `_compress_memory()`:
   - Replace `_summarize_events()` call with `interest_extraction_service.extract_interests()`
   - Get `(summary, interests)` tuple
   - Update profile: `profile.with_summary(summary).with_topics(interests)`
   - Save updated profile
3. Add structured logging:
   - Log extracted interests
   - Log topics added/removed

**Deliverables**:
- Updated `src/application/personalization/use_cases/personalized_reply.py`
- Updated integration tests

---

### Stage 4: Factory & DI (0.25 day, Dev B)

**Tasks**:
1. Update `create_personalized_use_cases()` factory:
   - Instantiate `InterestExtractionService`
   - Pass to `PersonalizedReplyUseCase`
2. Wire LLM client dependency

**Deliverables**:
- Updated `src/infrastructure/personalization/factory.py`

---

### Stage 5: Testing & Validation (0.75 day, QA)

**Tasks**:
1. **Integration test**: Themed conversations
   - Test scenario:
     - Send 55 messages about Python, Docker, Clean Architecture
     - Trigger compression
     - Verify `preferred_topics` contains ["Python", "Docker", "Clean Architecture"]
   - File: `tests/integration/personalization/test_interest_extraction_flow.py`

2. **E2E test**: Interest-aware responses
   - Test scenario:
     - User has `preferred_topics = ["Python", "Telegram bots"]`
     - Ask general question: "How to handle errors?"
     - Verify Butler response mentions Python or Telegram context
   - File: `tests/e2e/personalization/test_interest_aware_replies.py`

3. **Characterization test**: Sensitive data filtering
   - Test with conversations containing:
     - API keys: `sk-1234567890abcdef`
     - Passwords: `password=mysecret`
     - File paths: `/home/user/secret.txt`
   - Verify these are NOT in `preferred_topics`
   - File: `tests/unit/application/personalization/test_sensitive_data_filtering.py`

**Deliverables**:
- 3 new test files (integration + E2E + unit)
- Test coverage â‰¥80% for new service

---

## Technical Details

### Interest Merging Logic

```python
def _merge_interests(
    existing: List[str],
    new: List[str],
    max_items: int = 7
) -> List[str]:
    """Merge new interests with existing, preserving stability.

    Algorithm:
    1. Combine existing + new (deduplicate, case-insensitive)
    2. Rank by frequency (topics in both lists ranked higher)
    3. Keep top N (default 7)
    4. Preserve order: existing topics first, then new

    Args:
        existing: Current preferred_topics from profile.
        new: Newly extracted topics from conversation.
        max_items: Maximum topics to keep (default 7).

    Returns:
        Merged list of topics (max_items length).

    Example:
        >>> existing = ["Python", "Docker"]
        >>> new = ["Python", "Clean Architecture", "Telegram bots"]
        >>> _merge_interests(existing, new, max_items=4)
        ['Python', 'Docker', 'Clean Architecture', 'Telegram bots']
    """
    # Normalize: lowercase for comparison
    existing_normalized = {t.lower(): t for t in existing}
    new_normalized = {t.lower(): t for t in new}

    # Priority: topics in both lists (confirmed interests)
    confirmed = []
    for key in existing_normalized:
        if key in new_normalized:
            confirmed.append(existing_normalized[key])

    # Add remaining existing topics
    for topic in existing:
        if topic not in confirmed:
            confirmed.append(topic)

    # Add new topics (if space remains)
    for topic in new:
        if topic not in confirmed and len(confirmed) < max_items:
            confirmed.append(topic)

    return confirmed[:max_items]
```

### Sensitive Data Patterns (Regex)

```python
SENSITIVE_PATTERNS = [
    r"(api[_-]?key|token|password|secret|bearer)\s*[=:]\s*['\"]?[\w-]+",  # API keys
    r"sk-[a-zA-Z0-9]{20,}",  # OpenAI-style keys
    r"/home/[\w/]+|/var/[\w/]+|C:\\Users\\[\w\\]+",  # File paths
    r"\d{13,19}",  # User IDs (Telegram)
    r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",  # Emails
]

def _contains_sensitive_data(text: str) -> bool:
    """Check if text contains sensitive data patterns.

    Args:
        text: Topic candidate string.

    Returns:
        True if sensitive data detected.
    """
    for pattern in SENSITIVE_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            return True
    return False
```

---

## Prompt Engineering

### Interest Extraction Prompt (Structured)

```
You are analyzing a conversation to extract user interests.

Rules:
1. Identify 3-7 recurring topics, technologies, or domains the user discusses
2. Use canonical names (e.g., "Python", "Docker", "Clean Architecture")
3. Focus on: programming languages, frameworks, concepts, domains
4. EXCLUDE: API keys, passwords, personal info, file paths, URLs with secrets
5. Prefer stability: if topic mentioned before, keep it

Conversation history:
- User: I'm learning Python and working on a Telegram bot
- Butler: Excellent choice, sir. Python is well-suited for Telegram bot development.
- User: How do I deploy it with Docker?
- Butler: Docker containerization is recommended for production deployments...
[... more events ...]

Existing interests from previous conversations:
["Python", "Telegram bots"]

Extract:
1. Summary (max 300 tokens): Brief overview of what was discussed
2. Interests (3-7 items): List of topics user cares about

Output JSON:
{
  "summary": "User discussed...",
  "interests": ["Python", "Telegram bots", "Docker", "API deployment"]
}

JSON:
```

**Expected LLM Response**:
```json
{
  "summary": "User is learning Python for Telegram bot development and asked about Docker deployment strategies. Discussed containerization best practices and production deployment workflows.",
  "interests": ["Python", "Telegram bots", "Docker", "API deployment", "Clean Architecture"]
}
```

---

## Metrics & Observability

### New Metrics

```python
# In src/infrastructure/personalization/metrics.py

interest_extraction_total = Counter(
    "interest_extraction_total",
    "Total interest extraction operations",
    ["status"]  # success, parse_error, llm_error
)

interest_extraction_duration_seconds = Histogram(
    "interest_extraction_duration_seconds",
    "Interest extraction operation duration",
)

user_interests_updated_total = Counter(
    "user_interests_updated_total",
    "Total user profile interests updates"
)

user_interests_count = Histogram(
    "user_interests_count",
    "Number of interests per user profile",
    buckets=[0, 1, 3, 5, 7, 10]
)
```

### Logging

```python
logger.info(
    "Interests extracted and profile updated",
    extra={
        "user_id": user_id,
        "new_interests": interests,
        "existing_interests": profile.preferred_topics,
        "merged_interests": updated_profile.preferred_topics,
        "compression_duration_ms": duration_ms,
    }
)
```

---

## Configuration

### Environment Variables (Optional)

```bash
# In docker-compose or .env
INTEREST_EXTRACTION_ENABLED=true  # Default: true
INTEREST_EXTRACTION_MAX_TOPICS=7  # Default: 7 (3-7 range)
INTEREST_EXTRACTION_LLM_TEMPERATURE=0.3  # Lower = more deterministic
```

### Settings Update

```python
# In src/infrastructure/config/settings.py

class PersonalizationSettings(BaseSettings):
    # ... existing settings ...

    interest_extraction_enabled: bool = True
    interest_extraction_max_topics: int = Field(default=7, ge=3, le=10)
    interest_extraction_llm_temperature: float = Field(default=0.3, ge=0.0, le=1.0)
```

---

## Testing Strategy

### Unit Tests

**1. Interest Extraction Service**
- âœ… Test topic extraction from sample conversations
- âœ… Test JSON parsing (valid and malformed responses)
- âœ… Test merging logic (existing + new â†’ stable list)
- âœ… Test sensitive data filtering (API keys, passwords rejected)
- âœ… Test max_topics constraint (3-7 items)

**2. Profile with_topics() Method**
- âœ… Test immutable update
- âœ… Test timestamp update
- âœ… Test validation (empty list â†’ valid)

### Integration Tests

**3. Full Compression Flow**
- âœ… Scenario: 55 Python/Docker messages â†’ verify topics extracted
- âœ… Scenario: Compression with existing topics â†’ verify merge logic
- âœ… Scenario: LLM failure â†’ graceful degradation (summary only)

### E2E Tests

**4. Interest-Aware Responses**
- âœ… User with `preferred_topics = ["Python", "Telegram bots"]`
- âœ… Ask generic question â†’ verify response includes relevant context
- âœ… Metric check: verify `user_interests_count` histogram updated

**5. Characterization Tests**
- âœ… Conversations with sensitive data â†’ verify topics clean
- âœ… Edge cases: very long topic names, special characters

---

## Rollout Plan

### Phase 1: Development & Testing (3 days)
- âœ… Implement InterestExtractionService
- âœ… Update PersonalizedReplyUseCase
- âœ… Write comprehensive tests
- âœ… Feature flag: `INTEREST_EXTRACTION_ENABLED=false` (disabled)

### Phase 2: Staging Validation (1 week)
- âœ… Deploy to staging
- âœ… Enable feature flag: `INTEREST_EXTRACTION_ENABLED=true`
- âœ… Monitor metrics: `interest_extraction_total`, `user_interests_count`
- âœ… Manual testing: themed conversations
- âœ… Verify no sensitive data leaks

### Phase 3: Production Rollout (Gradual)
- âœ… Enable for 10% of users (canary)
- âœ… Monitor error rates, extraction quality
- âœ… Gradual rollout: 25% â†’ 50% â†’ 100%
- âœ… Fallback: disable flag if issues detected

---

## Success Criteria

### Functional
- âœ… After 3-5 themed conversations, `preferred_topics` populated
- âœ… Butler responses include relevant examples from user's domains
- âœ… No sensitive data in `preferred_topics` (validated via tests)

### Performance
- âœ… Interest extraction < 2s (P95)
- âœ… No significant increase in compression duration
- âœ… Error rate < 5% (graceful fallback if LLM fails)

### Quality
- âœ… Topics are relevant and stable (no churn)
- âœ… Topic names are canonical (e.g., "Python" not "python coding")
- âœ… Test coverage â‰¥80% for new service

---

## Risk Mitigation

| Risk | Impact | Likelihood | Mitigation |
| --- | --- | --- | --- |
| LLM extracts sensitive data | High | Medium | Regex validation + manual review of logs in staging |
| Topic churn (list changes often) | Medium | Medium | Stable merging logic (existing topics prioritized) |
| LLM fails to parse JSON | Medium | Low | Graceful fallback: use summary only, log parse error |
| Topics too generic ("technology") | Low | Medium | Prompt engineering: prefer specific technologies |
| Performance degradation | Medium | Low | Async extraction, monitor latency metrics |

---

## Future Enhancements (Out of Scope)

1. **Topic Decay**: Remove topics not mentioned in last 100 messages
2. **Topic Ranking**: Weight topics by recency and frequency
3. **Multi-Language Topics**: Extract topics in English even for RU conversations
4. **User Feedback**: `/topics` command to view/edit interests
5. **Semantic Clustering**: Group similar topics (Python + FastAPI â†’ Backend Development)

---

## Acceptance Checklist

- [ ] `InterestExtractionService` implemented with unit tests
- [ ] `UserProfile.with_topics()` method added
- [ ] `PersonalizedReplyUseCase._compress_memory()` updated
- [ ] Interest extraction prompt added to `persona_templates.yaml`
- [ ] Sensitive data filtering tested and validated
- [ ] Integration test: themed conversations â†’ topics extracted
- [ ] E2E test: topics reflected in replies
- [ ] Metrics added and exposed via `/metrics`
- [ ] Feature flag `INTEREST_EXTRACTION_ENABLED` implemented
- [ ] Documentation updated (user guide, operational docs)
- [ ] Code review passed
- [ ] Staging validation complete

---

## Documentation Updates

### User Guide

Add section to `docs/guides/personalized_butler_user_guide.md`:

```markdown
## ÐÐ´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ñ Ð¿Ð¾Ð´ Ð²Ð°ÑˆÐ¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹

Butler Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°ÐµÑ‚ Ñ‚ÐµÐ¼Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚, Ð¸ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð¿Ð¾Ð´ Ð²Ð°Ñˆ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚.

**ÐšÐ°Ðº ÑÑ‚Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚**:
- Ð’Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Butler Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð°ÑˆÐ¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¸ Ð·Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°ÐµÑ‚ Ñ‚ÐµÐ¼Ñ‹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, "Python", "Docker", "Telegram Ð±Ð¾Ñ‚Ñ‹")
- ÐšÐ¾Ð³Ð´Ð° Ð²Ñ‹ Ð·Ð°Ð´Ð°Ñ‘Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, Butler Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð· Ð²Ð°ÑˆÐ¸Ñ… Ð¾Ð±Ð»Ð°ÑÑ‚ÐµÐ¹
- Ð¢ÐµÐ¼Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑŽÑ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÐºÐ°Ð¶Ð´Ñ‹Ðµ ~50 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹

**ÐšÐ¾Ð½Ñ„Ð¸Ð´ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ**:
- Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚ÐµÐ¼Ñ‹ (Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸, ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸)
- API ÐºÐ»ÑŽÑ‡Ð¸, Ð¿Ð°Ñ€Ð¾Ð»Ð¸ Ð¸ Ð»Ð¸Ñ‡Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ ÐÐ• ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ
- Ð’ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ…Ñ€Ð°Ð½ÑÑ‚ÑÑ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ Ð² Mongo (Ð½Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ Ð² external SaaS)

**ÐŸÑ€Ð¸Ð¼ÐµÑ€**:
- Ð•ÑÐ»Ð¸ Ð²Ñ‹ Ñ‡Ð°ÑÑ‚Ð¾ ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¾ Python Ð¸ Docker, Butler Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°Ñ‚ÑŒ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð² Python Ð¸ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ñ‚ÑŒ Docker Ð¿Ñ€Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾Ð¹ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸
```

### Operational Docs

Add to `docs/operational/metrics.md`:

```markdown
## Interest Extraction Metrics

- `interest_extraction_total{status}` â€” Total interest extraction operations (success/parse_error/llm_error)
- `interest_extraction_duration_seconds` â€” Interest extraction latency histogram
- `user_interests_updated_total` â€” Total profile updates with new interests
- `user_interests_count` â€” Number of interests per user (histogram, buckets: 0,1,3,5,7,10)

**Alerts**:
- High parse error rate: >10% parse errors in 5min
- Slow extractions: P95 >5s
```

---

**Spec Version**: 1.0
**Status**: Ready for implementation
**Estimated Effort**: 2-3 days
**Dependencies**: Epic 25 TL-01 to TL-07 complete
