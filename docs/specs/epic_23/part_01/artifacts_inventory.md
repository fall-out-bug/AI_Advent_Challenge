# Epic 23 · Artifacts Inventory

**Epic:** EP23 – Observability & Benchmark Enablement  
**Completion Date:** 2025-11-16  
**Maintained by:** Dev A (cursor_dev_a_v1)

## Purpose

This document provides a comprehensive inventory of all artifacts produced during Epic 23 implementation, organized by stage (TL-01 through TL-08). Each artifact includes a path, description, purpose, and related test/validation evidence.

---

## TL-01: Benchmark Dataset Seeding

### Data Artifacts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `data/benchmarks/snapshots/2025-11-15/channel_counts.json` | Snapshot of seeded record counts per channel (5 channels × 30 digests + 30 review reports each) | Validates dataset completeness | Used in TL-01 DoD |
| `data/benchmarks/snapshots/2025-11-15/ru_spotcheck.md` | RU localization spot-check checklist with 5 samples per channel | Validates RU language fidelity | `docs/specs/epic_23/checklists/ru_localization_spotcheck.md` |
| `data/benchmarks/snapshots/2025-11-15/dataset_audit.json` | Output of `verify_benchmark_counts.py` audit script | Validates ≥30 records per channel + schema fields | Generated by `scripts/quality/analysis/verify_benchmark_counts.py` |

### Scripts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `scripts/quality/analysis/seed_benchmark_data.py` | CLI script for seeding benchmark data into MongoDB | Seeding pipeline entry point | Used in TL-01 execution |
| `scripts/quality/analysis/verify_benchmark_counts.py` | Dataset audit script verifying coverage and schema | Dataset quality gate | Added in TL-01 dataset audit |

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/specs/epic_23/checklists/ru_localization_spotcheck.md` | RU localization spot-check checklist | QA checklist for RU content | Filled with 5 samples per channel |

---

## TL-02: Exporter Verification

### Data Artifacts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `data/benchmarks/exports/2025-11-15/digests.jsonl` | Exported digest records (150 records) | Benchmark dataset for digests | Used in TL-03 benchmarks |
| `data/benchmarks/exports/2025-11-15/review_reports.jsonl` | Exported review report records (150 records) | Benchmark dataset for reviews | Used in TL-03 benchmarks |
| `data/benchmarks/exports/2025-11-15/manifest.json` | SHA256 manifest for exported files | File integrity verification | Generated by exporter scripts |
| `data/benchmarks/exports/2025-11-15/schema_validation.json` | Schema validation results | Validates JSONL schema compliance | Generated by exporter scripts |

### Scripts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `scripts/quality/analysis/export_digests.py` | CLI script for exporting digests to JSONL | Export pipeline entry point | Instrumented with `benchmark_export_duration_seconds` |
| `scripts/quality/analysis/export_review_reports.py` | CLI script for exporting review reports to JSONL | Export pipeline entry point | Instrumented with `benchmark_export_duration_seconds` |

### Tests
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/integration/benchmark/test_exporters.py` | Integration tests for exporter scripts | Validates exporter output schema | 2 tests passing (digests, review_reports) |

---

## TL-03: Benchmarks & Stage 05_03 Pilot

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/reference/en/PERFORMANCE_BENCHMARKS.md` | Performance benchmarks documentation | Stores benchmark results and thresholds | Updated with Stage 05_03 results |
| `docs/specs/epic_23/stage_05_03_pilot_log.md` | Stage 05_03 pilot execution log | Formalizes pilot run with approvals | Contains benchmark evidence + Analyst/Architect approvals |

### Scripts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `scripts/quality/benchmark/run_benchmark.py` | Benchmark execution script | Runs LLM-as-judge evaluations | Used for dry-run and live benchmarks |

---

## TL-04: Observability Instrumentation

### Configuration
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `prometheus/alerts.yml` | Prometheus alert rules | Defines alerts for Epic 23 metrics | Added 6 alerts (4 Epic 23 + 2 Loki) |
| `grafana/dashboards/stage05-benchmarks.json` | Grafana dashboard for Stage 05 benchmarks | Visualizes benchmark outcomes | Added Epic 23 metrics panel |

### Code Artifacts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `src/infrastructure/metrics/observability_metrics.py` | New Prometheus metrics module | Centralizes Epic 23 metrics | Exports `structured_logs_total`, `benchmark_export_duration_seconds`, `shared_infra_bootstrap_status`, `rag_variance_ratio` |
| `src/infrastructure/metrics/benchmark_metrics.py` | Benchmark seeding metrics | Tracks benchmark data ingestion | Exports `benchmark_digest_records_total`, `benchmark_review_records_total` |
| `src/infrastructure/logging/__init__.py` | Structured logging utilities | Increments `structured_logs_total` | Integrated with Prometheus registry |
| `src/infrastructure/rag/llm_reranker_adapter.py` | RAG reranker adapter | Records `rag_variance_ratio` and `rag_fallback_reason_total` | Instrumented for TL-07 |

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/operational/observability_labels.md` | Observability labels and conventions | Standardizes metric and log labels | Created in TL-04 |
| `docs/roles/analyst/day_capabilities.md` | Analyst role capabilities | Describes Day 23 observability capability | Updated with Day 23 section |
| `docs/roles/analyst/examples/day_23_observability.md` | Analyst observability example | Shows handoff JSON with observability metadata | Created in TL-04 |
| `docs/roles/analyst/examples/README.md` | Analyst examples index | Indexes available examples | Updated with Day 23 example |

### Tests
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/integration/observability/test_alert_rules.py` | Integration tests for alert rules | Validates Prometheus alert configuration | 3 tests added (Epic 23 alerts, Loki alerts, metrics validation) |

---

## TL-05: Shared Infrastructure Automation

### Scripts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `scripts/ci/bootstrap_shared_infra.py` | Shared infrastructure bootstrap script | Automates infra setup for CI | Added `--check` flag for CI gating |
| `scripts/ci/cleanup_shared_infra.py` | Shared infrastructure cleanup script | Automates infra teardown for CI | Used by `make day-23-down` |

### Makefile Targets
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `Makefile` (targets: `day-23-up`, `day-23-down`) | Make targets for shared infra automation | Wraps bootstrap/cleanup scripts | Created in TL-05 |

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/specs/epic_23/shared_infra_restart.md` | Shared infrastructure restart validation | Documents restart process and evidence | Contains commands, PromQL queries, screenshots |

### Tests
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/integration/shared_infra/test_bootstrap.py` | Integration tests for bootstrap/cleanup | Validates infra restart functionality | 4 tests (check flag, bootstrap, cleanup, restart validation) |

---

## TL-06: Documentation & Hygiene

### Scripts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `scripts/tools/compress_jsonl.py` | JSONL compression utility | Compresses large JSONL files using gzip | Created in TL-06 |
| `data/benchmarks/exports/*.jsonl.gz` | Compressed JSONL files | Reduced size from 555KB to ~148KB (26.5%) | Generated by compression script |

### Configuration Fixes
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `config/mcp_config.yaml` | MCP configuration | Fixed YAML parsing (removed docstring) | Validated in TL-06 |
| `tests/e2e/telegram/fixtures/test_messages.json` | E2E test fixtures | Fixed invalid JavaScript syntax | Validated in TL-06 |
| `archive/docker-compose/docker-compose.yml` | Archived Docker Compose config | Validated YAML syntax | Validated in TL-06 |

### Code Fixes
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `shared/tests/test_agents.py` | Shared package tests | Black formatted, removed unused imports | Fixed lint errors |
| `shared/tests/test_api_keys.py` | Shared package tests | Black formatted, removed unused imports | Fixed lint errors |
| `shared/tests/test_external_apis.py` | Shared package tests | Black formatted, re-added `patch` import | Fixed lint errors |

### Tests
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/integration/presentation/cli/test_backoffice_cli.py` | Backoffice CLI integration tests | Covers `channels` commands (list/add/remove) | 11 tests passing (6 new for channels) |

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `README.md` | Main project README | Added "Large Data Files" section with compression instructions | Updated in TL-06 |
| `README.ru.md` | Russian localization of README | Updated with observability metrics and restart validation | Updated in TL-06 |
| `docs/specs/epic_23/deployment_manifest_checklist.md` | Deployment manifest checklist | Inventory of legacy assets and deployment verification | Created in TL-06 |
| `archive/docs/epic_21/epic_21_backlog.md` | Epic 21 backlog | Documented legacy async tests | Updated in TL-06 |

---

## TL-07: RAG++ Reproducibility

### Configuration
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `config/retrieval_rerank_config.yaml` | RAG rerank configuration | Extended with `seed`, `variance_window`, `adaptive_threshold` | Updated in TL-07 |

### Code Artifacts
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `src/infrastructure/config/rag_rerank.py` | RAG rerank config models | Extended `RerankerConfig` with new fields | Updated in TL-07 |
| `src/infrastructure/rag/llm_reranker_adapter.py` | LLM reranker adapter | Uses `seed` parameter, records `rag_fallback_reason_total` | Updated in TL-07 |
| `src/presentation/cli/rag_commands.py` | RAG CLI commands | Passes `seed` from config to reranker | Updated in TL-07 |

### Documentation
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/specs/epic_23/owner_only/rag_plus_plus_addendum.md` | Owner-only RAG++ addendum | Documents tuning cadence, randomness controls, variance metrics, canary plan | Created in TL-07 |

### Tests
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/unit/rag/test_rag_plus_plus.py` | Unit tests for RAG++ config and metrics | Validates config loading and metric registration | 2 tests added |
| `tests/integration/rag/test_variance_metrics.py` | Integration tests for RAG++ variance metrics | Validates variance and fallback metrics behavior | 2 tests (variance, fallback) |

---

## TL-08: Challenge Days Gap Closure

### Examples (Wave 1: Days 1-8)
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `examples/day01_basic_agent.py` | Day 1: Basic agent example | Minimal agent with EchoTool | Created in Wave 1 |
| `examples/day02_output_schema.py` | Day 2: Structured output example | Agent with JSON schema parsing | Created in Wave 1 |
| `examples/day03_conversation.py` | Day 3: Conversational agent example | Multi-turn conversation with stopping condition | Created in Wave 1 |
| `examples/day04_temperature.py` | Day 4: Temperature comparison example | Compares responses with different temperatures | Created in Wave 1 |
| `examples/day05_model_comparison.py` | Day 5: Model comparison example | Compares multiple LLM models | Created in Wave 1 |
| `examples/day06_chain_of_thought.py` | Day 6: Chain of Thought example | CoT vs direct answer comparison | Created in Wave 1 |
| `examples/day07_agent_interaction.py` | Day 7: Agent interaction example | Two agents interacting via orchestrator | Created in Wave 1 |
| `examples/day08_token_handling.py` | Day 8: Token handling example | Token counting, truncation, summarization | Created in Wave 1 |

### Tests (Wave 1: Days 1-8)
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/unit/examples/test_day01_basic_agent.py` | Unit tests for Day 1 example | Validates basic agent functionality | 37 tests total (Days 1-8) |
| `tests/unit/examples/test_day02_output_schema.py` | Unit tests for Day 2 example | Validates structured output parsing | |
| `tests/unit/examples/test_day03_conversation.py` | Unit tests for Day 3 example | Validates conversational stopping | |
| `tests/unit/examples/test_day04_temperature.py` | Unit tests for Day 4 example | Validates temperature comparison | |
| `tests/unit/examples/test_day05_model_comparison.py` | Unit tests for Day 5 example | Validates model comparison | |
| `tests/unit/examples/test_day06_chain_of_thought.py` | Unit tests for Day 6 example | Validates CoT comparison | |
| `tests/unit/examples/test_day07_agent_interaction.py` | Unit tests for Day 7 example | Validates agent interaction | |
| `tests/unit/examples/test_day08_token_handling.py` | Unit tests for Day 8 example | Validates token handling | |

### Documentation (Wave 2: Days 11-18, Wave 3: Days 19-22)
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `docs/challenge_days.md` | Challenge Days master narrative | Updated for all Days 1-22 with implementation details | Comprehensive update in Waves 2-3 |

### Tests (Wave 3: Day 22)
| Path | Description | Purpose | Evidence |
| --- | --- | --- | --- |
| `tests/integration/rag/test_citations_enforcement.py` | Integration tests for citations enforcement | Validates citations in RAG prompts | 4 tests added |

---

## Summary Statistics

### Code Artifacts
- **New scripts**: 6 (`seed_benchmark_data.py`, `verify_benchmark_counts.py`, `export_digests.py`, `export_review_reports.py`, `compress_jsonl.py`, `run_benchmark.py`)
- **New examples**: 8 (Days 1-8)
- **New tests**: 12 suites (8 unit + 4 integration)
- **Code modules**: 10+ (metrics, logging, RAG, CLI)

### Data Artifacts
- **Benchmark snapshots**: 3 files (`channel_counts.json`, `ru_spotcheck.md`, `dataset_audit.json`)
- **Exported datasets**: 2 JSONL files (150 records each)
- **Compressed files**: 2 JSONL.gz files (555KB → 148KB)

### Documentation Artifacts
- **Specs**: 8+ files (`acceptance_matrix.md`, `work_log.md`, `completion_summary.md`, etc.)
- **Operational docs**: 3 files (`observability_labels.md`, `PERFORMANCE_BENCHMARKS.md`, `shared_infra_restart.md`)
- **Role docs**: 2 files (Analyst capabilities, examples)
- **Checklists**: 1 file (`ru_localization_spotcheck.md`)

### Configuration Artifacts
- **Alert rules**: `prometheus/alerts.yml` (6 alerts added)
- **Grafana dashboards**: `grafana/dashboards/stage05-benchmarks.json` (panel added)
- **RAG config**: `config/retrieval_rerank_config.yaml` (3 fields added)

### Test Artifacts
- **Total tests**: 41 passing (37 unit + 4 integration)
- **Test suites**: 12 (8 examples + 4 integration)
- **Coverage**: CLI coverage improved from 45.96% to ~60%+

---

## Quick Reference

### For Analysts
- **Benchmark data**: `data/benchmarks/snapshots/2025-11-15/`
- **Exports**: `data/benchmarks/exports/2025-11-15/`
- **RU localization**: `docs/specs/epic_23/checklists/ru_localization_spotcheck.md`
- **Observability examples**: `docs/roles/analyst/examples/day_23_observability.md`

### For Tech Leads
- **Acceptance matrix**: `docs/specs/epic_23/acceptance_matrix.md` (v1.10)
- **Work log**: `docs/specs/epic_23/work_log.md`
- **Completion summary**: `docs/specs/epic_23/epic_23_completion_summary.md`
- **Shared infra restart**: `docs/specs/epic_23/shared_infra_restart.md`

### For Developers
- **Dev handoff**: `docs/specs/epic_23/dev_handoff.md`
- **Challenge Days plan**: `docs/specs/epic_23/challenge_days_gap_closure_plan.md`
- **Legacy refactor proposal**: `docs/specs/epic_23/legacy_refactor_proposal.md`

---

_Maintained by cursor_dev_a_v1 · Updated 2025-11-16_

